{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "b_re = b.reshape([b.shape[0], 1, b.shape[1]])\n",
    "\n",
    "br_zeros = T.zeros_like(a)\n",
    "\n",
    "b_br = b_re + br_zeros\n",
    "test1 = theano.function([a, b], b_br)\n",
    "result = T.batched_dot(a, b_re.dimshuffle(0,2,1))\n",
    "mask = T.matrix()\n",
    "final_result = result * mask.reshape([mask.shape[0], mask.shape[1], 1])\n",
    "test = theano.function([a, b, mask], final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   6.],\n",
       "        [  15.],\n",
       "        [  24.],\n",
       "        [  33.]],\n",
       "\n",
       "       [[  84.],\n",
       "        [ 102.],\n",
       "        [ 120.],\n",
       "        [   0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = np.array([[[1,2,3], [4,5,6], [7,8,9], [10,11,12]],[[13,14,15],[16,17,18],[19,20,21],[22,23,24]]])\n",
    "b_1 = np.array([[1,1,1], [2,2,2]])\n",
    "mask_1 = np.array([[1,1,1,1],[1,1,1,0]])\n",
    "test(a_1, b_1, mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "b = T.tensor3()\n",
    "\n",
    "c = a*b\n",
    "\n",
    "result = theano.function([a,b],c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[1] = 2, input[1].shape[1] = 3)\nApply node that caused the error: Elemwise{mul,no_inplace}(InplaceDimShuffle{x,0,1}.0, <TensorType(float64, 3D)>)\nToposort index: 1\nInputs types: [TensorType(float64, (True, False, False)), TensorType(float64, 3D)]\nInputs shapes: [(1, 2, 3), (2, 3, 1)]\nInputs strides: [(48, 24, 8), (24, 8, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-3132bfe577b7>\", line 4, in <module>\n    c = a*b\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-676a655fd294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[1] = 2, input[1].shape[1] = 3)\nApply node that caused the error: Elemwise{mul,no_inplace}(InplaceDimShuffle{x,0,1}.0, <TensorType(float64, 3D)>)\nToposort index: 1\nInputs types: [TensorType(float64, (True, False, False)), TensorType(float64, 3D)]\nInputs shapes: [(1, 2, 3), (2, 3, 1)]\nInputs strides: [(48, 24, 8), (24, 8, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-3132bfe577b7>\", line 4, in <module>\n    c = a*b\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "a_ = np.array([[1,2,3],[4,4,4]])\n",
    "b_ = np.array([[[1],[1],[1]],[[2],[2],[2]]])\n",
    "result(a_, b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "a = T.vector()\n",
    "b = T.vector()\n",
    "\n",
    "c = lasagne.objectives.binary_crossentropy(a, b)\n",
    "test = theano.function([a,b], c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30258509,  0.69314718,  1.60943791])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.9,0.5,0.2])\n",
    "b = np.array([0,1,1])\n",
    "test(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "c = T.mean(a, axis = 1)\n",
    "d = T.sum(a, axis = 1) / T.sum(b, axis = 1).reshape([-1,1])\n",
    "\n",
    "test1 = theano.function([a,b], [c,d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.5,   6.5,   7.5],\n",
       "        [ 17.5,  18.5,  19.5]]),\n",
       " array([[  5.5       ,   6.5       ,   7.5       ],\n",
       "        [ 23.33333333,  24.66666667,  26.        ]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = np.array([[[1,2,3], [4,5,6], [7,8,9], [10,11,12]],[[13,14,15],[16,17,18],[19,20,21],[22,23,24]]])\n",
    "b_1 = np.array([[1,1,1], [2,2,2]])\n",
    "mask_1 = np.array([[1,1,1,1],[1,1,1,0]])\n",
    "test1(a_1, mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BLSTM_sequence\n",
    "import sys\n",
    "# from theano.printing import pydotprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, dropout_rate, batchsize, val_split_ratio, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "\n",
    "        self.train_func = None\n",
    "\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(200, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        # self.mlp_units = [int(elem) for elem in mlp_setting.split('x')]\n",
    "        self.bilinear_matrix = theano.shared(0.002*np.random.rand(self.rnn_units, self.rnn_units)-0.001)\n",
    "        self.dropout_rate = float(dropout_rate)\n",
    "        self.batchsize = int(batchsize)\n",
    "\n",
    "        self.val_split_ratio = float(val_split_ratio)\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.train_encodinglayer_vecs = []\n",
    "        self.test_encodinglayer_vecs = []\n",
    "        self.reasoninglayer_vec1 = []\n",
    "        self.reasoninglayer_vec2 = []\n",
    "        self.reasoninglayer_vec1_test = []\n",
    "        self.reasoninglayer_vec2_test = []\n",
    "        self.reasoning_pool_results = []\n",
    "        self.reasoning_pool_results_test = []\n",
    "        self.reasoners = []\n",
    "        self.attentioned_sent_rep1 = []\n",
    "        self.attentioned_sent_rep2 = []\n",
    "        self.monitor1 = []\n",
    "        self.monitor2 = []\n",
    "        self.attention_moni1 = []\n",
    "        self.attention_moni2 = []\n",
    "        self.softmask_moni = []\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "        \n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent):\n",
    "            self.train_encodinglayer_vecs.append(lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True))\n",
    "        ending1_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[4],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[4]},\n",
    "                                                        deterministic = True)\n",
    "        ending2_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[5],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[5]},\n",
    "                                                        deterministic = True)\n",
    "\n",
    "        l_end_in= lasagne.layers.InputLayer((None, None, self.rnn_units))\n",
    "        l_shuffle = lasagne.layers.DimshuffleLayer(l_end_in, (0,2,1))\n",
    "        l_pooling = lasagne.layers.GlobalPoolLayer(l_shuffle)\n",
    "\n",
    "\n",
    "        end1_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending1_sequence_tensor})\n",
    "        end2_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending2_sequence_tensor})\n",
    "        self.train_encodinglayer_vecs.append(end1_representation)\n",
    "        self.train_encodinglayer_vecs.append(end2_representation)\n",
    "        \n",
    "    def attention_layer(self):        \n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "      \n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention1_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[4])\n",
    "\n",
    "            attention2_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[5])\n",
    "\n",
    "#             softmax_mask = \n",
    "#             self.softmask_moni.append(softmax_mask)\n",
    "            numerator1 = self.inputs_masks[i] * T.exp(attention1_score_tensor - attention1_score_tensor.max(axis = 1, keepdims = True))\n",
    "            numerator2 = self.inputs_masks[i] * T.exp(attention2_score_tensor - attention2_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention1_weight_matrix = numerator1 / numerator1.sum(axis = 1, keepdims = True)\n",
    "            attention2_weight_matrix = numerator2 / numerator2.sum(axis = 1, keepdims = True)\n",
    "#             attention1_weight_matrix = T.nnet.softmax(attention1_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "#             attention2_weight_matrix = T.nnet.softmax(attention2_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "            self.attention_moni1.append(attention1_weight_matrix)\n",
    "            self.attention_moni2.append(attention2_weight_matrix)\n",
    "            \n",
    "            attentioned_sent_seq1 = self.train_encodinglayer_vecs[i]*(attention1_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            attentioned_sent_seq2 = self.train_encodinglayer_vecs[i]*(attention2_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            \n",
    "            self.monitor1.append(attentioned_sent_seq1)\n",
    "            self.monitor2.append(attentioned_sent_seq2)\n",
    "            \n",
    "            attentioned_sent_rep1 = T.sum(attentioned_sent_seq1, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "            attentioned_sent_rep2 = T.sum(attentioned_sent_seq2, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep1.append(attentioned_sent_rep1)\n",
    "            self.attentioned_sent_rep2.append(attentioned_sent_rep2)\n",
    "\n",
    "           \n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        for i in range(self.story_nsent+2):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "\n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units, dropout_rate = self.dropout_rate)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "        self.test0 = theano.function(self.inputs_variables + self.inputs_masks, self.train_encodinglayer_vecs)\n",
    "        #build attention layer\n",
    "        self.attention_layer()\n",
    "        \n",
    "        self.test2 = theano.function(self.inputs_variables + self.inputs_masks, self.monitor1+self.monitor2)\n",
    "        self.test3 = theano.function(self.inputs_variables + self.inputs_masks, self.attention_moni1 + self.attention_moni2)\n",
    "        \n",
    "#         self.test4 = theano.function(self.inputs_masks[:4], self.softmask_moni)\n",
    "        #build reasoning layers\n",
    "        \n",
    "        self.test1 = theano.function(self.inputs_variables + self.inputs_masks, self.attentioned_sent_rep1 + self.attentioned_sent_rep2)\n",
    "        self.merge_ls1 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep1]\n",
    "        self.merge_ls2 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep2]\n",
    "\n",
    "        encode_merge1 = T.concatenate(self.merge_ls1, axis = 1)\n",
    "        encode_merge2 = T.concatenate(self.merge_ls2, axis = 1)\n",
    "\n",
    "        l_in = lasagne.layers.InputLayer(shape=(None, None, self.rnn_units))\n",
    "        gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        b=lasagne.init.Constant(0.))\n",
    "\n",
    "        cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                        W_cell=None, \n",
    "                                                        b=lasagne.init.Constant(0.),\n",
    "                                                        # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        l_lstm = lasagne.layers.recurrent.LSTMLayer(l_in, \n",
    "                                                    num_units=self.rnn_units,\n",
    "                                                    # Here, we supply the gate parameters for each gate \n",
    "                                                    ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                    cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                    # We'll learn the initialization and use gradient clipping \n",
    "                                                    learn_init=True, grad_clipping=100.0)\n",
    "\n",
    "        # The back directional LSTM layers\n",
    "        l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_in,\n",
    "                                                         num_units=self.rnn_units,\n",
    "                                                         ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                         cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                         # We'll learn the initialization and use gradient clipping \n",
    "                                                         learn_init=True,grad_clipping=100.0,\n",
    "                                                         backwards=True)\n",
    "\n",
    "        # Do sum up of bidirectional LSTM results\n",
    "        l_out_right = lasagne.layers.SliceLayer(l_lstm, -1, 1)\n",
    "        l_out_left = lasagne.layers.SliceLayer(l_lstm_back, -1, 1)\n",
    "        l_sum = lasagne.layers.ElemwiseSumLayer([l_out_right, l_out_left])\n",
    "\n",
    "        reasoner_result1 = lasagne.layers.get_output(l_sum, {l_in: encode_merge1}, deterministic = True)\n",
    "        reasoner_result2 = lasagne.layers.get_output(l_sum, {l_in: encode_merge2}, deterministic = True)\n",
    "\n",
    "        reasoner_params = lasagne.layers.get_all_params(l_sum)\n",
    "\n",
    "        # l_story_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        # l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "        #                                   nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        # final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "        \n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "                                          nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "\n",
    "        score1 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-2]})\n",
    "        score2 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result2, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-1]})\n",
    "        self.test5 = theano.function(self.inputs_variables + self.inputs_masks,[score1, score2])\n",
    "        prob1 = lasagne.nonlinearities.softmax(score1)\n",
    "        prob2 = lasagne.nonlinearities.softmax(score2)\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        target1 = T.vector('gold_target1', dtype= 'int64')\n",
    "        target2 = T.vector('gold_target2', dtype= 'int64')\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, target1)\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, target2)\n",
    "\n",
    "        self.cost = lasagne.objectives.aggregate(cost1+cost2, mode='sum')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        all_params = self.encoder.all_params + reasoner_params + final_class_param\n",
    "\n",
    "        all_updates = lasagne.updates.sgd(self.cost, all_params, learning_rate=0.001)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "        updates_exp = [val for key,val in all_updates.items()]\n",
    "        self.test_params = theano.function(self.inputs_variables+self.inputs_masks+[target1, target2], updates_exp, on_unused_input='warn')\n",
    "        self.train_func = theano.function(self.inputs_variables + self.inputs_masks + [target1, target2], \n",
    "                                        [self.cost, prob1, prob2], updates = all_updates)\n",
    "\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + self.inputs_masks, [score1, score2])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a = Hierachi_RNN('300','0.0','20','0.25')\n",
    "a.model_constructor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "targ1 = np.random.randint(2, size=(5,))\n",
    "targ2 = 1 - targ1\n",
    "params = a.train_func(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5], targ1, targ2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7.641996219323214)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score1= a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[28, 54, 37, 81, 45, 85, 43, 30,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 45,  7, 27, 75, 20, 19, 50,  0, 61, 89, 68, 88, 63, 27,  5],\n",
       "        [49, 47, 95, 73, 22, 82, 58, 60, 94, 66,  6, 38, 87, 38, 67,  0],\n",
       "        [57, 51,  4, 97, 44, 47, 61, 35, 10, 62, 92,  0,  0,  0,  0,  0],\n",
       "        [ 1, 61, 44, 99, 33, 92, 71, 81, 57, 10, 59, 26, 39, 91, 66, 29]]),\n",
       " array([[93, 81, 48, 80, 88, 74, 81, 96, 98, 67, 59, 72, 51, 93, 17, 78],\n",
       "        [66, 13, 22, 10, 19, 47, 10, 81, 57, 43, 78, 56, 90, 11, 84,  0],\n",
       "        [ 4, 33, 74, 10, 97,  2,  0, 86, 93, 51, 52,  0,  0,  0,  0,  0],\n",
       "        [19, 22, 74, 43, 85, 97, 49, 46, 80, 95, 72, 18, 13, 13, 48, 48],\n",
       "        [54, 35, 99, 72, 19, 95, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[44, 22, 18, 66, 27, 56,  9, 41,  0, 26, 78, 41, 15, 85,  6,  0],\n",
       "        [ 8, 79, 77, 60,  3, 53, 39, 11, 87, 26, 71,  0,  0,  0,  0,  0],\n",
       "        [ 8, 87, 11, 57, 76, 87, 51, 82, 90, 10, 56, 16, 14, 14, 13, 23],\n",
       "        [10, 22, 44, 56, 18, 77, 78,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 85, 23, 59, 42, 80,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[83, 72, 49, 51, 43, 99, 48, 32, 73, 48, 47,  0,  0,  0,  0,  0],\n",
       "        [33, 38, 62, 10,  5, 16, 12, 60,  8, 69, 49, 17, 45, 84,  1, 36],\n",
       "        [26, 19, 25, 71, 87, 76, 82,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [55, 10, 85, 89, 28,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [72, 64, 34,  6, 91, 51, 79,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[20, 88, 40, 74, 57, 91, 70, 94, 60,  5, 91, 41, 94, 37, 32, 94],\n",
       "        [35, 47, 38, 99, 12, 62,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [17, 22, 96, 89, 43,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [10, 34,  5, 38, 83, 71,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 76, 42, 30, 60, 57, 66, 40, 77, 38, 53, 99, 77, 66, 55,  0]]),\n",
       " array([[14, 36, 71, 12, 30, 81, 64,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [59, 18, 55, 70, 89, 81,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [98, 89, 18, 88,  2,  3, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [41, 29, 38, 55, 69, 44,  3, 43, 31, 85, 42, 72,  4, 32, 89,  0],\n",
       "        [48, 82, 18, 48, 39,  0,  4, 57, 29, 27, 79, 97, 84, 40, 62, 80]])]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "\n",
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "result = a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                 inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  4 55 67 81 81  6 29  0  0  0  0  0  0  0  0]\n",
      " [21 36 34 19 78 49  2 19  0 77 75 74 17  9 19  3]\n",
      " [ 5 29 11 94 21 70 78 10  2  6 98 42 66 28  8  0]\n",
      " [ 3 67 35 72 27 50 47 96 91 89 98  0  0  0  0  0]\n",
      " [44 30 99 88 56 79 69 91 34 33 72 41 28 81 74 33]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[  6.12901829e-04   1.28206219e-02   1.85810721e-02   1.77323277e-03\n",
      "  -1.10088005e-02  -5.78050119e-04   9.91322895e-04   1.83338379e-02\n",
      "  -7.76145479e-03   9.97180350e-03   2.69632479e-03  -1.11936929e-02\n",
      "  -6.97481570e-03   6.67866176e-03  -6.61085645e-04   8.17177092e-03\n",
      "  -8.19279369e-03   1.05830154e-02  -1.43372396e-02  -2.16162561e-03\n",
      "   3.08066795e-03   5.19928999e-03   5.88627218e-04  -7.88304211e-03\n",
      "  -1.46142518e-02   1.33390188e-02  -9.66771911e-03  -1.12186504e-02\n",
      "   3.66041710e-03   9.62523792e-03   1.28240819e-03  -5.20637273e-03\n",
      "  -8.51101042e-03   1.73788929e-03   1.94455368e-02  -1.24445732e-02\n",
      "  -7.50992763e-03  -1.18625974e-02   1.06565481e-02  -8.50607810e-03\n",
      "   9.51179236e-03  -1.27784173e-02   5.83417507e-03   1.72071440e-03\n",
      "  -9.64891977e-03   3.19398294e-03   1.17664811e-03  -9.18265630e-03\n",
      "  -8.65501609e-03  -1.03077354e-02   6.24028133e-03   4.43544259e-03\n",
      "  -2.45638349e-03  -4.25684644e-03   3.18747801e-02  -4.83649828e-05\n",
      "  -2.67939775e-02   9.74076707e-03   1.85942881e-02   1.24826275e-02\n",
      "  -2.17771374e-03  -4.68531558e-03   1.65318610e-02  -7.70148862e-03\n",
      "  -4.53093356e-04   3.14170183e-03   5.68420569e-03   2.06413522e-03\n",
      "   6.46826867e-03   1.39458706e-02   7.86960621e-04   1.44683683e-02\n",
      "  -2.27745902e-03  -1.96257737e-03  -4.98108148e-03   1.09601473e-03\n",
      "   1.15702706e-02  -4.88663669e-04   5.55022096e-03  -2.14605097e-02\n",
      "   1.15699134e-02  -1.11456152e-02   1.79392008e-03  -9.65212770e-04\n",
      "  -4.01781367e-03  -2.66765009e-03   2.26317785e-02   2.62675659e-05\n",
      "  -1.10773527e-02   2.56231139e-02   3.64012285e-03   1.18579518e-03\n",
      "   6.27733309e-03   9.23497631e-03   1.62080369e-02   2.52564406e-02\n",
      "   7.51477522e-03  -2.06253158e-03   7.10767999e-03   1.40570235e-03\n",
      "   6.14302837e-03   1.19155039e-02   7.78394065e-03  -5.90404405e-03\n",
      "   1.82832533e-03   3.23915510e-03   9.65873192e-05  -4.56338311e-03\n",
      "  -7.07014263e-03   1.40139544e-02  -9.51349706e-03  -1.34675806e-02\n",
      "   4.32400248e-03   4.32495517e-03   3.97841646e-03   7.17472132e-03\n",
      "  -1.39945855e-02  -1.68467974e-02  -9.66305075e-03   1.60504493e-02\n",
      "   1.23255507e-03   6.79191690e-03  -2.96179842e-03  -2.38546597e-02\n",
      "  -7.90462629e-03  -1.30571703e-02  -9.85711479e-04   1.10375176e-02\n",
      "   2.34140539e-03   1.69988652e-02   1.65805489e-02  -4.31683382e-03\n",
      "   6.53745632e-03   1.43275687e-02  -1.28447464e-02   1.53071060e-02\n",
      "  -1.51665692e-02  -1.03113224e-02  -3.59152320e-03  -7.34195665e-04\n",
      "   6.31960286e-03   1.13752726e-03  -2.51985425e-03   6.72883109e-03\n",
      "   1.05660976e-02   4.02486207e-03   4.20284436e-03  -6.79560347e-03\n",
      "  -6.66788572e-03  -5.18571887e-03  -5.30564288e-03   7.62538054e-03\n",
      "  -6.82219998e-04  -2.58756882e-02   1.60720733e-02   3.64325227e-03\n",
      "  -1.36926145e-02   8.85965549e-03  -6.08703759e-03  -2.43360334e-03\n",
      "   2.86727818e-02  -1.08768390e-02  -1.10670555e-02   7.06415504e-03\n",
      "   6.29545874e-03   1.67114386e-02   2.66423131e-03   8.70040078e-04\n",
      "  -1.26650183e-02  -1.16223439e-03  -4.61444065e-03   1.12443631e-02\n",
      "  -6.52807044e-03   2.42937622e-04  -1.19337379e-02  -1.99760387e-02\n",
      "   2.54425996e-03  -2.08506154e-03  -2.02432775e-03  -6.02969191e-03\n",
      "   7.65383764e-03  -4.72874181e-03   1.77809952e-02  -1.45806668e-02\n",
      "   1.92331560e-03  -1.64423652e-03   1.51963304e-02   1.02336222e-02\n",
      "   5.04524088e-03   2.43555917e-04  -3.03444673e-03  -4.60696976e-03\n",
      "  -1.04928335e-02  -5.72604887e-03   5.84920778e-03   4.77405925e-03\n",
      "   1.19406516e-02   4.07472596e-03  -1.93495969e-03   1.42278470e-02\n",
      "  -6.40953767e-03  -7.15519049e-03   9.44585834e-03  -3.15805734e-03\n",
      "   1.99132209e-02   1.36058179e-02   3.28401758e-03   9.36933386e-04\n",
      "  -2.77298232e-02   1.75149988e-02  -1.12172287e-02   8.29564100e-03\n",
      "  -1.13648752e-02   1.20745985e-02   1.16299438e-02  -7.76033557e-03\n",
      "   9.58660938e-03  -9.81128668e-03  -7.01891847e-03   1.89040723e-02\n",
      "   6.08100699e-04  -1.55949339e-02   1.47368876e-03   5.40284637e-03\n",
      "   1.08121872e-03  -3.98831696e-03   2.64104700e-03   1.66084846e-02\n",
      "   8.20015834e-03  -1.80545218e-03  -1.52018644e-02   1.25828250e-02\n",
      "   1.04639226e-03   2.18510069e-03  -4.46118589e-03   2.65594848e-03\n",
      "  -1.41341777e-03  -1.02972093e-02   1.12638984e-02  -9.95874766e-04\n",
      "   7.03455949e-03   4.65672125e-03  -1.00189111e-03   1.38683847e-02\n",
      "  -5.79315488e-03  -7.92557103e-03  -6.39303663e-03   1.43947534e-02\n",
      "   7.89221383e-03  -9.02580717e-03   1.41391766e-02   1.13795110e-02\n",
      "   9.97864095e-04   1.92361880e-03   4.65610356e-03   9.56517716e-03\n",
      "  -1.20648781e-02   2.21202066e-03  -7.56610858e-03  -1.59140463e-02\n",
      "   1.47016665e-02  -3.72651362e-03  -1.05129558e-02  -1.15903027e-02\n",
      "   5.47858685e-03  -7.38039301e-03  -1.25416205e-02   5.04812993e-03\n",
      "  -2.50375041e-03  -9.64182127e-03   1.06434698e-02  -9.69211901e-03\n",
      "   9.88548112e-03  -5.84101852e-03  -6.41420916e-03  -2.72472152e-04\n",
      "  -1.03198516e-02  -1.88283584e-05   1.17215420e-02   1.04900717e-02\n",
      "  -1.11961182e-02  -7.96973804e-03  -8.23949385e-03   8.53354294e-03\n",
      "  -1.37106648e-04  -8.38620352e-03  -4.77263147e-03   2.54838106e-04\n",
      "  -3.07033373e-03   6.87926961e-03   1.37273834e-02  -1.32135102e-02\n",
      "   3.76477724e-03  -2.70994728e-03  -1.02458705e-02   6.57407824e-03\n",
      "  -2.17595903e-02  -7.30573375e-03  -1.35557353e-02  -9.36033449e-03]\n"
     ]
    }
   ],
   "source": [
    "print inputs_v[0]\n",
    "print inputs_m[0]\n",
    "print result[0][3][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "IN_ = T.matrix(dtype = 'int64')\n",
    "MASK = T.matrix(dtype = theano.config.floatX)\n",
    "\n",
    "IN = IN_.reshape((IN_.shape[0], IN_.shape[1], 1))\n",
    "\n",
    "wemb = theano.shared(np.random.rand(100, 300))\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, 1))\n",
    "\n",
    "# Masks input shape ==> (n_batch, n_time_steps)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None))\n",
    "\n",
    "#setting gates and cell parameters with specific nonlinearity functions\n",
    "gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                b=lasagne.init.Constant(0.))\n",
    "\n",
    "cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                W_cell=None, \n",
    "                                                b=lasagne.init.Constant(0.),\n",
    "                                                # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "# The embedding layers with retieve subtensor from word embedding matrix\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, input_size=wemb.get_value().shape[0], output_size=wemb.get_value().shape[1], W=wemb)\n",
    "\n",
    "l_drop = lasagne.layers.DropoutLayer(l_emb, p = 0.0)\n",
    "# The LSTM layer should have the same mask input in order to avoid padding entries\n",
    "l_lstm = lasagne.layers.recurrent.LSTMLayer(l_drop, \n",
    "                                            num_units=300,\n",
    "                                            # We need to specify a separate input for masks\n",
    "                                            mask_input=l_mask,\n",
    "                                            # Here, we supply the gate parameters for each gate \n",
    "                                            ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                            cell=cell_parameters, outgate=gate_parameters,\n",
    "                                            # We'll learn the initialization and use gradient clipping \n",
    "                                            learn_init=True\n",
    "                                            )\n",
    "\n",
    "\n",
    "# The back directional LSTM layers\n",
    "l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_drop,\n",
    "                                                 num_units=300,\n",
    "                                                 mask_input = l_mask,\n",
    "                                                 ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                 cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                 # We'll learn the initialization and use gradient clipping \n",
    "                                                 learn_init=True,\n",
    "                                                 backwards=True\n",
    "                                                )\n",
    "\n",
    "\n",
    "# Do sum up of bidirectional LSTM results\n",
    "l_sum = lasagne.layers.ElemwiseSumLayer([l_lstm, l_lstm_back])\n",
    "out = lasagne.layers.get_output(l_sum, {l_in:IN, l_mask:MASK}, deterministic = True)\n",
    "\n",
    "test = theano.function([IN_, MASK], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.41805189e-01   4.65947280e-02  -8.36854174e-02   1.07350674e-01\n",
      "  -2.37396935e-01  -1.79823246e-01   6.51879467e-02   4.60637026e-03\n",
      "  -2.09297061e-01  -1.59060352e-01   2.93781539e-01   2.85348498e-01\n",
      "   8.93948845e-02   5.16647735e-02  -6.63083297e-01  -3.32605698e-01\n",
      "  -2.13643046e-01  -2.52780222e-02   3.30183841e-01  -1.86089749e-01\n",
      "   2.64025800e-01   1.07492811e-01   5.57596003e-02  -4.45173354e-01\n",
      "  -1.89919893e-01   1.83129174e-01   1.55992846e-01   6.95604518e-02\n",
      "   2.86514647e-01  -4.01425141e-01  -3.06143785e-02  -2.88565510e-01\n",
      "  -6.13725809e-01  -1.95180382e-01  -2.38842957e-01  -2.73882412e-01\n",
      "  -1.94990750e-02   1.82266075e-01  -2.67372722e-02   1.89460599e-01\n",
      "  -3.17284749e-01   1.24459833e-01   1.97643377e-02  -4.07787518e-02\n",
      "   1.33853864e-01  -1.82464355e-01   8.99734217e-02   3.00601495e-01\n",
      "   1.07841359e-01   1.00602480e-01  -1.10121118e-01  -1.49100513e-01\n",
      "   4.55662451e-02   3.19698477e-01  -2.52166452e-01  -5.48263467e-02\n",
      "  -1.66052223e-01   2.32730964e-01   2.44532437e-01   2.88979955e-02\n",
      "  -1.54972644e-01   3.11617652e-02  -2.86030581e-01  -1.80347307e-01\n",
      "  -5.80585754e-03  -3.50427965e-01  -2.00044557e-01  -2.23736678e-01\n",
      "   3.44473783e-01  -1.16633545e-01   1.20076037e-01   1.64516287e-01\n",
      "  -3.76728337e-02   1.43556057e-01  -2.14316441e-01   3.13081906e-02\n",
      "  -1.81261681e-01   2.59679044e-01   6.83491469e-02   3.15903151e-01\n",
      "   1.42963854e-01  -4.82822922e-02   3.07992117e-02   8.36729715e-02\n",
      "  -2.20836098e-01   1.08064683e-01  -3.52158981e-01   6.33299526e-02\n",
      "   5.38521374e-02   1.26293333e-01  -1.51400991e-01  -1.73199360e-01\n",
      "   4.93580934e-02   9.74224017e-02  -1.90682080e-01  -1.18575519e-01\n",
      "  -6.88681518e-02   2.02876577e-01   6.42778192e-02  -3.59663086e-01\n",
      "  -1.61170709e-01   2.73048496e-01   3.04291984e-01  -5.47830130e-02\n",
      "   3.80496389e-02   1.29263373e-01  -1.41486884e-01   4.22245969e-01\n",
      "   3.45574460e-01  -1.32493562e-01  -4.02829865e-01  -1.19528884e-01\n",
      "  -1.18042623e-01   1.17232048e-01  -1.19601572e-01  -1.17724887e-01\n",
      "  -2.09025329e-02  -1.03244352e-02  -2.28599887e-04  -2.17391905e-01\n",
      "   1.20204521e-01   6.17174912e-02   2.30203500e-01  -1.38244054e-01\n",
      "   4.94981929e-02   2.18195071e-01  -2.12267096e-01  -1.88235632e-01\n",
      "   4.21086305e-02  -2.39597071e-01   1.73129334e-02   1.25530104e-01\n",
      "   9.64885552e-02   1.03689624e-01   1.17677763e-01  -1.42404896e-01\n",
      "   3.03548037e-01   3.59071841e-01  -1.43170138e-01  -1.45115828e-01\n",
      "   1.31757523e-01  -1.50814769e-02  -3.40939391e-01  -1.83105860e-02\n",
      "  -4.58525958e-01  -7.63787368e-03   2.66319285e-01  -1.84122525e-01\n",
      "   9.95186823e-02  -1.29188925e-01   2.43182762e-01   3.90279821e-02\n",
      "   1.40789155e-01   2.02716717e-01  -4.32419332e-04  -2.22346982e-01\n",
      "  -8.41890580e-02   1.87262149e-01  -5.17058521e-02   1.75941274e-01\n",
      "  -6.09538677e-03   1.42833704e-01  -1.31358050e-01  -1.12612377e-01\n",
      "   8.57445285e-02   1.66430535e-01   2.43428334e-01  -1.03569232e-01\n",
      "   1.99629578e-01   4.40311666e-01   5.33493546e-02  -7.20940593e-03\n",
      "   1.90127928e-01   2.48668682e-01  -6.49166649e-02   4.41358638e-02\n",
      "   8.76208976e-02   3.78786052e-01   2.18508988e-01  -3.75633042e-02\n",
      "   2.85975905e-02   2.19808020e-01   2.47440780e-01  -2.58754165e-01\n",
      "   2.94155414e-01  -8.21444917e-02  -1.16559695e-01   1.00147221e-01\n",
      "  -1.00013320e-01  -3.05407031e-01  -3.54175547e-02  -1.88286286e-01\n",
      "   1.31801810e-01  -2.50033897e-01  -3.64544650e-01  -1.92514940e-01\n",
      "  -2.20179670e-01   6.71782634e-02  -1.91986005e-01   8.99862525e-02\n",
      "   4.58506849e-02  -3.21618118e-01   1.27360550e-01  -5.78044083e-02\n",
      "  -2.46030986e-01   2.14993254e-01   4.92059966e-01  -2.24785879e-01\n",
      "   1.54586488e-02  -1.07244769e-01   1.34986476e-01   1.35231754e-01\n",
      "   2.63036715e-01  -1.32974960e-01  -2.19755114e-01  -2.90404075e-01\n",
      "   1.88962878e-01   2.57108608e-01   1.59051415e-01   6.40235904e-01\n",
      "  -8.81937500e-02   2.83615642e-01   2.79403292e-01  -1.40605716e-01\n",
      "  -1.35850237e-01   1.16606192e-01  -1.90442652e-01  -8.30214388e-02\n",
      "  -1.62195090e-01  -3.84474590e-03   3.35333647e-01   1.17424547e-01\n",
      "  -1.20708468e-01   2.80735464e-02   9.40222540e-02   7.45179891e-02\n",
      "  -1.92942886e-01   6.96951262e-03   2.33246674e-01   3.22433086e-01\n",
      "  -2.32097845e-01   1.67652782e-01  -7.95807504e-01  -2.43798434e-01\n",
      "   3.55652130e-01   4.94266208e-02  -2.10341914e-01   5.86849788e-02\n",
      "  -3.29640513e-02   2.18896708e-01  -3.64652703e-01  -9.67156222e-02\n",
      "   9.51957111e-02   3.68453550e-01   1.62654674e-01   2.12130387e-01\n",
      "  -4.76252094e-03   2.39174365e-01  -4.83751075e-02   1.95502159e-01\n",
      "   2.20471606e-01  -2.59043233e-01   1.10918691e-01   1.01299499e-01\n",
      "   1.67898083e-02   9.50671082e-02   7.92833124e-02   9.29138265e-02\n",
      "  -9.03090968e-02  -1.59619268e-02   3.25049892e-01  -8.55021027e-02\n",
      "  -1.25485420e-01  -2.75248046e-01  -1.31954432e-01  -6.11103789e-02\n",
      "  -1.85230646e-01   2.45496488e-01  -2.40795010e-01  -4.03117173e-01\n",
      "   5.85117944e-02  -2.81123249e-01  -2.09622975e-01  -1.48278290e-01\n",
      "   7.75883161e-02   6.81594361e-02  -8.07407569e-02  -6.23219426e-02\n",
      "   6.91475017e-02   2.72539457e-02  -1.36219491e-01  -1.29714907e-01\n",
      "   1.23861649e-01  -8.22218655e-02  -1.64528626e-01   1.89155404e-01\n",
      "  -1.06625821e-01   6.45507821e-02   2.63013033e-01  -2.77682583e-02]\n"
     ]
    }
   ],
   "source": [
    "result = test(inputs_v[5], inputs_m[5])\n",
    "print result[4][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "\n",
    "b = T.sum(a, axis = 1).reshape([-1,1])\n",
    "\n",
    "c = T.matrix()\n",
    "d = c / b\n",
    "test = theano.function([a,c], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1.5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(np.array([[1,1]]), np.array([[3,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "\n",
    "b = theano.shared\n",
    "a_ = a.reshape((-1, a.shape[2]))\n",
    "b_ = b.reshape((1,b.shape[0],b.shape[1]))\n",
    "b_f = b_ + T.zeros((a_.shape[0], b.shape[0], b.shape[1]))\n",
    "result = T.batched_dot(a_, b_f).reshape((a.shape[0], a.shape[1], -1))\n",
    "loss = result.sum()\n",
    "\n",
    "test = theano.function([a,b], result)\n",
    "train  = theano.function([a,b], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-54a9fa44f2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "a_test = np.arange(3*4*5).reshape((3,4,5))\n",
    "\n",
    "b_test = np.arange(5*5).reshape((5,5))\n",
    "\n",
    "testing = test(a_test, b_test)\n",
    "print testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "loss = T.batched_dot(a, b)\n",
    "test = theano.function([a,b], loss)\n",
    "# test = theano.function([inp], loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]\n",
      "  [30 31 32 33 34]\n",
      "  [35 36 37 38 39]]\n",
      "\n",
      " [[40 41 42 43 44]\n",
      "  [45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   30.,    80.,   130.,   180.],\n",
       "       [  780.,   955.,  1130.,  1305.],\n",
       "       [ 2530.,  2830.,  3130.,  3430.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test = np.arange(3*4*5).reshape((3,4,5))\n",
    "b_test = np.arange(3*5).reshape((3,5))\n",
    "print a_test\n",
    "print b_test\n",
    "test(a_test, b_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.tensor3()\n",
    "\n",
    "b_ = b.dimshuffle(0,2,1)\n",
    "a_ = a[0]\n",
    "test1 = theano.function([a], a_)\n",
    "c_ls, _ = theano.scan(lambda i:T.batched_dot(a[i], b_[i]), sequences=[T.arange(a.shape[0])])\n",
    "test = theano.function([a,b], c_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,2,3,3])\n",
    "c = np.all(a-b==0)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   1.   2.   3.   4.]\n",
      "  [  5.   6.   7.   8.   9.]\n",
      "  [ 10.  11.  12.  13.  14.]\n",
      "  [ 15.  16.  17.  18.  19.]]\n",
      "\n",
      " [[ 20.  21.  22.  23.  24.]\n",
      "  [ 25.  26.  27.  28.  29.]\n",
      "  [ 30.  31.  32.  33.  34.]\n",
      "  [ 35.  36.  37.  38.  39.]]\n",
      "\n",
      " [[ 40.  41.  42.  43.  44.]\n",
      "  [ 45.  46.  47.  48.  49.]\n",
      "  [ 50.  51.  52.  53.  54.]\n",
      "  [ 55.  56.  57.  58.  59.]]]\n",
      "[[  0.   1.   2.   3.   4.]\n",
      " [  5.   6.   7.   8.   9.]\n",
      " [ 10.  11.  12.  13.  14.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   30.,    80.,   130.,   180.],\n",
       "       [  780.,   955.,  1130.,  1305.],\n",
       "       [ 2530.,  2830.,  3130.,  3430.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(3 * 4 * 5).reshape(3, 4, 5).astype('float32')\n",
    "b = np.arange(3 * 5).reshape(3, 5).astype('float32')\n",
    "\n",
    "A = T.ftensor3()\n",
    "B = T.fmatrix()\n",
    "\n",
    "# out1 = T.tensordot(A,B)\n",
    "out = (A * B.dimshuffle(0, 'x', 1)).sum(2)\n",
    "print a\n",
    "print b\n",
    "out.eval({A: a, B: b})\n",
    "# out1.eval({A:a, B:b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "a_ = T.nnet.softmax(a)\n",
    "b = T.imatrix()\n",
    "\n",
    "c = lasagne.objectives.categorical_crossentropy(a_, b)\n",
    "test = theano.function([a, b], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "dictionary = pickle.load(open('../../data/pickles/index_wemb_matrix.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.matrix()\n",
    "\n",
    "e_x = x.max(axis=1, keepdims=True)\n",
    "\n",
    "test = theano.function([x], e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.],\n",
       "       [  7.],\n",
       "       [ 11.]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.matrix()\n",
    "b = T.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
