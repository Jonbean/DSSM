{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import cPickle as pickle\n",
    "import BLSTM_sequence\n",
    "import BLSTM_last\n",
    "import DNN_liar\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import sys\n",
    "# from theano.printing import pydotprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, val_split_ratio, D_batchsize, G_batchsize, liar_setting, \n",
    "                learning_rate1, learning_rate2, optimizer, \n",
    "                score_func_nonlin = 'default', wemb_trainable = 1, generator_halt_threshold = 0.1, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "        self.learning_rate1 = float(learning_rate1)\n",
    "        self.learning_rate2 = float(learning_rate2)\n",
    "        self.classifier_train_func = None\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(100, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "        self.train_set_path = '../../data/pickles/train_index_corpus.pkl'\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "        self.index2word_dict_path = '../../data/pickles/ROC_train_index_dict.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        self.liar_setting = [int(elem) for elem in liar_setting.split('x')]\n",
    "        # self.dropout_rate = float(dropout_rate)\n",
    "        self.D_batchsize = int(D_batchsize)\n",
    "        self.G_batchsize = int(G_batchsize)\n",
    "\n",
    "        self.val_split_ratio = float(val_split_ratio)\n",
    "        self.generator_halt_threshold = float(generator_halt_threshold)\n",
    "\n",
    "        self.classifier_hid1 = 1024\n",
    "        # self.val_split_ratio = float(val_split_ratio)\n",
    "        self.words_num = 28820\n",
    "        # self.delta = float(delta)\n",
    "        if score_func_nonlin == 'default':\n",
    "            self.score_func_nonlin = lasagne.nonlinearities.tanh\n",
    "        else:\n",
    "            self.score_func_nonlin = None\n",
    "\n",
    "        self.wemb_trainable = bool(int(wemb_trainable))\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.sent_reps = []\n",
    "\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "\n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent):\n",
    "            lstm_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True)\n",
    "            sent_rep = (lstm_seq * self.inputs_masks[i].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[i].sum(axis = 1, keepdims = True)\n",
    "            self.sent_reps.append(sent_rep)\n",
    "\n",
    "        self.end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                            {self.encoder.l_in:self.reshaped_inputs_variables[4], \n",
    "                                            self.encoder.l_mask:self.inputs_masks[4]},\n",
    "                                            deterministic = True)\n",
    "\n",
    "        self.current_Nbatch = self.sent_reps[0].shape[0]\n",
    "\n",
    "        merge_ls = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.sent_reps]\n",
    "        encode_merge = T.concatenate(merge_ls, axis = 1)\n",
    "\n",
    "        self.plot_rep = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge}, \n",
    "                                                    deterministic = True)\n",
    "\n",
    "    def attention_layer1(self):        \n",
    "        n_batch, n_seq, _ = self.end_seq.shape\n",
    "\n",
    "        #second attention\n",
    "        bili_part1 = T.dot(self.end_seq, self.bilinear_attention_matrix)\n",
    "\n",
    "        attention_score_tensor = T.batched_dot(bili_part1, self.plot_rep)\n",
    "\n",
    "        numerator = self.inputs_masks[4] * T.exp(attention_score_tensor - attention_score_tensor.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        attention_weight_matrix = numerator / numerator.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        attentioned_end_seq = self.end_seq * (attention_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "        self.attentioned_end_rep = T.sum(attentioned_end_seq, axis = 1) / T.sum(self.inputs_masks[4], axis = 1).reshape([-1, 1])\n",
    "\n",
    "    def attention_layer2(self):\n",
    "        n_batch, n_seq, _ = self.encode_2nd_end_seq.shape\n",
    "        #second attention\n",
    "        bili_part1 = T.dot(self.encode_2nd_end_seq, self.bilinear_attention_matrix)\n",
    "\n",
    "        attention_score_tensor = T.batched_dot(bili_part1, self.plot_rep)\n",
    "\n",
    "        numerator = self.vt_2nd_end_mask * T.exp(attention_score_tensor - attention_score_tensor.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        attention_weight_matrix = numerator / numerator.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        attentioned_end_seq = self.encode_2nd_end_seq*(attention_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "        self.vt_2nd_end_repr = T.sum(attentioned_end_seq, axis = 1) / T.sum(self.vt_2nd_end_mask, axis = 1).reshape([-1, 1])\n",
    "\n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        self.vt_2nd_end_in = T.matrix('second_end', dtype='int64')\n",
    "        self.vt_2nd_end = self.vt_2nd_end_in.reshape([self.vt_2nd_end_in.shape[0], self.vt_2nd_end_in.shape[1],1])\n",
    "        self.vt_2nd_end_mask = T.matrix('second_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "        for i in range(self.story_nsent+1):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "            \n",
    "        self.test1 = theano.function(self.inputs_variables + [self.vt_2nd_end_in], self.reshaped_inputs_variables + [self.vt_2nd_end])\n",
    "        \n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units, wemb_trainable = self.wemb_trainable)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "        self.sent_encoder = BLSTM_last.BlstmEncoder(INPUT_SIZE = self.rnn_units, LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.sent_encoder.build_model()\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "        self.test2 = theano.function(self.inputs_variables + self.inputs_masks, [self.plot_rep, self.end_seq])\n",
    "\n",
    "        '''============================================================================'''\n",
    "        #encode possible second ending\n",
    "        self.encode_2nd_end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.vt_2nd_end, \n",
    "                                                     self.encoder.l_mask:self.vt_2nd_end_mask},\n",
    "                                                     deterministic = True)\n",
    "        self.test3 = theano.function([self.vt_2nd_end_in, self.vt_2nd_end_mask], self.encode_2nd_end_seq)\n",
    "        self.attention_layer1()\n",
    "        self.test4 = theano.function(self.inputs_variables + self.inputs_masks, self.attentioned_end_rep)\n",
    "\n",
    "        self.attention_layer2()\n",
    "        self.test5 = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], self.vt_2nd_end_repr, on_unused_input = 'ignore')\n",
    "        '''============================================================================'''\n",
    "        '''alternative ending construction part'''\n",
    "        '''========================================================'''\n",
    "\n",
    "        # self.DNN_liar.l_in.shape = (n_batch, self.rnn_units * 2)\n",
    "        # self.DNN_liar.output = (n_batch, self.rnn_units)\n",
    "        self.DNN_liar = DNN_liar.DNNLiar(INPUTS_SIZE = self.rnn_units, LAYER_UNITS = self.liar_setting, INPUTS_PARTS = 1)\n",
    "\n",
    "        # self.alternative_end.shape = self.DNN_liar.output\n",
    "        self.alternative_end = lasagne.layers.get_output(self.DNN_liar.output, {self.DNN_liar.l_in: self.plot_rep})\n",
    "\n",
    "        '''========================================================'''\n",
    "\n",
    "        '''discriminator'''\n",
    "        '''========================================================'''\n",
    "\n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "        l_hid1 = lasagne.layers.DenseLayer(l_concate, num_units = self.classifier_hid1, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "        classifier = lasagne.layers.DenseLayer(l_hid1, num_units=2,\n",
    "                                          nonlinearity=self.score_func_nonlin)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(classifier)\n",
    "\n",
    "        '''========================================================'''\n",
    "        '''               generator training graph                 '''\n",
    "        '''========================================================'''\n",
    "        # euclidien_distance = T.sqrt(T.sum(T.sqr(self.alternative_end - self.plot_rep), axis = 1))\n",
    "\n",
    "        '''========================================================'''\n",
    "        '''                    generating score                    '''\n",
    "        '''========================================================'''\n",
    "\n",
    "        # answer = (2 * srng.uniform((n_batch,))).astype('int64')\n",
    "\n",
    "        # ending_pair_tensor1 = self.train_encodinglayer_vecs[-1] * (1-answer).dimshuffle(0,'x') + self.alternative_end * answer.dimshuffle(0,'x')\n",
    "        # ending_pair_tensor2 = self.train_encodinglayer_vecs[-1] * (answer).dimshuffle(0,'x') + self.alternative_end * (1-answer).dimshuffle(0,'x')\n",
    "        \n",
    "\n",
    "        origi_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.attentioned_end_rep})\n",
    "        alter_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.alternative_end})\n",
    "        \n",
    "        # srng = RandomStreams(seed=234)\n",
    "\n",
    "        # noise_story = srng.normal((self.batchsize, self.rnn_units))\n",
    "        # noise_score = lasagne.layers.get_output(classifier, {l_story_in: noise_story})\n",
    "\n",
    "        '''========================================================'''\n",
    "\n",
    "        vt_2nd_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.vt_2nd_end_repr})\n",
    "\n",
    "        self.test6 = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], [origi_score, alter_score, vt_2nd_score], on_unused_input = 'ignore')\n",
    "\n",
    "        prob1 = lasagne.nonlinearities.softmax(origi_score)\n",
    "        prob2 = lasagne.nonlinearities.softmax(alter_score)\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, T.ones((self.current_Nbatch, )).astype('int64'))\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, T.zeros((self.current_Nbatch, )).astype('int64'))\n",
    "\n",
    "        liar_cost = lasagne.objectives.categorical_crossentropy(prob2, T.ones((self.current_Nbatch, )).astype('int64'))\n",
    "\n",
    "        self.main_cost = lasagne.objectives.aggregate(cost1+cost2, mode = 'mean')\n",
    "        self.liar_cost = lasagne.objectives.aggregate(liar_cost, mode = 'mean')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        main_params = self.encoder.all_params + self.sent_encoder.all_params + final_class_param + [self.bilinear_attention_matrix]\n",
    "\n",
    "\n",
    "        liar_params = self.DNN_liar.all_params\n",
    "\n",
    "        main_updates = None\n",
    "        liar_updates = None\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            main_updates = lasagne.updates.adam(self.main_cost, main_params, learning_rate=self.learning_rate1)\n",
    "\n",
    "            liar_updates = lasagne.updates.adam(self.liar_cost, liar_params, learning_rate=self.learning_rate2)\n",
    "        else:\n",
    "            main_updates = lasagne.updates.momentum(self.main_cost, main_params, learning_rate=self.learning_rate1, momentum=0.9)\n",
    "            liar_updates = lasagne.updates.momentum(self.liar_cost, liar_params, learning_rate=self.learning_rate2, momentum=0.9)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "\n",
    "        # all_updates = []\n",
    "        # for k,v in main_updates.items()+liar_updates.items():\n",
    "        #     all_updates.append((k,v))\n",
    "\n",
    "        # combine two sets of parameters update into a single OrderedDict \n",
    "        self.classifier_train_func = theano.function(self.inputs_variables + self.inputs_masks, \n",
    "                                        [self.main_cost, origi_score, alter_score], updates = main_updates)\n",
    "        self.generator_train_func = theano.function(self.inputs_variables + self.inputs_masks, self.liar_cost, updates = liar_updates, on_unused_input='ignore')\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], [origi_score, vt_2nd_score])\n",
    "\n",
    "        self.adv_monitor = theano.function(self.inputs_variables + self.inputs_masks, self.alternative_end, on_unused_input='ignore')\n",
    "\n",
    "        self.test_end_matrix = T.matrix('test_end', dtype='int64')\n",
    "        self.test_end_mask = T.matrix('test_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "        self.test_end_rep = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.test_end_matrix, \n",
    "                                                    self.encoder.l_mask:self.test_end_mask},\n",
    "                                                    deterministic = True)\n",
    "        check_end_representation = (self.test_end_rep * self.test_end_mask.dimshuffle(0,1,'x')).sum(axis = 1) / self.test_end_mask.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        self.end_rep_check = theano.function([self.test_end_matrix, self.test_end_mask], check_end_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Hierachi_RNN(300, 0.8, 150, 100, '512x256', 0.001, 0.001, 'sgd', 'default', 0, 0.01)\n",
    "a.model_constructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plot = [np.random.randint(5, size=(5,20)).astype('int64') for i in range(4)]\n",
    "plot_mask = [np.ones((5,20)) for i in range(4)]\n",
    "end1 = np.random.randint(5, size=(5,20)).astype('int64')\n",
    "end1_mask = np.ones((5,20))\n",
    "end2 = np.random.randint(5, size=(5,20)).astype('int64')\n",
    "end2_mask = np.ones((5, 20))\n",
    "\n",
    "results = a.test2(plot[0], plot[1], plot[2], plot[3], end1, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask)\n",
    "results[1].shape\n",
    "#, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20, 300)\n"
     ]
    }
   ],
   "source": [
    "result3 = a.test3(end2, end2_mask)\n",
    "print result3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 300)\n"
     ]
    }
   ],
   "source": [
    "result4 = a.test4(plot[0], plot[1], plot[2], plot[3], end1, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask)\n",
    "\n",
    "print result4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5 = a.test5(plot[0], plot[1], plot[2], plot[3], end1, end2, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask)\n",
    "\n",
    "result5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6 = a.prediction(plot[0], plot[1], plot[2], plot[3], end1, end2, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask)\n",
    "result6[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30258509,  0.69314718,  1.60943791])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.9,0.5,0.2])\n",
    "b = np.array([0,1,1])\n",
    "test(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "c = T.mean(a, axis = 1)\n",
    "d = T.sum(a, axis = 1) / T.sum(b, axis = 1).reshape([-1,1])\n",
    "\n",
    "test1 = theano.function([a,b], [c,d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.5,   6.5,   7.5],\n",
       "        [ 17.5,  18.5,  19.5]]),\n",
       " array([[  5.5       ,   6.5       ,   7.5       ],\n",
       "        [ 23.33333333,  24.66666667,  26.        ]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = np.array([[[1,2,3], [4,5,6], [7,8,9], [10,11,12]],[[13,14,15],[16,17,18],[19,20,21],[22,23,24]]])\n",
    "b_1 = np.array([[1,1,1], [2,2,2]])\n",
    "mask_1 = np.array([[1,1,1,1],[1,1,1,0]])\n",
    "test1(a_1, mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BLSTM_sequence\n",
    "import sys\n",
    "# from theano.printing import pydotprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, dropout_rate, batchsize, val_split_ratio, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "\n",
    "        self.train_func = None\n",
    "\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(200, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        # self.mlp_units = [int(elem) for elem in mlp_setting.split('x')]\n",
    "        self.bilinear_matrix = theano.shared(0.002*np.random.rand(self.rnn_units, self.rnn_units)-0.001)\n",
    "        self.dropout_rate = float(dropout_rate)\n",
    "        self.batchsize = int(batchsize)\n",
    "\n",
    "        self.val_split_ratio = float(val_split_ratio)\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.train_encodinglayer_vecs = []\n",
    "        self.test_encodinglayer_vecs = []\n",
    "        self.reasoninglayer_vec1 = []\n",
    "        self.reasoninglayer_vec2 = []\n",
    "        self.reasoninglayer_vec1_test = []\n",
    "        self.reasoninglayer_vec2_test = []\n",
    "        self.reasoning_pool_results = []\n",
    "        self.reasoning_pool_results_test = []\n",
    "        self.reasoners = []\n",
    "        self.attentioned_sent_rep1 = []\n",
    "        self.attentioned_sent_rep2 = []\n",
    "        self.monitor1 = []\n",
    "        self.monitor2 = []\n",
    "        self.attention_moni1 = []\n",
    "        self.attention_moni2 = []\n",
    "        self.softmask_moni = []\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "        \n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent):\n",
    "            self.train_encodinglayer_vecs.append(lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True))\n",
    "        ending1_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[4],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[4]},\n",
    "                                                        deterministic = True)\n",
    "        ending2_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[5],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[5]},\n",
    "                                                        deterministic = True)\n",
    "\n",
    "        l_end_in= lasagne.layers.InputLayer((None, None, self.rnn_units))\n",
    "        l_shuffle = lasagne.layers.DimshuffleLayer(l_end_in, (0,2,1))\n",
    "        l_pooling = lasagne.layers.GlobalPoolLayer(l_shuffle)\n",
    "\n",
    "\n",
    "        end1_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending1_sequence_tensor})\n",
    "        end2_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending2_sequence_tensor})\n",
    "        self.train_encodinglayer_vecs.append(end1_representation)\n",
    "        self.train_encodinglayer_vecs.append(end2_representation)\n",
    "        \n",
    "    def attention_layer(self):        \n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "      \n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention1_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[4])\n",
    "\n",
    "            attention2_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[5])\n",
    "\n",
    "#             softmax_mask = \n",
    "#             self.softmask_moni.append(softmax_mask)\n",
    "            numerator1 = self.inputs_masks[i] * T.exp(attention1_score_tensor - attention1_score_tensor.max(axis = 1, keepdims = True))\n",
    "            numerator2 = self.inputs_masks[i] * T.exp(attention2_score_tensor - attention2_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention1_weight_matrix = numerator1 / numerator1.sum(axis = 1, keepdims = True)\n",
    "            attention2_weight_matrix = numerator2 / numerator2.sum(axis = 1, keepdims = True)\n",
    "#             attention1_weight_matrix = T.nnet.softmax(attention1_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "#             attention2_weight_matrix = T.nnet.softmax(attention2_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "            self.attention_moni1.append(attention1_weight_matrix)\n",
    "            self.attention_moni2.append(attention2_weight_matrix)\n",
    "            \n",
    "            attentioned_sent_seq1 = self.train_encodinglayer_vecs[i]*(attention1_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            attentioned_sent_seq2 = self.train_encodinglayer_vecs[i]*(attention2_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            \n",
    "            self.monitor1.append(attentioned_sent_seq1)\n",
    "            self.monitor2.append(attentioned_sent_seq2)\n",
    "            \n",
    "            attentioned_sent_rep1 = T.sum(attentioned_sent_seq1, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "            attentioned_sent_rep2 = T.sum(attentioned_sent_seq2, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep1.append(attentioned_sent_rep1)\n",
    "            self.attentioned_sent_rep2.append(attentioned_sent_rep2)\n",
    "\n",
    "           \n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        for i in range(self.story_nsent+2):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "\n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units, dropout_rate = self.dropout_rate)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "        self.test0 = theano.function(self.inputs_variables + self.inputs_masks, self.train_encodinglayer_vecs)\n",
    "        #build attention layer\n",
    "        self.attention_layer()\n",
    "        \n",
    "        self.test2 = theano.function(self.inputs_variables + self.inputs_masks, self.monitor1+self.monitor2)\n",
    "        self.test3 = theano.function(self.inputs_variables + self.inputs_masks, self.attention_moni1 + self.attention_moni2)\n",
    "        \n",
    "#         self.test4 = theano.function(self.inputs_masks[:4], self.softmask_moni)\n",
    "        #build reasoning layers\n",
    "        \n",
    "        self.test1 = theano.function(self.inputs_variables + self.inputs_masks, self.attentioned_sent_rep1 + self.attentioned_sent_rep2)\n",
    "        self.merge_ls1 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep1]\n",
    "        self.merge_ls2 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep2]\n",
    "\n",
    "        encode_merge1 = T.concatenate(self.merge_ls1, axis = 1)\n",
    "        encode_merge2 = T.concatenate(self.merge_ls2, axis = 1)\n",
    "\n",
    "        l_in = lasagne.layers.InputLayer(shape=(None, None, self.rnn_units))\n",
    "        gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        b=lasagne.init.Constant(0.))\n",
    "\n",
    "        cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                        W_cell=None, \n",
    "                                                        b=lasagne.init.Constant(0.),\n",
    "                                                        # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        l_lstm = lasagne.layers.recurrent.LSTMLayer(l_in, \n",
    "                                                    num_units=self.rnn_units,\n",
    "                                                    # Here, we supply the gate parameters for each gate \n",
    "                                                    ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                    cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                    # We'll learn the initialization and use gradient clipping \n",
    "                                                    learn_init=True, grad_clipping=100.0)\n",
    "\n",
    "        # The back directional LSTM layers\n",
    "        l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_in,\n",
    "                                                         num_units=self.rnn_units,\n",
    "                                                         ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                         cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                         # We'll learn the initialization and use gradient clipping \n",
    "                                                         learn_init=True,grad_clipping=100.0,\n",
    "                                                         backwards=True)\n",
    "\n",
    "        # Do sum up of bidirectional LSTM results\n",
    "        l_out_right = lasagne.layers.SliceLayer(l_lstm, -1, 1)\n",
    "        l_out_left = lasagne.layers.SliceLayer(l_lstm_back, -1, 1)\n",
    "        l_sum = lasagne.layers.ElemwiseSumLayer([l_out_right, l_out_left])\n",
    "\n",
    "        reasoner_result1 = lasagne.layers.get_output(l_sum, {l_in: encode_merge1}, deterministic = True)\n",
    "        reasoner_result2 = lasagne.layers.get_output(l_sum, {l_in: encode_merge2}, deterministic = True)\n",
    "\n",
    "        reasoner_params = lasagne.layers.get_all_params(l_sum)\n",
    "\n",
    "        # l_story_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        # l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "        #                                   nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        # final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "        \n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "                                          nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "\n",
    "        score1 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-2]})\n",
    "        score2 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result2, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-1]})\n",
    "        self.test5 = theano.function(self.inputs_variables + self.inputs_masks,[score1, score2])\n",
    "        prob1 = lasagne.nonlinearities.softmax(score1)\n",
    "        prob2 = lasagne.nonlinearities.softmax(score2)\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        target1 = T.vector('gold_target1', dtype= 'int64')\n",
    "        target2 = T.vector('gold_target2', dtype= 'int64')\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, target1)\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, target2)\n",
    "\n",
    "        self.cost = lasagne.objectives.aggregate(cost1+cost2, mode='sum')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        all_params = self.encoder.all_params + reasoner_params + final_class_param\n",
    "\n",
    "        all_updates = lasagne.updates.sgd(self.cost, all_params, learning_rate=0.001)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "        updates_exp = [val for key,val in all_updates.items()]\n",
    "        self.test_params = theano.function(self.inputs_variables+self.inputs_masks+[target1, target2], updates_exp, on_unused_input='warn')\n",
    "        self.train_func = theano.function(self.inputs_variables + self.inputs_masks + [target1, target2], \n",
    "                                        [self.cost, prob1, prob2], updates = all_updates)\n",
    "\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + self.inputs_masks, [score1, score2])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a = Hierachi_RNN('300','0.0','20','0.25')\n",
    "a.model_constructor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "targ1 = np.random.randint(2, size=(5,))\n",
    "targ2 = 1 - targ1\n",
    "params = a.train_func(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5], targ1, targ2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7.641996219323214)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score1= a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[28, 54, 37, 81, 45, 85, 43, 30,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 45,  7, 27, 75, 20, 19, 50,  0, 61, 89, 68, 88, 63, 27,  5],\n",
       "        [49, 47, 95, 73, 22, 82, 58, 60, 94, 66,  6, 38, 87, 38, 67,  0],\n",
       "        [57, 51,  4, 97, 44, 47, 61, 35, 10, 62, 92,  0,  0,  0,  0,  0],\n",
       "        [ 1, 61, 44, 99, 33, 92, 71, 81, 57, 10, 59, 26, 39, 91, 66, 29]]),\n",
       " array([[93, 81, 48, 80, 88, 74, 81, 96, 98, 67, 59, 72, 51, 93, 17, 78],\n",
       "        [66, 13, 22, 10, 19, 47, 10, 81, 57, 43, 78, 56, 90, 11, 84,  0],\n",
       "        [ 4, 33, 74, 10, 97,  2,  0, 86, 93, 51, 52,  0,  0,  0,  0,  0],\n",
       "        [19, 22, 74, 43, 85, 97, 49, 46, 80, 95, 72, 18, 13, 13, 48, 48],\n",
       "        [54, 35, 99, 72, 19, 95, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[44, 22, 18, 66, 27, 56,  9, 41,  0, 26, 78, 41, 15, 85,  6,  0],\n",
       "        [ 8, 79, 77, 60,  3, 53, 39, 11, 87, 26, 71,  0,  0,  0,  0,  0],\n",
       "        [ 8, 87, 11, 57, 76, 87, 51, 82, 90, 10, 56, 16, 14, 14, 13, 23],\n",
       "        [10, 22, 44, 56, 18, 77, 78,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 85, 23, 59, 42, 80,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[83, 72, 49, 51, 43, 99, 48, 32, 73, 48, 47,  0,  0,  0,  0,  0],\n",
       "        [33, 38, 62, 10,  5, 16, 12, 60,  8, 69, 49, 17, 45, 84,  1, 36],\n",
       "        [26, 19, 25, 71, 87, 76, 82,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [55, 10, 85, 89, 28,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [72, 64, 34,  6, 91, 51, 79,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[20, 88, 40, 74, 57, 91, 70, 94, 60,  5, 91, 41, 94, 37, 32, 94],\n",
       "        [35, 47, 38, 99, 12, 62,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [17, 22, 96, 89, 43,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [10, 34,  5, 38, 83, 71,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 76, 42, 30, 60, 57, 66, 40, 77, 38, 53, 99, 77, 66, 55,  0]]),\n",
       " array([[14, 36, 71, 12, 30, 81, 64,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [59, 18, 55, 70, 89, 81,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [98, 89, 18, 88,  2,  3, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [41, 29, 38, 55, 69, 44,  3, 43, 31, 85, 42, 72,  4, 32, 89,  0],\n",
       "        [48, 82, 18, 48, 39,  0,  4, 57, 29, 27, 79, 97, 84, 40, 62, 80]])]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "\n",
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "result = a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                 inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  4 55 67 81 81  6 29  0  0  0  0  0  0  0  0]\n",
      " [21 36 34 19 78 49  2 19  0 77 75 74 17  9 19  3]\n",
      " [ 5 29 11 94 21 70 78 10  2  6 98 42 66 28  8  0]\n",
      " [ 3 67 35 72 27 50 47 96 91 89 98  0  0  0  0  0]\n",
      " [44 30 99 88 56 79 69 91 34 33 72 41 28 81 74 33]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[  6.12901829e-04   1.28206219e-02   1.85810721e-02   1.77323277e-03\n",
      "  -1.10088005e-02  -5.78050119e-04   9.91322895e-04   1.83338379e-02\n",
      "  -7.76145479e-03   9.97180350e-03   2.69632479e-03  -1.11936929e-02\n",
      "  -6.97481570e-03   6.67866176e-03  -6.61085645e-04   8.17177092e-03\n",
      "  -8.19279369e-03   1.05830154e-02  -1.43372396e-02  -2.16162561e-03\n",
      "   3.08066795e-03   5.19928999e-03   5.88627218e-04  -7.88304211e-03\n",
      "  -1.46142518e-02   1.33390188e-02  -9.66771911e-03  -1.12186504e-02\n",
      "   3.66041710e-03   9.62523792e-03   1.28240819e-03  -5.20637273e-03\n",
      "  -8.51101042e-03   1.73788929e-03   1.94455368e-02  -1.24445732e-02\n",
      "  -7.50992763e-03  -1.18625974e-02   1.06565481e-02  -8.50607810e-03\n",
      "   9.51179236e-03  -1.27784173e-02   5.83417507e-03   1.72071440e-03\n",
      "  -9.64891977e-03   3.19398294e-03   1.17664811e-03  -9.18265630e-03\n",
      "  -8.65501609e-03  -1.03077354e-02   6.24028133e-03   4.43544259e-03\n",
      "  -2.45638349e-03  -4.25684644e-03   3.18747801e-02  -4.83649828e-05\n",
      "  -2.67939775e-02   9.74076707e-03   1.85942881e-02   1.24826275e-02\n",
      "  -2.17771374e-03  -4.68531558e-03   1.65318610e-02  -7.70148862e-03\n",
      "  -4.53093356e-04   3.14170183e-03   5.68420569e-03   2.06413522e-03\n",
      "   6.46826867e-03   1.39458706e-02   7.86960621e-04   1.44683683e-02\n",
      "  -2.27745902e-03  -1.96257737e-03  -4.98108148e-03   1.09601473e-03\n",
      "   1.15702706e-02  -4.88663669e-04   5.55022096e-03  -2.14605097e-02\n",
      "   1.15699134e-02  -1.11456152e-02   1.79392008e-03  -9.65212770e-04\n",
      "  -4.01781367e-03  -2.66765009e-03   2.26317785e-02   2.62675659e-05\n",
      "  -1.10773527e-02   2.56231139e-02   3.64012285e-03   1.18579518e-03\n",
      "   6.27733309e-03   9.23497631e-03   1.62080369e-02   2.52564406e-02\n",
      "   7.51477522e-03  -2.06253158e-03   7.10767999e-03   1.40570235e-03\n",
      "   6.14302837e-03   1.19155039e-02   7.78394065e-03  -5.90404405e-03\n",
      "   1.82832533e-03   3.23915510e-03   9.65873192e-05  -4.56338311e-03\n",
      "  -7.07014263e-03   1.40139544e-02  -9.51349706e-03  -1.34675806e-02\n",
      "   4.32400248e-03   4.32495517e-03   3.97841646e-03   7.17472132e-03\n",
      "  -1.39945855e-02  -1.68467974e-02  -9.66305075e-03   1.60504493e-02\n",
      "   1.23255507e-03   6.79191690e-03  -2.96179842e-03  -2.38546597e-02\n",
      "  -7.90462629e-03  -1.30571703e-02  -9.85711479e-04   1.10375176e-02\n",
      "   2.34140539e-03   1.69988652e-02   1.65805489e-02  -4.31683382e-03\n",
      "   6.53745632e-03   1.43275687e-02  -1.28447464e-02   1.53071060e-02\n",
      "  -1.51665692e-02  -1.03113224e-02  -3.59152320e-03  -7.34195665e-04\n",
      "   6.31960286e-03   1.13752726e-03  -2.51985425e-03   6.72883109e-03\n",
      "   1.05660976e-02   4.02486207e-03   4.20284436e-03  -6.79560347e-03\n",
      "  -6.66788572e-03  -5.18571887e-03  -5.30564288e-03   7.62538054e-03\n",
      "  -6.82219998e-04  -2.58756882e-02   1.60720733e-02   3.64325227e-03\n",
      "  -1.36926145e-02   8.85965549e-03  -6.08703759e-03  -2.43360334e-03\n",
      "   2.86727818e-02  -1.08768390e-02  -1.10670555e-02   7.06415504e-03\n",
      "   6.29545874e-03   1.67114386e-02   2.66423131e-03   8.70040078e-04\n",
      "  -1.26650183e-02  -1.16223439e-03  -4.61444065e-03   1.12443631e-02\n",
      "  -6.52807044e-03   2.42937622e-04  -1.19337379e-02  -1.99760387e-02\n",
      "   2.54425996e-03  -2.08506154e-03  -2.02432775e-03  -6.02969191e-03\n",
      "   7.65383764e-03  -4.72874181e-03   1.77809952e-02  -1.45806668e-02\n",
      "   1.92331560e-03  -1.64423652e-03   1.51963304e-02   1.02336222e-02\n",
      "   5.04524088e-03   2.43555917e-04  -3.03444673e-03  -4.60696976e-03\n",
      "  -1.04928335e-02  -5.72604887e-03   5.84920778e-03   4.77405925e-03\n",
      "   1.19406516e-02   4.07472596e-03  -1.93495969e-03   1.42278470e-02\n",
      "  -6.40953767e-03  -7.15519049e-03   9.44585834e-03  -3.15805734e-03\n",
      "   1.99132209e-02   1.36058179e-02   3.28401758e-03   9.36933386e-04\n",
      "  -2.77298232e-02   1.75149988e-02  -1.12172287e-02   8.29564100e-03\n",
      "  -1.13648752e-02   1.20745985e-02   1.16299438e-02  -7.76033557e-03\n",
      "   9.58660938e-03  -9.81128668e-03  -7.01891847e-03   1.89040723e-02\n",
      "   6.08100699e-04  -1.55949339e-02   1.47368876e-03   5.40284637e-03\n",
      "   1.08121872e-03  -3.98831696e-03   2.64104700e-03   1.66084846e-02\n",
      "   8.20015834e-03  -1.80545218e-03  -1.52018644e-02   1.25828250e-02\n",
      "   1.04639226e-03   2.18510069e-03  -4.46118589e-03   2.65594848e-03\n",
      "  -1.41341777e-03  -1.02972093e-02   1.12638984e-02  -9.95874766e-04\n",
      "   7.03455949e-03   4.65672125e-03  -1.00189111e-03   1.38683847e-02\n",
      "  -5.79315488e-03  -7.92557103e-03  -6.39303663e-03   1.43947534e-02\n",
      "   7.89221383e-03  -9.02580717e-03   1.41391766e-02   1.13795110e-02\n",
      "   9.97864095e-04   1.92361880e-03   4.65610356e-03   9.56517716e-03\n",
      "  -1.20648781e-02   2.21202066e-03  -7.56610858e-03  -1.59140463e-02\n",
      "   1.47016665e-02  -3.72651362e-03  -1.05129558e-02  -1.15903027e-02\n",
      "   5.47858685e-03  -7.38039301e-03  -1.25416205e-02   5.04812993e-03\n",
      "  -2.50375041e-03  -9.64182127e-03   1.06434698e-02  -9.69211901e-03\n",
      "   9.88548112e-03  -5.84101852e-03  -6.41420916e-03  -2.72472152e-04\n",
      "  -1.03198516e-02  -1.88283584e-05   1.17215420e-02   1.04900717e-02\n",
      "  -1.11961182e-02  -7.96973804e-03  -8.23949385e-03   8.53354294e-03\n",
      "  -1.37106648e-04  -8.38620352e-03  -4.77263147e-03   2.54838106e-04\n",
      "  -3.07033373e-03   6.87926961e-03   1.37273834e-02  -1.32135102e-02\n",
      "   3.76477724e-03  -2.70994728e-03  -1.02458705e-02   6.57407824e-03\n",
      "  -2.17595903e-02  -7.30573375e-03  -1.35557353e-02  -9.36033449e-03]\n"
     ]
    }
   ],
   "source": [
    "print inputs_v[0]\n",
    "print inputs_m[0]\n",
    "print result[0][3][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "IN_ = T.matrix(dtype = 'int64')\n",
    "MASK = T.matrix(dtype = theano.config.floatX)\n",
    "\n",
    "IN = IN_.reshape((IN_.shape[0], IN_.shape[1], 1))\n",
    "\n",
    "wemb = theano.shared(np.random.rand(100, 300))\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, 1))\n",
    "\n",
    "# Masks input shape ==> (n_batch, n_time_steps)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None))\n",
    "\n",
    "#setting gates and cell parameters with specific nonlinearity functions\n",
    "gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                b=lasagne.init.Constant(0.))\n",
    "\n",
    "cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                W_cell=None, \n",
    "                                                b=lasagne.init.Constant(0.),\n",
    "                                                # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "# The embedding layers with retieve subtensor from word embedding matrix\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, input_size=wemb.get_value().shape[0], output_size=wemb.get_value().shape[1], W=wemb)\n",
    "\n",
    "l_drop = lasagne.layers.DropoutLayer(l_emb, p = 0.0)\n",
    "# The LSTM layer should have the same mask input in order to avoid padding entries\n",
    "l_lstm = lasagne.layers.recurrent.LSTMLayer(l_drop, \n",
    "                                            num_units=300,\n",
    "                                            # We need to specify a separate input for masks\n",
    "                                            mask_input=l_mask,\n",
    "                                            # Here, we supply the gate parameters for each gate \n",
    "                                            ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                            cell=cell_parameters, outgate=gate_parameters,\n",
    "                                            # We'll learn the initialization and use gradient clipping \n",
    "                                            learn_init=True\n",
    "                                            )\n",
    "\n",
    "\n",
    "# The back directional LSTM layers\n",
    "l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_drop,\n",
    "                                                 num_units=300,\n",
    "                                                 mask_input = l_mask,\n",
    "                                                 ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                 cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                 # We'll learn the initialization and use gradient clipping \n",
    "                                                 learn_init=True,\n",
    "                                                 backwards=True\n",
    "                                                )\n",
    "\n",
    "\n",
    "# Do sum up of bidirectional LSTM results\n",
    "l_sum = lasagne.layers.ElemwiseSumLayer([l_lstm, l_lstm_back])\n",
    "out = lasagne.layers.get_output(l_sum, {l_in:IN, l_mask:MASK}, deterministic = True)\n",
    "\n",
    "test = theano.function([IN_, MASK], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.41805189e-01   4.65947280e-02  -8.36854174e-02   1.07350674e-01\n",
      "  -2.37396935e-01  -1.79823246e-01   6.51879467e-02   4.60637026e-03\n",
      "  -2.09297061e-01  -1.59060352e-01   2.93781539e-01   2.85348498e-01\n",
      "   8.93948845e-02   5.16647735e-02  -6.63083297e-01  -3.32605698e-01\n",
      "  -2.13643046e-01  -2.52780222e-02   3.30183841e-01  -1.86089749e-01\n",
      "   2.64025800e-01   1.07492811e-01   5.57596003e-02  -4.45173354e-01\n",
      "  -1.89919893e-01   1.83129174e-01   1.55992846e-01   6.95604518e-02\n",
      "   2.86514647e-01  -4.01425141e-01  -3.06143785e-02  -2.88565510e-01\n",
      "  -6.13725809e-01  -1.95180382e-01  -2.38842957e-01  -2.73882412e-01\n",
      "  -1.94990750e-02   1.82266075e-01  -2.67372722e-02   1.89460599e-01\n",
      "  -3.17284749e-01   1.24459833e-01   1.97643377e-02  -4.07787518e-02\n",
      "   1.33853864e-01  -1.82464355e-01   8.99734217e-02   3.00601495e-01\n",
      "   1.07841359e-01   1.00602480e-01  -1.10121118e-01  -1.49100513e-01\n",
      "   4.55662451e-02   3.19698477e-01  -2.52166452e-01  -5.48263467e-02\n",
      "  -1.66052223e-01   2.32730964e-01   2.44532437e-01   2.88979955e-02\n",
      "  -1.54972644e-01   3.11617652e-02  -2.86030581e-01  -1.80347307e-01\n",
      "  -5.80585754e-03  -3.50427965e-01  -2.00044557e-01  -2.23736678e-01\n",
      "   3.44473783e-01  -1.16633545e-01   1.20076037e-01   1.64516287e-01\n",
      "  -3.76728337e-02   1.43556057e-01  -2.14316441e-01   3.13081906e-02\n",
      "  -1.81261681e-01   2.59679044e-01   6.83491469e-02   3.15903151e-01\n",
      "   1.42963854e-01  -4.82822922e-02   3.07992117e-02   8.36729715e-02\n",
      "  -2.20836098e-01   1.08064683e-01  -3.52158981e-01   6.33299526e-02\n",
      "   5.38521374e-02   1.26293333e-01  -1.51400991e-01  -1.73199360e-01\n",
      "   4.93580934e-02   9.74224017e-02  -1.90682080e-01  -1.18575519e-01\n",
      "  -6.88681518e-02   2.02876577e-01   6.42778192e-02  -3.59663086e-01\n",
      "  -1.61170709e-01   2.73048496e-01   3.04291984e-01  -5.47830130e-02\n",
      "   3.80496389e-02   1.29263373e-01  -1.41486884e-01   4.22245969e-01\n",
      "   3.45574460e-01  -1.32493562e-01  -4.02829865e-01  -1.19528884e-01\n",
      "  -1.18042623e-01   1.17232048e-01  -1.19601572e-01  -1.17724887e-01\n",
      "  -2.09025329e-02  -1.03244352e-02  -2.28599887e-04  -2.17391905e-01\n",
      "   1.20204521e-01   6.17174912e-02   2.30203500e-01  -1.38244054e-01\n",
      "   4.94981929e-02   2.18195071e-01  -2.12267096e-01  -1.88235632e-01\n",
      "   4.21086305e-02  -2.39597071e-01   1.73129334e-02   1.25530104e-01\n",
      "   9.64885552e-02   1.03689624e-01   1.17677763e-01  -1.42404896e-01\n",
      "   3.03548037e-01   3.59071841e-01  -1.43170138e-01  -1.45115828e-01\n",
      "   1.31757523e-01  -1.50814769e-02  -3.40939391e-01  -1.83105860e-02\n",
      "  -4.58525958e-01  -7.63787368e-03   2.66319285e-01  -1.84122525e-01\n",
      "   9.95186823e-02  -1.29188925e-01   2.43182762e-01   3.90279821e-02\n",
      "   1.40789155e-01   2.02716717e-01  -4.32419332e-04  -2.22346982e-01\n",
      "  -8.41890580e-02   1.87262149e-01  -5.17058521e-02   1.75941274e-01\n",
      "  -6.09538677e-03   1.42833704e-01  -1.31358050e-01  -1.12612377e-01\n",
      "   8.57445285e-02   1.66430535e-01   2.43428334e-01  -1.03569232e-01\n",
      "   1.99629578e-01   4.40311666e-01   5.33493546e-02  -7.20940593e-03\n",
      "   1.90127928e-01   2.48668682e-01  -6.49166649e-02   4.41358638e-02\n",
      "   8.76208976e-02   3.78786052e-01   2.18508988e-01  -3.75633042e-02\n",
      "   2.85975905e-02   2.19808020e-01   2.47440780e-01  -2.58754165e-01\n",
      "   2.94155414e-01  -8.21444917e-02  -1.16559695e-01   1.00147221e-01\n",
      "  -1.00013320e-01  -3.05407031e-01  -3.54175547e-02  -1.88286286e-01\n",
      "   1.31801810e-01  -2.50033897e-01  -3.64544650e-01  -1.92514940e-01\n",
      "  -2.20179670e-01   6.71782634e-02  -1.91986005e-01   8.99862525e-02\n",
      "   4.58506849e-02  -3.21618118e-01   1.27360550e-01  -5.78044083e-02\n",
      "  -2.46030986e-01   2.14993254e-01   4.92059966e-01  -2.24785879e-01\n",
      "   1.54586488e-02  -1.07244769e-01   1.34986476e-01   1.35231754e-01\n",
      "   2.63036715e-01  -1.32974960e-01  -2.19755114e-01  -2.90404075e-01\n",
      "   1.88962878e-01   2.57108608e-01   1.59051415e-01   6.40235904e-01\n",
      "  -8.81937500e-02   2.83615642e-01   2.79403292e-01  -1.40605716e-01\n",
      "  -1.35850237e-01   1.16606192e-01  -1.90442652e-01  -8.30214388e-02\n",
      "  -1.62195090e-01  -3.84474590e-03   3.35333647e-01   1.17424547e-01\n",
      "  -1.20708468e-01   2.80735464e-02   9.40222540e-02   7.45179891e-02\n",
      "  -1.92942886e-01   6.96951262e-03   2.33246674e-01   3.22433086e-01\n",
      "  -2.32097845e-01   1.67652782e-01  -7.95807504e-01  -2.43798434e-01\n",
      "   3.55652130e-01   4.94266208e-02  -2.10341914e-01   5.86849788e-02\n",
      "  -3.29640513e-02   2.18896708e-01  -3.64652703e-01  -9.67156222e-02\n",
      "   9.51957111e-02   3.68453550e-01   1.62654674e-01   2.12130387e-01\n",
      "  -4.76252094e-03   2.39174365e-01  -4.83751075e-02   1.95502159e-01\n",
      "   2.20471606e-01  -2.59043233e-01   1.10918691e-01   1.01299499e-01\n",
      "   1.67898083e-02   9.50671082e-02   7.92833124e-02   9.29138265e-02\n",
      "  -9.03090968e-02  -1.59619268e-02   3.25049892e-01  -8.55021027e-02\n",
      "  -1.25485420e-01  -2.75248046e-01  -1.31954432e-01  -6.11103789e-02\n",
      "  -1.85230646e-01   2.45496488e-01  -2.40795010e-01  -4.03117173e-01\n",
      "   5.85117944e-02  -2.81123249e-01  -2.09622975e-01  -1.48278290e-01\n",
      "   7.75883161e-02   6.81594361e-02  -8.07407569e-02  -6.23219426e-02\n",
      "   6.91475017e-02   2.72539457e-02  -1.36219491e-01  -1.29714907e-01\n",
      "   1.23861649e-01  -8.22218655e-02  -1.64528626e-01   1.89155404e-01\n",
      "  -1.06625821e-01   6.45507821e-02   2.63013033e-01  -2.77682583e-02]\n"
     ]
    }
   ],
   "source": [
    "result = test(inputs_v[5], inputs_m[5])\n",
    "print result[4][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "\n",
    "b = T.sum(a, axis = 1).reshape([-1,1])\n",
    "\n",
    "c = T.matrix()\n",
    "d = c / b\n",
    "test = theano.function([a,c], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1.5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(np.array([[1,1]]), np.array([[3,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "\n",
    "b = theano.shared\n",
    "a_ = a.reshape((-1, a.shape[2]))\n",
    "b_ = b.reshape((1,b.shape[0],b.shape[1]))\n",
    "b_f = b_ + T.zeros((a_.shape[0], b.shape[0], b.shape[1]))\n",
    "result = T.batched_dot(a_, b_f).reshape((a.shape[0], a.shape[1], -1))\n",
    "loss = result.sum()\n",
    "\n",
    "test = theano.function([a,b], result)\n",
    "train  = theano.function([a,b], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-54a9fa44f2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "a_test = np.arange(3*4*5).reshape((3,4,5))\n",
    "\n",
    "b_test = np.arange(5*5).reshape((5,5))\n",
    "\n",
    "testing = test(a_test, b_test)\n",
    "print testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "loss = T.batched_dot(a, b)\n",
    "test = theano.function([a,b], loss)\n",
    "# test = theano.function([inp], loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]\n",
      "  [30 31 32 33 34]\n",
      "  [35 36 37 38 39]]\n",
      "\n",
      " [[40 41 42 43 44]\n",
      "  [45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   30.,    80.,   130.,   180.],\n",
       "       [  780.,   955.,  1130.,  1305.],\n",
       "       [ 2530.,  2830.,  3130.,  3430.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test = np.arange(3*4*5).reshape((3,4,5))\n",
    "b_test = np.arange(3*5).reshape((3,5))\n",
    "print a_test\n",
    "print b_test\n",
    "test(a_test, b_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.tensor3()\n",
    "\n",
    "b_ = b.dimshuffle(0,2,1)\n",
    "a_ = a[0]\n",
    "test1 = theano.function([a], a_)\n",
    "c_ls, _ = theano.scan(lambda i:T.batched_dot(a[i], b_[i]), sequences=[T.arange(a.shape[0])])\n",
    "test = theano.function([a,b], c_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,2,3,3])\n",
    "c = np.all(a-b==0)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   1.   2.   3.   4.]\n",
      "  [  5.   6.   7.   8.   9.]\n",
      "  [ 10.  11.  12.  13.  14.]\n",
      "  [ 15.  16.  17.  18.  19.]]\n",
      "\n",
      " [[ 20.  21.  22.  23.  24.]\n",
      "  [ 25.  26.  27.  28.  29.]\n",
      "  [ 30.  31.  32.  33.  34.]\n",
      "  [ 35.  36.  37.  38.  39.]]\n",
      "\n",
      " [[ 40.  41.  42.  43.  44.]\n",
      "  [ 45.  46.  47.  48.  49.]\n",
      "  [ 50.  51.  52.  53.  54.]\n",
      "  [ 55.  56.  57.  58.  59.]]]\n",
      "[[  0.   1.   2.   3.   4.]\n",
      " [  5.   6.   7.   8.   9.]\n",
      " [ 10.  11.  12.  13.  14.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   30.,    80.,   130.,   180.],\n",
       "       [  780.,   955.,  1130.,  1305.],\n",
       "       [ 2530.,  2830.,  3130.,  3430.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(3 * 4 * 5).reshape(3, 4, 5).astype('float32')\n",
    "b = np.arange(3 * 5).reshape(3, 5).astype('float32')\n",
    "\n",
    "A = T.ftensor3()\n",
    "B = T.fmatrix()\n",
    "\n",
    "# out1 = T.tensordot(A,B)\n",
    "out = (A * B.dimshuffle(0, 'x', 1)).sum(2)\n",
    "print a\n",
    "print b\n",
    "out.eval({A: a, B: b})\n",
    "# out1.eval({A:a, B:b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "a_ = T.nnet.softmax(a)\n",
    "b = T.imatrix()\n",
    "\n",
    "c = lasagne.objectives.categorical_crossentropy(a_, b)\n",
    "test = theano.function([a, b], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "dictionary = pickle.load(open('../../data/pickles/index_wemb_matrix.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.matrix()\n",
    "\n",
    "e_x = x.max(axis=1, keepdims=True)\n",
    "\n",
    "test = theano.function([x], e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import numpy as np\n",
    "wemb = theano.shared(np.arange(100*5).reshape(100,5))\n",
    "a = T.matrix()\n",
    "\n",
    "b = T.iscalar()\n",
    "\n",
    "c = T.arange(b)\n",
    "\n",
    "d = T.set_subtensor(a[c], wemb[c])\n",
    "\n",
    "test = theano.function([a,b], [a,d])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.]]), array([[  0.,   1.,   2.,   3.,   4.],\n",
       "        [  5.,   6.,   7.,   8.,   9.],\n",
       "        [ 10.,  11.,  12.,  13.,  14.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test = np.ones((7,5))\n",
    "b = 3\n",
    "test(a_test, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "aa = T.iscalar()\n",
    "substi_word_index = (2 * srng.uniform((aa, ))).astype('int64')\n",
    "test = theano.function([aa], substi_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BLSTM_sequence\n",
    "import BLSTM_last\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, batchsize, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "\n",
    "        self.train_func = None\n",
    "\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(300, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "        self.train_set_path = '../../data/pickles/train_index_corpus.pkl'\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        # self.mlp_units = [int(elem) for elem in mlp_setting.split('x')]\n",
    "        self.bilinear_matrix = theano.shared(0.002*np.random.rand(self.rnn_units, self.rnn_units)-0.001)\n",
    "        # self.dropout_rate = float(dropout_rate)\n",
    "        self.batchsize = int(batchsize)\n",
    "\n",
    "        # self.val_split_ratio = float(val_split_ratio)\n",
    "        self.words_num = 100\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.train_encodinglayer_vecs = []\n",
    "        self.test_encodinglayer_vecs = []\n",
    "        self.reasoninglayer_vec1 = []\n",
    "        self.reasoninglayer_vec2 = []\n",
    "        self.reasoninglayer_vec1_test = []\n",
    "        self.reasoninglayer_vec2_test = []\n",
    "        self.reasoning_pool_results = []\n",
    "        self.reasoning_pool_results_test = []\n",
    "        self.reasoners = []\n",
    "        self.attentioned_sent_rep1 = []\n",
    "        self.attentioned_sent_rep2 = []\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent + 1):\n",
    "            self.train_encodinglayer_vecs.append(lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True))\n",
    "\n",
    "\n",
    "        end_representation = (self.train_encodinglayer_vecs[-1] * self.inputs_masks[4].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[4].sum(axis = 1, keepdims = True)\n",
    "\n",
    "        #The last one (index-5) is the average of the non-attentioned ending sequence\n",
    "        self.train_encodinglayer_vecs.append(end_representation)\n",
    "        \n",
    "    def attention1_layer(self):        \n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "            #second attention\n",
    "\n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention1_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[5])\n",
    "\n",
    "            numerator1 = self.inputs_masks[i] * T.exp(attention1_score_tensor - attention1_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention1_weight_matrix = numerator1 / numerator1.sum(axis = 1, keepdims = True)\n",
    "\n",
    "            attentioned_sent_seq1 = self.train_encodinglayer_vecs[i]*(attention1_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "            attentioned_sent_rep1 = T.sum(attentioned_sent_seq1, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep1.append(attentioned_sent_rep1)\n",
    "\n",
    "    def attention2_layer(self):\n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "            #second attention\n",
    "\n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention2_score_tensor = T.batched_dot(bili_part1, self.vt_2nd_end_repr)\n",
    "\n",
    "            numerator2 = self.inputs_masks[i] * T.exp(attention2_score_tensor - attention2_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention2_weight_matrix = numerator2 / numerator2.sum(axis = 1, keepdims = True)\n",
    "\n",
    "            attentioned_sent_seq2 = self.train_encodinglayer_vecs[i]*(attention2_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "            attentioned_sent_rep2 = T.sum(attentioned_sent_seq2, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep2.append(attentioned_sent_rep2)\n",
    "           \n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        self.vt_2nd_end = T.matrix('second_end', dtype='int64')\n",
    "        self.vt_2nd_end_mask = T.matrix('second_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "        for i in range(self.story_nsent+1):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "\n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "\n",
    "        '''============================================================================'''\n",
    "        #encode possible second ending\n",
    "        self.encode_2nd_end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.vt_2nd_end, \n",
    "                                                     self.encoder.l_mask:self.vt_2nd_end_mask},\n",
    "                                                     deterministic = True)\n",
    "\n",
    "        self.vt_2nd_end_repr = (self.encode_2nd_end_seq * self.vt_2nd_end_mask.dimshuffle(0,1,'x')).sum(axis = 1) / self.vt_2nd_end_mask.sum(axis = 1, keepdims = True)\n",
    "        '''============================================================================'''\n",
    "\n",
    "        #build attention layer\n",
    "        self.attention1_layer()\n",
    "        self.attention2_layer()\n",
    "        #build reasoning layers\n",
    "        \n",
    "        self.test1 = theano.function(self.inputs_variables + self.inputs_masks, self.train_encodinglayer_vecs[5], on_unused_input='ignore')\n",
    "        # merge tensors to fit in BLSTM models as input tensor\n",
    "        # merge_ls1.shape = (n_batch, m_seq, self.rnn_units)\n",
    "        self.merge_ls1 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep1]\n",
    "        self.merge_ls2 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep2]\n",
    "        encode_merge1 = T.concatenate(self.merge_ls1, axis = 1)\n",
    "        encode_merge2 = T.concatenate(self.merge_ls2, axis = 1)\n",
    "        self.test2 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [encode_merge1, encode_merge2])\n",
    "        # create sentence level encoder\n",
    "        # using only last encoding result of both direction of the LSTM\n",
    "        self.sent_encoder = BLSTM_last.BlstmEncoder(INPUT_SIZE = self.rnn_units, LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.sent_encoder.build_model()\n",
    "\n",
    "        # reasoner_result1.shape = (n_batch, self.rnn_units)\n",
    "        reasoner_result1 = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge1}, \n",
    "                                                    deterministic = True)\n",
    "\n",
    "        reasoner_result2 = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge2}, \n",
    "                                                    deterministic = True)\n",
    "        self.test3 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [reasoner_result1, reasoner_result2])\n",
    "        # self.train_encodinglayer_vecs[4].shape == (n_batch, m_seq, 300)\n",
    "        end_attention_part1 = T.dot(self.train_encodinglayer_vecs[4], self.bilinear_attention_matrix)\n",
    "        end_attention = T.batched_dot(end_attention_part1, reasoner_result1)\n",
    "\n",
    "\n",
    "        end_att_numerator1 = self.inputs_masks[4] * T.exp(end_attention - end_attention.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        end_attention_weight_matrix = end_att_numerator1 / end_att_numerator1.sum(axis = 1, keepdims = True)\n",
    "        self.test3_1 = theano.function(self.inputs_variables + self.inputs_masks, end_attention_weight_matrix)\n",
    "        # end_attention_weight_matrix.shape = (n_batch, m_seq)\n",
    "        # neg_ending_rep.shape == (n_batc, m_seq)\n",
    "        # neg_ending_subs_index is the one to be substituted in the original sentence\n",
    "        neg_ending_subs_index = T.argmax(end_attention_weight_matrix, axis = 1)\n",
    "        n_batch = self.train_encodinglayer_vecs[0].shape[0]\n",
    "\n",
    "        # substi_word_index is the random index generate to surrogate the original ones\n",
    "        srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "        substi_word_index = (self.words_num * srng.uniform((n_batch, ))).astype('int64')\n",
    "        self.test3_2 = theano.function(self.inputs_variables + self.inputs_masks, substi_word_index, on_unused_input = 'ignore')\n",
    "        batch_dim = T.arange(n_batch)\n",
    "        self.test3_3 = theano.function(self.inputs_variables + self.inputs_masks, batch_dim, on_unused_input = 'ignore')\n",
    "        # set_subtensor won't change the original tensor\n",
    "        # new_end_seq_tensor.shape = (self.batchsize, m_seq, 300)\n",
    "        new_end_seq_tensor = T.set_subtensor(self.train_encodinglayer_vecs[4][batch_dim, neg_ending_subs_index], self.wemb[substi_word_index])\n",
    "        # neg_end_rep.shape = (self.batchsize, self.rnn_units)\n",
    "        self.test3_4 = theano.function(self.inputs_variables + self.inputs_masks, new_end_seq_tensor)\n",
    "        neg_end_rep = (new_end_seq_tensor * self.inputs_masks[4].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[4].sum(axis = 1, keepdims = True)\n",
    "        self.test4 = theano.function(self.inputs_variables + self.inputs_masks, neg_end_rep)\n",
    "        \n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "        \n",
    "        l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "                                          nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "        answer = (2 * srng.uniform((n_batch,))).astype('int64')\n",
    "\n",
    "        ending_pair_tensor1 = self.train_encodinglayer_vecs[-1] * (1-answer).dimshuffle(0,'x') + neg_end_rep * answer.dimshuffle(0,'x')\n",
    "        ending_pair_tensor2 = self.train_encodinglayer_vecs[-1] * (answer).dimshuffle(0,'x') + neg_end_rep * (1-answer).dimshuffle(0,'x')\n",
    "        self.test5 = theano.function(self.inputs_variables + self.inputs_masks, [ending_pair_tensor1, ending_pair_tensor2])\n",
    "\n",
    "        score1 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: ending_pair_tensor1})\n",
    "        score2 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: ending_pair_tensor2})\n",
    "\n",
    "        vt_2nd_score = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result2, \n",
    "                                                   l_end_in: self.vt_2nd_end_repr})\n",
    "        self.test6 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [score1, score2, vt_2nd_score])\n",
    "\n",
    "\n",
    "        prob1 = lasagne.nonlinearities.softmax(score1)\n",
    "        prob2 = lasagne.nonlinearities.softmax(score2)\n",
    "\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, answer)\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, 1-answer)\n",
    "\n",
    "        self.cost = lasagne.objectives.aggregate(cost1+cost2, mode='sum')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        all_params = self.encoder.all_params + self.sent_encoder.all_params + final_class_param + [self.bilinear_attention_matrix]\n",
    "\n",
    "        all_updates = lasagne.updates.adam(self.cost, all_params, learning_rate=0.001)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "\n",
    "        self.train_func = theano.function(self.inputs_variables + self.inputs_masks, \n",
    "                                        [self.cost, prob1, prob2, answer], updates = all_updates)\n",
    "\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [score1, vt_2nd_score])\n",
    "        # pydotprint(self.train_func, './computational_graph.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Hierachi_RNN(rnn_setting = '300', batchsize = '20')\n",
    "\n",
    "a.model_constructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "\n",
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "result = a.test3_4(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4],\n",
    "                 inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one line cases\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "test_inputs = [np.random.randint(100, size=(1,leng_v[j])) for i in range(6) for j in range(6)]\n",
    "\n",
    "test_masks = [np.ones_like(sent) for sent in test_inputs]\n",
    "\n",
    "result = a.test3_4(test_inputs[0],test_inputs[1],test_inputs[2],test_inputs[3],test_inputs[4],\n",
    "                test_masks[0], test_masks[1], test_masks[2], test_masks[3],test_masks[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 300)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "n_batch = a.shape[0]\n",
    "neg_ending_subs_index = T.ivector()\n",
    "srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "substi_word_index = (100 * srng.uniform((1, n_batch))).astype('int64')\n",
    "batch_dim = T.arange(n_batch)\n",
    "wemb = theano.shared(np.arange(100*5).reshape(100,5))\n",
    "\n",
    "new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n",
    "\n",
    "test1 = theano.function([a, neg_ending_subs_index], new_end_seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array is not broadcastable to correct shape\nApply node that caused the error: AdvancedIncSubtensor1{inplace,set}(AdvancedSubtensor1.0, Reshape{3}.0, <TensorType(int32, vector)>)\nToposort index: 12\nInputs types: [TensorType(float64, 3D), TensorType(int64, (True, False, False)), TensorType(int32, vector)]\nInputs shapes: [(7, 8, 5), (1, 7, 5), (7,)]\nInputs strides: [(320, 40, 8), (280, 40, 8), (4,)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-d77298e604ac>\", line 9, in <module>\n    new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a69ae3bd09b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtensorA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msub_index_ls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_index_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array is not broadcastable to correct shape\nApply node that caused the error: AdvancedIncSubtensor1{inplace,set}(AdvancedSubtensor1.0, Reshape{3}.0, <TensorType(int32, vector)>)\nToposort index: 12\nInputs types: [TensorType(float64, 3D), TensorType(int64, (True, False, False)), TensorType(int32, vector)]\nInputs shapes: [(7, 8, 5), (1, 7, 5), (7,)]\nInputs strides: [(320, 40, 8), (280, 40, 8), (4,)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-d77298e604ac>\", line 9, in <module>\n    new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "tensorA = np.random.rand(7, 8, 5)\n",
    "sub_index_ls = np.asarray([2,6,4,3,2,2,0]).astype('int32')\n",
    "result = test1(tensorA, sub_index_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.ivector()\n",
    "c = T.ivector()\n",
    "d = T.ivector()\n",
    "e = theano.shared(np.random.rand(100, 5))\n",
    "\n",
    "f = T.set_subtensor(a[b,c], e[d])\n",
    "test = theano.function([a,b,c,d], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_ = np.arange(6*15*5).reshape(6,15,5)\n",
    "b_ = np.arange(6).astype('int32')\n",
    "c_ = np.random.randint(15, size=(6,)).astype('int32')\n",
    "d_ = np.random.randint(100, size=(6,)).astype('int32')\n",
    "result = test(a_, b_, c_, d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  0  0 14 14  5]\n",
      "[62 69 37 24 60 33]\n"
     ]
    }
   ],
   "source": [
    "print c_\n",
    "print d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3669229 ,  0.0759273 ,  0.34172383,  0.78630821,  0.60700849])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "index2word_dic = pickle.load(open('../../data/pickles/ROC_train_index_dict.pkl'))\n",
    "\n",
    "wemb_matrix = pickle.load(open('../../data/pickles/index_wemb_matrix.pkl'))\n",
    "\n",
    "train_set = pickle.load(open('../../data/pickles/train_index_corpus.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Title + story plot \n",
    "import numpy as np\n",
    "\n",
    "story_set = np.asarray(train_set[0])\n",
    "\n",
    "story_n = len(end_set)\n",
    "story_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    story_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k][j]] for j in range(len(story_set[i][k]))) for k in range(5))/5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# story plot \n",
    "\n",
    "story_set = np.asarray(train_set[0])\n",
    "\n",
    "story_n = len(end_set)\n",
    "storyplot_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    storyplot_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k][j]] for j in range(len(story_set[i][k]))) for k in range(1, 5))/4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "end_set = np.asarray(train_set[1])\n",
    "\n",
    "story_n = len(end_set)\n",
    "end_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    end_rep_matrix[i] = np.sum(wemb_matrix[end_set[i]], axis = 0)/(len(end_set[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2]),\n",
       " array([3, 4, 5, 6, 1, 7]),\n",
       " array([ 3,  8,  1,  9, 10,  7]),\n",
       " array([11, 12, 13, 14,  5, 15,  8, 16,  7]),\n",
       " array([14,  5, 17, 18, 19, 20, 21, 22, 23,  7]),\n",
       " array([24, 25, 26, 18,  3, 27, 22, 28,  7])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# story plot + ending\n",
    "\n",
    "\n",
    "story_set = new_train_set\n",
    "\n",
    "story_n = len(end_set)\n",
    "storyplotNend_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    storyplotNend_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k]],axis = 0) for k in range(1,6))/5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_simi(rep_matrix, story_n):    \n",
    "    normalized_matrix_vec = np.linalg.norm(rep_matrix, axis = 1)\n",
    "\n",
    "\n",
    "    most_similar_pair = np.zeros((story_n, 1))\n",
    "    for i in range(story_n):\n",
    "        dot_vec = np.dot(rep_matrix[i], rep_matrix.T)\n",
    "        norm_vec = np.asarray([normalized_matrix_vec[i] * normalized_matrix_vec[j] for j in range(story_n)])\n",
    "        cos_vec = dot_vec / norm_vec\n",
    "        most_similar_pair[i] = np.argsort(cos_vec)[-2]\n",
    "    return most_similar_pair\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,34]).reshape(-1,1)\n",
    "b = np.array([1,2,33]).reshape(-1,1)\n",
    "\n",
    "c = np.dot(a,b.T)\n",
    "d = np.argmax(c, axis = 0)\n",
    "print d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_simi_story_pair = cos_simi(story_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_simi_storyplot_pair = cos_simi(storyplot_rep_matrix, story_n)\n",
    "most_simi_end_pair = cos_simi(end_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_simi_storyplotNend_pair = cos_simi(storyplotNend_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle.dump(most_simi_story_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_story_pair.pkl', 'w'))\n",
    "pickle.dump(most_simi_storyplot_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_storyplot_pair.pkl','w'))\n",
    "pickle.dump(most_simi_end_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_end_pair.pkl','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(most_simi_storyplotNend_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_storyplotNend_pair.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert(nump_matrix):\n",
    "    return nump_matrix.reshape(-1,).astype('int32')\n",
    "\n",
    "most_simi_end_pair = convert(most_simi_end_pair)\n",
    "most_simi_story_pair = convert(most_simi_story_pair)\n",
    "most_simi_storyplot_pair = convert(most_simi_storyplot_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_simi_storyPNend_pair = convert(most_simi_storyplotNend_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3665,   899, 11902, 10411, 18049, 32872, 23746,  4604, 15949, 34794], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_storyPNend_pair[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance # 0\n",
      "dental adventures | one day , sally was eating nuts and heard a crack . | she had bitten into a shell and cracked her tooth ! | the tooth hurt very badly . | she called her dentist . | the dentist saw her later that day and fixed her tooth .\n",
      "==================most similar end pairs====================\n",
      "loose tooth | tricia had a loose tooth . | she was eating her cereal one morning . | her tooth was hanging on by just a little bit . | tricia bit into something hard . | she realized her tooth had come out in her cereal .\n",
      "\n",
      "instance # 1\n",
      "meeting an old friend | i recently met an old friend . | i accompanied him while he ran various errands . | we went to his job , his house , and a thrift shop . | i quite enjoyed playing around in the thrift shop . | the day wasn 't exciting , but i enjoyed my friend 's company .\n",
      "==================most similar end pairs====================\n",
      "keeping lips closed | i was walking to the local coffee shop . | as soon as i looked around , i can into my friend don . | he was kissing another female other than his wife . | he saw me in the shop and begged me not to tell anyone . | since we 're close friends , i kept his promise .\n",
      "\n",
      "instance # 2\n",
      "michelle 's first job | michelle wanted to work at a clothing store . | she applied to many clothing stores in her town . | michelle went to a couple of interviews . | her top choice called her a week later to hire her . | michelle was so excited to start working at her new job !\n",
      "==================most similar end pairs====================\n",
      "the interview | lexi just turned 16 . | she wanted to get a part time job to earn some money . | she went from store to store in the mall . | at her fifth stop they wanted to interview her immediately . | she was hired on the spot at a jewelry store .\n",
      "\n",
      "instance # 3\n",
      "tim and the bully . | tim got picked on at school by a bully . | every day the bully would pull his hair . | tim told the teacher , but that just made the bully more upset . | tim decided to stick with a large group of friends . | the bully never picked on him again .\n",
      "==================most similar end pairs====================\n",
      "tiny tim | tim was very tiny for his age and got bullied . | he was very fed up with his bully and decided to confront him . | the bully just laughed because tim was so small . | but tim used his arms to trip up the bully 's long legs . | the bully fell hard and never messed with tim again .\n",
      "\n",
      "instance # 4\n",
      "down the street | jackson and gloria were childhood friends . | they had grown up on the same street . | they had attended 12 consecutive years of school together . | then jackson 's family moved out of the state . | they never spoke again .\n",
      "==================most similar end pairs====================\n",
      "reconnecting | bonnie hadn 't seen her high school boyfriend in years . | at their ten year reunion they talked all night . | they were both still single . | they got together and started dating again . | they were married the following year .\n",
      "\n",
      "instance # 5\n",
      "broken phone | the other day i was talking on my cell phone to my friend . | while walking through the house , the phone slipped out of my hand . | the phone dropped and shattered . | i was upset because i loved the phone . | luckily it had a protector on it so it was okay .\n",
      "==================most similar end pairs====================\n",
      "pool jump | i was in my friend 's backyard by a pool . | i put on a silly voice and jumped into the pool . | after jumping in , i remembered that i left my phone in my pocket . | i climbed out of the water to check on my phone , but it was broken . | i had to leave my friend 's house to get a new phone .\n",
      "\n",
      "instance # 6\n",
      "guns | joe was afraid of guns . | one day his uncle took him to a shooting range . | he taught him how to shoot the gun . | but the gun had a huge recoil and flew out of his hand ! | joe is now even more afraid of guns .\n",
      "==================most similar end pairs====================\n",
      "gun jam | hank drove to the shooting range with his guns one day . | he walked up the targets with his guns . | just as he prepared to shoot , his gun became jammed . | hank spent over an hour trying to fix the gun . | he eventually gave up and used a different gun , then went home .\n",
      "\n",
      "instance # 7\n",
      "the hard way | two women decided to race to the top of a mountain . | the first woman meticulously planned her climb . | she charted out her route with great care . | when she arrived at the summit , she found that she had been beaten . | the other woman had taken the ski lift .\n",
      "==================most similar end pairs====================\n",
      "losing the competition . | alison had entered her painting into a contest . | she had made it all the way to nationals . | there , her painting was in the top ten . | she was waiting to see if she would win . | unfortunately , she only got third place .\n",
      "\n",
      "instance # 8\n",
      "ring ring | i called the insurance company . | i needed to find a new doctor . | the woman on the phone said i wasn 't a member . | i was at a loss for words . | it took her five minutes to realize she had entered my number wrong .\n",
      "==================most similar end pairs====================\n",
      "first car accident | i had just gotten a new job as a swim coach the day before . | on the second day of practice , i decided to take a new way to work . | while stopping , i noticed a man behind me who was not stopping . | the man ran into the back of my car like i wasn 't even there . | no one was hurt but my bank account .\n",
      "\n",
      "instance # 9\n",
      "recess mishap | joey fell off the jungle gym during recess . | the nurse called his mom to pick joey up . | joey 's mom brought him to the doctor . | the doctor had to put a cast on joey 's broken wrist . | the next day , joey let his classmates sign his cast .\n",
      "==================most similar end pairs====================\n",
      "baseball injury | jake was playing catch with his dad . | jake threw a baseball for his dad to catch . | his dad missed , and the baseball hit him right in the face . | jake got his father some ice to put on his face after . | his dad had to miss work the very next day .\n",
      "\n",
      "instance # 10\n",
      "inti | i do volunteer work for a non profit group called inti . | the group runs a soccer and art school for poor kids . | today my director sent me a grant proposal to proofread . | i made a few edits and returned the proposal . | i hope we get the $35,000 grant .\n",
      "==================most similar end pairs====================\n",
      "community service | my teacher assigned our class a community service project . | i wasn 't sure how to approach the task . | my dad suggested asking a nearby food bank if they need volunteers . | i called the food bank and made an appointment for orientation . | i went to help sort donations and got an a on the project .\n",
      "\n",
      "instance # 11\n",
      "can you smell that smell ? | cora walked into the kitchen and noticed a bad odor . | she looked in the trash can to see if the smell was coming from there . | the trash didn 't smell , so cora checked the cabinets . | nothing was smelly in the cabinets , so cora checked the sink . | she realized that a nasty smell was wafting from the garbage disposal !\n",
      "==================most similar end pairs====================\n",
      "the skunk which scared me | there once was a horrid smell in the house . | it smelled so bad , that i had to find the source . | it led me to my wardrobe,which was opened a bit . | i almost gagged in horror when i smelled the odor from the wardrobe | and then a skunk popped out , causing me to shriek loudly ! \n",
      "\n",
      "instance # 12\n",
      "delivery | tina 's water broke one night . | she hurried to the hospital . | they set her up on medicine and encouraged her . | she struggled through the birth of her baby . | and after sixteen hours , tina became a mommy !\n",
      "==================most similar end pairs====================\n",
      "too fast | karen was 9 months pregnant . | she was very ready to have her baby . | one night she was woken up by her water breaking . | her and her husband began their 30 minute drive to the hospital . | the baby couldn 't wait and was born in the car .\n",
      "\n",
      "instance # 13\n",
      "the old roller coaster | when i was a child i used to go to a local amusement park . | the park had one of the oldest roller coasters in the usa . | i went on it once and it felt shaky and unsafe . | i decided i would never go on it again since i valued my safety . | i recently heard that the park had finally tore it down .\n",
      "==================most similar end pairs====================\n",
      "space mountain ride | my cousin and i were about to go on the space mountain ride at disney . | i had never been on a coaster before and was freaked out . | as i got in the car and put the bar close to me , i shut my eyes . | the ride took off and i was freaking out . | thankfully it was over before i knew it .\n",
      "\n",
      "instance # 14\n",
      "painting | for valentine 's day andrew wanted to paint a portrait of her . | he got one of her pictures that he had . | he spent a week painting the portrait . | valentines day finally arrived . | his girlfriend loved the picture .\n",
      "==================most similar end pairs====================\n",
      "locket | rod bought his mom a locket for her birthday . | he wondered what pictures to put in it . | then he had a great idea . | he printed tiny copies of images of him and his sister . | he gave them to his mom in her new locket .\n",
      "\n",
      "instance # 15\n",
      "caught cheating . | harley was walking up his apartment stairs . | he walked inside and noticed a man 's pair of shoes . | that 's when he heard noises in the bedroom . | he caught his wife sleeping with someone else . | he didn 't know what to do so he just threw both of them out .\n",
      "==================most similar end pairs====================\n",
      "the scared kid . | max was asleep in his bed . | suddenly he woke up . | he thought that he saw something scary outside of his window . | he ran to his mom 's room and woke her up . | she checked for him but there was nothing there .\n",
      "\n",
      "instance # 16\n",
      "the end of friendship | brian and josh were friends . | one day , brian got mad at josh . | josh didn 't understand why brian was mad . | brian would not talk to josh . | brian and josh are no longer friends .\n",
      "==================most similar end pairs====================\n",
      "fight | brian found out matt was talking about him online . | matt was insulting brian . | matt decides to stop by brian 's house . | brian 's brother comes out . | brian 's brother beats matt up .\n",
      "\n",
      "instance # 17\n",
      "jimmy had to sell his shop | jimmy and his long time partner owned a hot dog shop together | they started getting into disputes over running the business | they decided to sell the place | it went up for auction and they each ended up bidding for it | jimmy 's partner won the auction from jimmy for 300k\n",
      "==================most similar end pairs====================\n",
      "mike 's unemployed | mike quit his job one day and then needed to find a source of income . | mike lived on savings for a while before deciding to start a business . | he came up with the idea for a t shirt company and bought the tools . | after designing some t shirts and a website , mike began to get work . | mike 's t shirt business began to kick off and he was a success .\n",
      "\n",
      "instance # 18\n",
      "can 't get away | maurice moved to florida to get away from his ex . | after moving into his new house , he looked around his yard . | he turned to his right at the house next door . | standing in the yard was his ex . | she had moved in next door .\n",
      "==================most similar end pairs====================\n",
      "crushed finger | william went to his school to pick up his class schedule . | he walked into the front office . | he picked up his schedule from a lady at the front desk . | while leaving the office , william closed his finger between the doors . | he yelped in pain , then left the school and treated his injury .\n",
      "\n",
      "instance # 19\n",
      "the promotion | john had worked for his company for many years . | he worked hard and often did more than his job required . | one day , john 's boss called him into an empty office . | he told john that the company appreciated all his work over the years . | finally , he told john that john was getting a promotion and a raise !\n",
      "==================most similar end pairs====================\n",
      "modern family | john was a hard worker at his job . | he spent at least 50 hours a week on his new business he started . | however , his wife and children has begun to feel neglected . | john saw how much they wanted to be with him . | so john quit his old job to take care of his family more\n",
      "\n",
      "instance # 20\n",
      "painting | maria wanted to learn to paint . | she signed up for a class . | she attended the class diligently . | by the end of the class , she wasn 't as good as she wanted to be . | she vowed to practice even more , every single day .\n",
      "==================most similar end pairs====================\n",
      "art teacher | bianca likes to teach art to children . | she set up an art studio to give classes to them . | the first day she had all of her seats filled for the class . | she taught them new techniques and terms they would be using . | at the end of the day she felt that it had been a success .\n",
      "\n",
      "instance # 21\n",
      "minecraft | jay 's son loved playing the game minecraft . | jay was curious and wanted to see what it was all about . | he logged on and tried to play the game himself . | but he was completely lost and confused . | jay could not figure out minecraft at all !\n",
      "==================most similar end pairs====================\n",
      "chess | i tried to play internet chess with my friend last night . | it was only 8 pm . | he refused to play , saying he was tired . | i played other people on the net instead . | it was fun , but not as fun as playing someone i knew .\n",
      "\n",
      "instance # 22\n",
      "anger at friends | i found out that my friend had been lying to me . | he had also stolen all of my money . | when i confronted him , he said i was crazy . | when he said this , i provided proof . | we are no longer friends .\n",
      "==================most similar end pairs====================\n",
      "blamed | when i was seven i was accused of stealing my father 's glasses . | i kept telling my parents that i didn 't . | they did not believe me . | eventually , the glasses were found on a table where my dad left them . | he never apologized for blaming me which makes me mad to this day .\n",
      "\n",
      "instance # 23\n",
      "the ball | zeke had a dog . | the dog loved to play catch . | one day , the dog 's favorite ball got lost . | the dog was sad . | zeke bought the dog a new ball and the dog was happy again .\n",
      "==================most similar end pairs====================\n",
      "loose dog | jim always walked to school . | but one day he heard a dog barking . | he looked behind him . | and it was a loose dog . | luckily , the owner caught the dog in time .\n",
      "\n",
      "instance # 24\n",
      "practice makes perfect | jane 's tennis serve was awful ! | her overall play was very good except for her serve . | jane realized she needed professional training . | she hired the best tennis trainer and she practiced every day . | jane won the next tennis match and , eventually , the championship !\n",
      "==================most similar end pairs====================\n",
      "illness | frankie loved tennis . | she was the star of her team . | she got sick and could not play for three weeks . | she worked hard to get her game back . | she eventually won the school tournament .\n",
      "\n",
      "instance # 25\n",
      "leg lifts | my goal is to leg lift over two hundred pounds at the gym . | right now i can only leg lift about one hundred pounds . | i got a trainer and worked hard for months . | the trainer helped me to push myself further and further . | months later i was able to reach my goal .\n",
      "==================most similar end pairs====================\n",
      "lifting | i 've always wanted to be able to lift four hundred pounds over my head . | right now i can lift about three hundred pounds that high . | i got myself a trainer and worked real head for a year . | i ate right and got plenty of sleep . | about a year later i became stronger and reached my goal !\n",
      "\n",
      "instance # 26\n",
      "stinky breath | for the past week or so , suzy has forgotten to brush her teeth ! | everyone around her had wondered where that awful smell was from . | luckily , her older sister had a brilliant idea . | suzy 's sister bought her some mint gum for a treat . | now at least suzy 's breath doesn 't stink !\n",
      "==================most similar end pairs====================\n",
      "smelly feet | my sister always wears sandals . | she was at my mom 's house one day . | no one could figure out the awful odor . | then as we got closer to her , we noticed the stench . | it was her smelly feet !\n",
      "\n",
      "instance # 27\n",
      "daniel affords a plane | daniel wanted to buy a toy plane , but he didn 't have any money . | he asked his neighbors if they would pay him to do jobs . | daniel raked leaves for one neighbor , and helped another one garden . | after 5 weeks of work he could finally afford his plane . | he bought his toy plane , and kept working so he could buy another !\n",
      "==================most similar end pairs====================\n",
      "broken phone | jamal wanted to get a new phone . | he did not want to buy one unnecessarily because he didn 't need it . | last night after work , he was walking to the car when his phone fell . | it fell face down and shattered and nothing would turn on . | he had no choice but to buy a new one to replace it .\n",
      "\n",
      "instance # 28\n",
      "clams | cj loved clams . | one day he went to the beach . | he dug for clams . | there were a lot of clams for him to collect . | cj had a great dinner that night with the clams .\n",
      "==================most similar end pairs====================\n",
      "clams | spence has always been grossed out by seafood . | he and his friends took a trip to the coast . | they went to one of the best seafood restaurants . | he decided to try clams . | he loved them !\n",
      "\n",
      "instance # 29\n",
      "bobo the clown | bobo was a clown who was very tall . | he had a small head however . | his odd proportions allowed him to be even funnier . | while he was younger other kids would laugh at him . | but now he makes a living with his odd physique .\n",
      "==================most similar end pairs====================\n",
      "a new pet in town | shawn was almost an adult now . | he had always wanted a pet dog for himself . | his parents would always say no because he was too young . | now that his eighteenth birthday was here he felt old enough . | before he could ask them again they surprised him with his very own dog .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_start = np.random.randint(story_n)\n",
    "for i in range(rand_start, rand_start + 30):\n",
    "    print \"instance #\",i - rand_start\n",
    "    print \" | \".join([\" \".join([index2word_dic[new_train_set[i][j][k]] for k in range(len(new_train_set[i][j]))]) for j in range(6)])\n",
    "    print \"==================most similar end pairs====================\"\n",
    "    print \" | \".join([\" \".join([index2word_dic[new_train_set[most_simi_storyPNend_pair[i]][j][k]] for k in range(len(new_train_set[most_simi_storyPNend_pair[i]][j]))]) for j in range(6)])\n",
    "    print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45502,)\n"
     ]
    }
   ],
   "source": [
    "most_simi_end = pickle.load(open('../../data/pickles/most_simi_end_pair.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(most_simi_end[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same_pair_dict = {}\n",
    "\n",
    "for i in range(len(compare_vec)):\n",
    "    if compare_vec[i] == 0:\n",
    "        same_pair_dict[i] = most_simi_story_pair[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same_pair_k_ls = np.asarray([k for k,v in same_pair_dict.items()])\n",
    "sorted_spkls = np.sort(same_pair_k_ls, kind='mergesort')\n",
    "\n",
    "sorted_same_pair_ls = [(k,same_pair_dict[k]) for k in sorted_spkls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 32732.0),\n",
       " (113, 31763.0),\n",
       " (142, 42605.0),\n",
       " (210, 27850.0),\n",
       " (241, 5262.0),\n",
       " (243, 243.0),\n",
       " (314, 35863.0),\n",
       " (381, 14434.0),\n",
       " (430, 34086.0),\n",
       " (453, 2806.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_same_pair_ls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20210.,  11891.,  16703.,  27791.,  40423.,  25657.,  11257.,\n",
       "        40423.,  40023.,   6907.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_story_pair[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19170.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_story_pair[42605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "whole_set = train_set[1]\n",
    "\n",
    "story_n = len(end_set)\n",
    "ending_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    ending_rep_matrix[i] = np.sum([wemb_matrix[end_set[i][j]] for j in range(len(end_set[i]))], axis = 0)/float(len(end_set[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pickle.load(open('../../data/pickles/train_index_corpus.pkl'))\n",
    "train_story = train_set[0]\n",
    "train_ending = train_set[1]\n",
    "n_train = len(train_ending)\n",
    "stories_indices = np.random.randint(n_train, size=(5,))\n",
    "adv_end_rep_batch = np.random.rand(5, 300)\n",
    "for i in range(len(train_ending)):\n",
    "    end_rep_matrix[i] = np.sum(wemb_matrix[train_ending[i]], axis = 0) / (len(train_ending[i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# '''part III print out story and the most similar end correspondingly'''\n",
    "# for i in range(5):\n",
    "#     index = stories_indices[i]\n",
    "#     story_string = \" | \".join([\" \".join(index2word_dict[train_story[index][j][k]] for k in range(len(train_story[index][j])))] for j in range(5))\n",
    "#     story_end = \" \".join(index2word_dict[train_ending[index][k]] for k in range(len(train_ending[index])))\n",
    "#     generated_end = \" \".join(index2word_dict[train_ending[index_list[i]][k]] for k in range(len(train_ending[index_list[i]])))\n",
    "\n",
    "#     print story_string + \"#END#\" + story_end\n",
    "#     print \"adv model generated:\" + generated_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_end_rep_matrix = np.linalg.norm(end_rep_matrix, axis = 1).reshape(-1,1)\n",
    "norm_adv_end_rep = np.linalg.norm(adv_end_rep_batch, axis = 1).reshape(-1,1)\n",
    "# norm_denominator_matrix.shape = (45503, 5)\n",
    "norm_denominator_matrix = np.dot(norm_end_rep_matrix, norm_adv_end_rep.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dot_prod.shape = (45503, 5)\n",
    "dot_prod = np.dot(end_rep_matrix, adv_end_rep_batch.T)\n",
    "\n",
    "# cos_simi_matrix.shape = (45503, 5)\n",
    "cos_simi_matrix = dot_prod / norm_denominator_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_list = np.argmax(cos_simi_matrix, axis = 0)\n",
    "index2word_dict = index2word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_LR_ls = [0.001, 0.01, 0.005, 0.002]\n",
    "\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(SGD_LR_ls)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('./AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.job','w')\n",
    "        \n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.8\"\\n')\n",
    "        f.write('SETTING3=\"150\"\\n')\n",
    "        f.write('SETTING4=\"100\"\\n')\n",
    "        f.write('SETTING5=\"512x512\"\\n')\n",
    "        f.write('SETTING6=\"'+str(SGD_LR_ls[i])+'\"\\n')\n",
    "        f.write('SETTING7=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING8=\"sgd\"\\n')\n",
    "        f.write('SETTING9=\"adam\"\\n')\n",
    "        f.write('SETTING10=\"default\"\\n')\n",
    "        f.write('SETTING11=\"0\"\\n')\n",
    "        f.write('SETTING12=\"0.005\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BLSTM_inverseAtt_onlyAdvOnVal.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7 $SETTING8 $SETTING9 $SETTING10 $SETTING11 $SETTING12\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_LR_ls = [0.001, 0.002, 0.003, 0.004]\n",
    "\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(SGD_LR_ls)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('./AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.job','w')\n",
    "\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.8\"\\n')\n",
    "        f.write('SETTING3=\"150\"\\n')\n",
    "        f.write('SETTING4=\"100\"\\n')\n",
    "        f.write('SETTING5=\"512x512\"\\n')\n",
    "        f.write('SETTING6=\"'+str(SGD_LR_ls[i])+'\"\\n')\n",
    "        f.write('SETTING7=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING8=\"adam\"\\n')\n",
    "        f.write('SETTING9=\"adam\"\\n')\n",
    "        f.write('SETTING10=\"None\"\\n')\n",
    "        f.write('SETTING11=\"0\"\\n')\n",
    "        f.write('SETTING12=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING13=\"euclidean_distance\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BLSTM_inverseAtt_onlyAdvOnVal.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7 $SETTING8 $SETTING9 $SETTING10 $SETTING11 $SETTING12 $SETTING13\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92985543  0.90911165  0.20109549]\n",
      " [ 0.70195594  0.90439855  0.78901144]]\n",
      "[[ 0.35095578  0.60516986  0.13955199]\n",
      " [ 0.10720247  0.37202453  0.60294815]\n",
      " [ 0.45571606  0.19578082  0.26391564]\n",
      " [ 0.10561486  0.86833171  0.4073849 ]\n",
      " [ 0.17762925  0.77835721  0.96040957]]\n",
      "[[ 0.57889965  0.30394179  0.06154351]\n",
      " [ 0.82265296  0.53708712 -0.40185265]\n",
      " [ 0.47413937  0.71333083 -0.06282015]\n",
      " [ 0.82424057  0.04077993 -0.2062894 ]\n",
      " [ 0.75222618  0.13075444 -0.75931408]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(2,3)\n",
    "\n",
    "b = np.random.rand(5,3)\n",
    "\n",
    "c = a[0] - b\n",
    "\n",
    "print a\n",
    "print b\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight #END# overweight overweight overweight overweight overweight\n",
      "adv model generated: overweight overweight overweight overweight overweight\n",
      "overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight #END# overweight overweight overweight overweight overweight\n",
      "adv model generated: overweight overweight overweight overweight overweight\n",
      "overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight #END# kid kid kid kid kid\n",
      "adv model generated: overweight overweight overweight overweight overweight\n",
      "overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight | overweight overweight overweight overweight overweight overweight overweight overweight overweight overweight #END# kid kid kid kid kid\n",
      "adv model generated: overweight overweight overweight overweight overweight\n",
      "doctors told and decided and unhealthy doctors decided well it | unhealthy decided his and unhealthy the decided decided told doctors | doctors his told decided unhealthy told doctors understood the decided | told well the understood told doctors decided well it his | unhealthy told the and unhealthy his it the unhealthy well #END# kid kid kid kid kid\n",
      "adv model generated: overweight overweight overweight overweight overweight\n"
     ]
    }
   ],
   "source": [
    "a.adv_model_monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.cmodule): Removing key file /home-nfs/jontsai/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.2.1511-Core-x86_64-2.7.11-64/tmp9_R29q/key.pkl because the corresponding module is gone from the file system.\n",
      "WARNING:theano.gof.cmodule:Removing key file /home-nfs/jontsai/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.2.1511-Core-x86_64-2.7.11-64/tmp9_R29q/key.pkl because the corresponding module is gone from the file system.\n"
     ]
    }
   ],
   "source": [
    "a = T.vector()\n",
    "b = T.abs_(a)\n",
    "test = theano.function([a], b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(np.array([1,2,3,4,-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING:theano.tensor.blas:We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "a = T.matrix()\n",
    "b = T.matrix()\n",
    "c = T.batched_dot(a,b)\n",
    "\n",
    "test = theano.function([a,b], c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]]\n",
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0.,    2.,    6.,   12.,   20.,   30.,   42.,   56.,   72.,\n",
       "         90.,  110.,  132.,  156.,  182.,  210.,  240.,  272.,  306.,\n",
       "        342.,  380.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t = np.arange(20).reshape(-1,1)\n",
    "b_t = np.arange(1,21).reshape(-1,1)\n",
    "print a_t\n",
    "print b_t\n",
    "test(a_t, b_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.vector()\n",
    "b = T.vector()\n",
    "c = a/b\n",
    "\n",
    "test = theano.function([a,b], c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[ nan   1.   1.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "b = np.arange(5)\n",
    "c = test(a,b)\n",
    "print c.shape\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = theano.shared(np.array())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
