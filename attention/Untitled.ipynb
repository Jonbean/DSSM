{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import cPickle as pickle\n",
    "import BLSTM_sequence\n",
    "import BLSTM_last\n",
    "import DNN_liar\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import sys\n",
    "# from theano.printing import pydotprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, val_split_ratio, D_batchsize, G_batchsize, liar_setting, \n",
    "                learning_rate1, learning_rate2, optimizer, \n",
    "                score_func_nonlin = 'default', wemb_trainable = 1, generator_halt_threshold = 0.1, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "        self.learning_rate1 = float(learning_rate1)\n",
    "        self.learning_rate2 = float(learning_rate2)\n",
    "        self.classifier_train_func = None\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(100, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "        self.train_set_path = '../../data/pickles/train_index_corpus.pkl'\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "        self.index2word_dict_path = '../../data/pickles/ROC_train_index_dict.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        self.liar_setting = [int(elem) for elem in liar_setting.split('x')]\n",
    "        # self.dropout_rate = float(dropout_rate)\n",
    "        self.D_batchsize = int(D_batchsize)\n",
    "        self.G_batchsize = int(G_batchsize)\n",
    "\n",
    "        self.val_split_ratio = float(val_split_ratio)\n",
    "        self.generator_halt_threshold = float(generator_halt_threshold)\n",
    "\n",
    "        self.classifier_hid1 = 1024\n",
    "        # self.val_split_ratio = float(val_split_ratio)\n",
    "        self.words_num = 28820\n",
    "        # self.delta = float(delta)\n",
    "        if score_func_nonlin == 'default':\n",
    "            self.score_func_nonlin = lasagne.nonlinearities.tanh\n",
    "        else:\n",
    "            self.score_func_nonlin = None\n",
    "\n",
    "        self.wemb_trainable = bool(int(wemb_trainable))\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.sent_reps = []\n",
    "\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "\n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent):\n",
    "            lstm_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True)\n",
    "            sent_rep = (lstm_seq * self.inputs_masks[i].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[i].sum(axis = 1, keepdims = True)\n",
    "            self.sent_reps.append(sent_rep)\n",
    "\n",
    "        self.end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                            {self.encoder.l_in:self.reshaped_inputs_variables[4], \n",
    "                                            self.encoder.l_mask:self.inputs_masks[4]},\n",
    "                                            deterministic = True)\n",
    "\n",
    "        self.current_Nbatch = self.sent_reps[0].shape[0]\n",
    "\n",
    "        merge_ls = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.sent_reps]\n",
    "        encode_merge = T.concatenate(merge_ls, axis = 1)\n",
    "\n",
    "        self.plot_rep = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge}, \n",
    "                                                    deterministic = True)\n",
    "\n",
    "    def attention_layer1(self):        \n",
    "        n_batch, n_seq, _ = self.end_seq.shape\n",
    "\n",
    "        #second attention\n",
    "        bili_part1 = T.dot(self.end_seq, self.bilinear_attention_matrix)\n",
    "\n",
    "        attention_score_tensor = T.batched_dot(bili_part1, self.plot_rep)\n",
    "\n",
    "        numerator = self.inputs_masks[4] * T.exp(attention_score_tensor - attention_score_tensor.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        attention_weight_matrix = numerator / numerator.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        attentioned_end_seq = self.end_seq * (attention_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "        self.attentioned_end_rep = T.sum(attentioned_end_seq, axis = 1) / T.sum(self.inputs_masks[4], axis = 1).reshape([-1, 1])\n",
    "\n",
    "    def attention_layer2(self):\n",
    "        n_batch, n_seq, _ = self.encode_2nd_end_seq.shape\n",
    "        #second attention\n",
    "        bili_part1 = T.dot(self.encode_2nd_end_seq, self.bilinear_attention_matrix)\n",
    "\n",
    "        attention_score_tensor = T.batched_dot(bili_part1, self.plot_rep)\n",
    "\n",
    "        numerator = self.vt_2nd_end_mask * T.exp(attention_score_tensor - attention_score_tensor.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        attention_weight_matrix = numerator / numerator.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        attentioned_end_seq = self.encode_2nd_end_seq*(attention_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "        self.vt_2nd_end_repr = T.sum(attentioned_end_seq, axis = 1) / T.sum(self.vt_2nd_end_mask, axis = 1).reshape([-1, 1])\n",
    "\n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        self.vt_2nd_end_in = T.matrix('second_end', dtype='int64')\n",
    "        self.vt_2nd_end = self.vt_2nd_end_in.reshape([self.vt_2nd_end_in.shape[0], self.vt_2nd_end_in.shape[1],1])\n",
    "        self.vt_2nd_end_mask = T.matrix('second_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "        for i in range(self.story_nsent+1):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "            \n",
    "        self.test1 = theano.function(self.inputs_variables + [self.vt_2nd_end_in], self.reshaped_inputs_variables + [self.vt_2nd_end])\n",
    "        \n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units, wemb_trainable = self.wemb_trainable)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "        self.sent_encoder = BLSTM_last.BlstmEncoder(INPUT_SIZE = self.rnn_units, LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.sent_encoder.build_model()\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "        self.test2 = theano.function(self.inputs_variables + self.inputs_masks, [self.plot_rep, self.end_seq])\n",
    "\n",
    "        '''============================================================================'''\n",
    "        #encode possible second ending\n",
    "        self.encode_2nd_end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.vt_2nd_end, \n",
    "                                                     self.encoder.l_mask:self.vt_2nd_end_mask},\n",
    "                                                     deterministic = True)\n",
    "        self.test3 = theano.function([self.vt_2nd_end_in, self.vt_2nd_end_mask], self.encode_2nd_end_seq)\n",
    "        self.attention_layer1()\n",
    "        self.test4 = theano.function(self.inputs_variables + self.inputs_masks, self.attentioned_end_rep)\n",
    "\n",
    "        self.attention_layer2()\n",
    "        self.test5 = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], self.vt_2nd_end_repr, on_unused_input = 'ignore')\n",
    "        '''============================================================================'''\n",
    "        '''alternative ending construction part'''\n",
    "        '''========================================================'''\n",
    "\n",
    "        # self.DNN_liar.l_in.shape = (n_batch, self.rnn_units * 2)\n",
    "        # self.DNN_liar.output = (n_batch, self.rnn_units)\n",
    "        self.DNN_liar = DNN_liar.DNNLiar(INPUTS_SIZE = self.rnn_units, LAYER_UNITS = self.liar_setting, INPUTS_PARTS = 1)\n",
    "\n",
    "        # self.alternative_end.shape = self.DNN_liar.output\n",
    "        self.alternative_end = lasagne.layers.get_output(self.DNN_liar.output, {self.DNN_liar.l_in: self.plot_rep})\n",
    "\n",
    "        '''========================================================'''\n",
    "\n",
    "        '''discriminator'''\n",
    "        '''========================================================'''\n",
    "\n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "        l_hid1 = lasagne.layers.DenseLayer(l_concate, num_units = self.classifier_hid1, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "        classifier = lasagne.layers.DenseLayer(l_hid1, num_units=2,\n",
    "                                          nonlinearity=self.score_func_nonlin)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(classifier)\n",
    "\n",
    "        '''========================================================'''\n",
    "        '''               generator training graph                 '''\n",
    "        '''========================================================'''\n",
    "        # euclidien_distance = T.sqrt(T.sum(T.sqr(self.alternative_end - self.plot_rep), axis = 1))\n",
    "\n",
    "        '''========================================================'''\n",
    "        '''                    generating score                    '''\n",
    "        '''========================================================'''\n",
    "\n",
    "        # answer = (2 * srng.uniform((n_batch,))).astype('int64')\n",
    "\n",
    "        # ending_pair_tensor1 = self.train_encodinglayer_vecs[-1] * (1-answer).dimshuffle(0,'x') + self.alternative_end * answer.dimshuffle(0,'x')\n",
    "        # ending_pair_tensor2 = self.train_encodinglayer_vecs[-1] * (answer).dimshuffle(0,'x') + self.alternative_end * (1-answer).dimshuffle(0,'x')\n",
    "        \n",
    "\n",
    "        origi_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.attentioned_end_rep})\n",
    "        alter_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.alternative_end})\n",
    "        \n",
    "        # srng = RandomStreams(seed=234)\n",
    "\n",
    "        # noise_story = srng.normal((self.batchsize, self.rnn_units))\n",
    "        # noise_score = lasagne.layers.get_output(classifier, {l_story_in: noise_story})\n",
    "\n",
    "        '''========================================================'''\n",
    "\n",
    "        vt_2nd_score = lasagne.layers.get_output(classifier, {l_story_in: self.plot_rep, \n",
    "                                                   l_end_in: self.vt_2nd_end_repr})\n",
    "\n",
    "        self.test6 = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], [origi_score, alter_score, vt_2nd_score], on_unused_input = 'ignore')\n",
    "\n",
    "        prob1 = lasagne.nonlinearities.softmax(origi_score)\n",
    "        prob2 = lasagne.nonlinearities.softmax(alter_score)\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, T.ones((self.current_Nbatch, )).astype('int64'))\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, T.zeros((self.current_Nbatch, )).astype('int64'))\n",
    "\n",
    "        liar_cost = lasagne.objectives.categorical_crossentropy(prob2, T.ones((self.current_Nbatch, )).astype('int64'))\n",
    "\n",
    "        self.main_cost = lasagne.objectives.aggregate(cost1+cost2, mode = 'mean')\n",
    "        self.liar_cost = lasagne.objectives.aggregate(liar_cost, mode = 'mean')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        main_params = self.encoder.all_params + self.sent_encoder.all_params + final_class_param + [self.bilinear_attention_matrix]\n",
    "\n",
    "\n",
    "        liar_params = self.DNN_liar.all_params\n",
    "\n",
    "        main_updates = None\n",
    "        liar_updates = None\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            main_updates = lasagne.updates.adam(self.main_cost, main_params, learning_rate=self.learning_rate1)\n",
    "\n",
    "            liar_updates = lasagne.updates.adam(self.liar_cost, liar_params, learning_rate=self.learning_rate2)\n",
    "        else:\n",
    "            main_updates = lasagne.updates.momentum(self.main_cost, main_params, learning_rate=self.learning_rate1, momentum=0.9)\n",
    "            liar_updates = lasagne.updates.momentum(self.liar_cost, liar_params, learning_rate=self.learning_rate2, momentum=0.9)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "\n",
    "        # all_updates = []\n",
    "        # for k,v in main_updates.items()+liar_updates.items():\n",
    "        #     all_updates.append((k,v))\n",
    "\n",
    "        # combine two sets of parameters update into a single OrderedDict \n",
    "        self.classifier_train_func = theano.function(self.inputs_variables + self.inputs_masks, \n",
    "                                        [self.main_cost, origi_score, alter_score], updates = main_updates)\n",
    "        self.generator_train_func = theano.function(self.inputs_variables + self.inputs_masks, self.liar_cost, updates = liar_updates, on_unused_input='ignore')\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + [self.vt_2nd_end_in] + self.inputs_masks + [self.vt_2nd_end_mask], [origi_score, vt_2nd_score])\n",
    "\n",
    "        self.adv_monitor = theano.function(self.inputs_variables + self.inputs_masks, self.alternative_end, on_unused_input='ignore')\n",
    "\n",
    "        self.test_end_matrix = T.matrix('test_end', dtype='int64')\n",
    "        self.test_end_mask = T.matrix('test_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "        self.test_end_rep = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.test_end_matrix, \n",
    "                                                    self.encoder.l_mask:self.test_end_mask},\n",
    "                                                    deterministic = True)\n",
    "        check_end_representation = (self.test_end_rep * self.test_end_mask.dimshuffle(0,1,'x')).sum(axis = 1) / self.test_end_mask.sum(axis = 1, keepdims = True)\n",
    "\n",
    "        self.end_rep_check = theano.function([self.test_end_matrix, self.test_end_mask], check_end_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Hierachi_RNN(300, 0.8, 150, 100, '512x256', 0.001, 0.001, 'sgd', 'default', 0, 0.01)\n",
    "a.model_constructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plot = [np.random.randint(5, size=(5,20)).astype('int64') for i in range(4)]\n",
    "plot_mask = [np.ones((5,20)) for i in range(4)]\n",
    "end1 = np.random.randint(5, size=(5,20)).astype('int64')\n",
    "end1_mask = np.ones((5,20))\n",
    "end2 = np.random.randint(5, size=(5,20)).astype('int64')\n",
    "end2_mask = np.ones((5, 20))\n",
    "\n",
    "results = a.test2(plot[0], plot[1], plot[2], plot[3], end1, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask)\n",
    "results[1].shape\n",
    "#, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20, 300)\n"
     ]
    }
   ],
   "source": [
    "result3 = a.test3(end2, end2_mask)\n",
    "print result3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 300)\n"
     ]
    }
   ],
   "source": [
    "result4 = a.test4(plot[0], plot[1], plot[2], plot[3], end1, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask)\n",
    "\n",
    "print result4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5 = a.test5(plot[0], plot[1], plot[2], plot[3], end1, end2, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask)\n",
    "\n",
    "result5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6 = a.prediction(plot[0], plot[1], plot[2], plot[3], end1, end2, plot_mask[0], plot_mask[1],  plot_mask[2],  plot_mask[3], end1_mask, end2_mask)\n",
    "result6[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30258509,  0.69314718,  1.60943791])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.9,0.5,0.2])\n",
    "b = np.array([0,1,1])\n",
    "test(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.matrix()\n",
    "\n",
    "c = T.mean(a, axis = 1)\n",
    "d = T.sum(a, axis = 1) / T.sum(b, axis = 1).reshape([-1,1])\n",
    "\n",
    "test1 = theano.function([a,b], [c,d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.5,   6.5,   7.5],\n",
       "        [ 17.5,  18.5,  19.5]]),\n",
       " array([[  5.5       ,   6.5       ,   7.5       ],\n",
       "        [ 23.33333333,  24.66666667,  26.        ]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = np.array([[[1,2,3], [4,5,6], [7,8,9], [10,11,12]],[[13,14,15],[16,17,18],[19,20,21],[22,23,24]]])\n",
    "b_1 = np.array([[1,1,1], [2,2,2]])\n",
    "mask_1 = np.array([[1,1,1,1],[1,1,1,0]])\n",
    "test1(a_1, mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BLSTM_sequence\n",
    "import sys\n",
    "# from theano.printing import pydotprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, dropout_rate, batchsize, val_split_ratio, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "\n",
    "        self.train_func = None\n",
    "\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(200, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        # self.mlp_units = [int(elem) for elem in mlp_setting.split('x')]\n",
    "        self.bilinear_matrix = theano.shared(0.002*np.random.rand(self.rnn_units, self.rnn_units)-0.001)\n",
    "        self.dropout_rate = float(dropout_rate)\n",
    "        self.batchsize = int(batchsize)\n",
    "\n",
    "        self.val_split_ratio = float(val_split_ratio)\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.train_encodinglayer_vecs = []\n",
    "        self.test_encodinglayer_vecs = []\n",
    "        self.reasoninglayer_vec1 = []\n",
    "        self.reasoninglayer_vec2 = []\n",
    "        self.reasoninglayer_vec1_test = []\n",
    "        self.reasoninglayer_vec2_test = []\n",
    "        self.reasoning_pool_results = []\n",
    "        self.reasoning_pool_results_test = []\n",
    "        self.reasoners = []\n",
    "        self.attentioned_sent_rep1 = []\n",
    "        self.attentioned_sent_rep2 = []\n",
    "        self.monitor1 = []\n",
    "        self.monitor2 = []\n",
    "        self.attention_moni1 = []\n",
    "        self.attention_moni2 = []\n",
    "        self.softmask_moni = []\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "        \n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent):\n",
    "            self.train_encodinglayer_vecs.append(lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True))\n",
    "        ending1_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[4],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[4]},\n",
    "                                                        deterministic = True)\n",
    "        ending2_sequence_tensor = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[5],\n",
    "                                                        self.encoder.l_mask:self.inputs_masks[5]},\n",
    "                                                        deterministic = True)\n",
    "\n",
    "        l_end_in= lasagne.layers.InputLayer((None, None, self.rnn_units))\n",
    "        l_shuffle = lasagne.layers.DimshuffleLayer(l_end_in, (0,2,1))\n",
    "        l_pooling = lasagne.layers.GlobalPoolLayer(l_shuffle)\n",
    "\n",
    "\n",
    "        end1_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending1_sequence_tensor})\n",
    "        end2_representation = lasagne.layers.get_output(l_pooling, {l_end_in:ending2_sequence_tensor})\n",
    "        self.train_encodinglayer_vecs.append(end1_representation)\n",
    "        self.train_encodinglayer_vecs.append(end2_representation)\n",
    "        \n",
    "    def attention_layer(self):        \n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "      \n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention1_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[4])\n",
    "\n",
    "            attention2_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[5])\n",
    "\n",
    "#             softmax_mask = \n",
    "#             self.softmask_moni.append(softmax_mask)\n",
    "            numerator1 = self.inputs_masks[i] * T.exp(attention1_score_tensor - attention1_score_tensor.max(axis = 1, keepdims = True))\n",
    "            numerator2 = self.inputs_masks[i] * T.exp(attention2_score_tensor - attention2_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention1_weight_matrix = numerator1 / numerator1.sum(axis = 1, keepdims = True)\n",
    "            attention2_weight_matrix = numerator2 / numerator2.sum(axis = 1, keepdims = True)\n",
    "#             attention1_weight_matrix = T.nnet.softmax(attention1_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "#             attention2_weight_matrix = T.nnet.softmax(attention2_score_tensor.reshape([n_batch, -1])*self.inputs_masks[i])\n",
    "            self.attention_moni1.append(attention1_weight_matrix)\n",
    "            self.attention_moni2.append(attention2_weight_matrix)\n",
    "            \n",
    "            attentioned_sent_seq1 = self.train_encodinglayer_vecs[i]*(attention1_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            attentioned_sent_seq2 = self.train_encodinglayer_vecs[i]*(attention2_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "            \n",
    "            self.monitor1.append(attentioned_sent_seq1)\n",
    "            self.monitor2.append(attentioned_sent_seq2)\n",
    "            \n",
    "            attentioned_sent_rep1 = T.sum(attentioned_sent_seq1, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "            attentioned_sent_rep2 = T.sum(attentioned_sent_seq2, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep1.append(attentioned_sent_rep1)\n",
    "            self.attentioned_sent_rep2.append(attentioned_sent_rep2)\n",
    "\n",
    "           \n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        for i in range(self.story_nsent+2):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "\n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units, dropout_rate = self.dropout_rate)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "        self.test0 = theano.function(self.inputs_variables + self.inputs_masks, self.train_encodinglayer_vecs)\n",
    "        #build attention layer\n",
    "        self.attention_layer()\n",
    "        \n",
    "        self.test2 = theano.function(self.inputs_variables + self.inputs_masks, self.monitor1+self.monitor2)\n",
    "        self.test3 = theano.function(self.inputs_variables + self.inputs_masks, self.attention_moni1 + self.attention_moni2)\n",
    "        \n",
    "#         self.test4 = theano.function(self.inputs_masks[:4], self.softmask_moni)\n",
    "        #build reasoning layers\n",
    "        \n",
    "        self.test1 = theano.function(self.inputs_variables + self.inputs_masks, self.attentioned_sent_rep1 + self.attentioned_sent_rep2)\n",
    "        self.merge_ls1 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep1]\n",
    "        self.merge_ls2 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep2]\n",
    "\n",
    "        encode_merge1 = T.concatenate(self.merge_ls1, axis = 1)\n",
    "        encode_merge2 = T.concatenate(self.merge_ls2, axis = 1)\n",
    "\n",
    "        l_in = lasagne.layers.InputLayer(shape=(None, None, self.rnn_units))\n",
    "        gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        b=lasagne.init.Constant(0.))\n",
    "\n",
    "        cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                        W_hid=lasagne.init.Orthogonal(),\n",
    "                                                        # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                        W_cell=None, \n",
    "                                                        b=lasagne.init.Constant(0.),\n",
    "                                                        # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        l_lstm = lasagne.layers.recurrent.LSTMLayer(l_in, \n",
    "                                                    num_units=self.rnn_units,\n",
    "                                                    # Here, we supply the gate parameters for each gate \n",
    "                                                    ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                    cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                    # We'll learn the initialization and use gradient clipping \n",
    "                                                    learn_init=True, grad_clipping=100.0)\n",
    "\n",
    "        # The back directional LSTM layers\n",
    "        l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_in,\n",
    "                                                         num_units=self.rnn_units,\n",
    "                                                         ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                         cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                         # We'll learn the initialization and use gradient clipping \n",
    "                                                         learn_init=True,grad_clipping=100.0,\n",
    "                                                         backwards=True)\n",
    "\n",
    "        # Do sum up of bidirectional LSTM results\n",
    "        l_out_right = lasagne.layers.SliceLayer(l_lstm, -1, 1)\n",
    "        l_out_left = lasagne.layers.SliceLayer(l_lstm_back, -1, 1)\n",
    "        l_sum = lasagne.layers.ElemwiseSumLayer([l_out_right, l_out_left])\n",
    "\n",
    "        reasoner_result1 = lasagne.layers.get_output(l_sum, {l_in: encode_merge1}, deterministic = True)\n",
    "        reasoner_result2 = lasagne.layers.get_output(l_sum, {l_in: encode_merge2}, deterministic = True)\n",
    "\n",
    "        reasoner_params = lasagne.layers.get_all_params(l_sum)\n",
    "\n",
    "        # l_story_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        # l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        # l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "        #                                   nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        # final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "        \n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "\n",
    "        l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "                                          nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "\n",
    "        score1 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-2]})\n",
    "        score2 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result2, \n",
    "                                                   l_end_in: self.train_encodinglayer_vecs[-1]})\n",
    "        self.test5 = theano.function(self.inputs_variables + self.inputs_masks,[score1, score2])\n",
    "        prob1 = lasagne.nonlinearities.softmax(score1)\n",
    "        prob2 = lasagne.nonlinearities.softmax(score2)\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        target1 = T.vector('gold_target1', dtype= 'int64')\n",
    "        target2 = T.vector('gold_target2', dtype= 'int64')\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, target1)\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, target2)\n",
    "\n",
    "        self.cost = lasagne.objectives.aggregate(cost1+cost2, mode='sum')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        all_params = self.encoder.all_params + reasoner_params + final_class_param\n",
    "\n",
    "        all_updates = lasagne.updates.sgd(self.cost, all_params, learning_rate=0.001)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "        updates_exp = [val for key,val in all_updates.items()]\n",
    "        self.test_params = theano.function(self.inputs_variables+self.inputs_masks+[target1, target2], updates_exp, on_unused_input='warn')\n",
    "        self.train_func = theano.function(self.inputs_variables + self.inputs_masks + [target1, target2], \n",
    "                                        [self.cost, prob1, prob2], updates = all_updates)\n",
    "\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + self.inputs_masks, [score1, score2])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a = Hierachi_RNN('300','0.0','20','0.25')\n",
    "a.model_constructor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "targ1 = np.random.randint(2, size=(5,))\n",
    "targ2 = 1 - targ1\n",
    "params = a.train_func(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5], targ1, targ2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7.641996219323214)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score1= a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                                  inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[28, 54, 37, 81, 45, 85, 43, 30,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 45,  7, 27, 75, 20, 19, 50,  0, 61, 89, 68, 88, 63, 27,  5],\n",
       "        [49, 47, 95, 73, 22, 82, 58, 60, 94, 66,  6, 38, 87, 38, 67,  0],\n",
       "        [57, 51,  4, 97, 44, 47, 61, 35, 10, 62, 92,  0,  0,  0,  0,  0],\n",
       "        [ 1, 61, 44, 99, 33, 92, 71, 81, 57, 10, 59, 26, 39, 91, 66, 29]]),\n",
       " array([[93, 81, 48, 80, 88, 74, 81, 96, 98, 67, 59, 72, 51, 93, 17, 78],\n",
       "        [66, 13, 22, 10, 19, 47, 10, 81, 57, 43, 78, 56, 90, 11, 84,  0],\n",
       "        [ 4, 33, 74, 10, 97,  2,  0, 86, 93, 51, 52,  0,  0,  0,  0,  0],\n",
       "        [19, 22, 74, 43, 85, 97, 49, 46, 80, 95, 72, 18, 13, 13, 48, 48],\n",
       "        [54, 35, 99, 72, 19, 95, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[44, 22, 18, 66, 27, 56,  9, 41,  0, 26, 78, 41, 15, 85,  6,  0],\n",
       "        [ 8, 79, 77, 60,  3, 53, 39, 11, 87, 26, 71,  0,  0,  0,  0,  0],\n",
       "        [ 8, 87, 11, 57, 76, 87, 51, 82, 90, 10, 56, 16, 14, 14, 13, 23],\n",
       "        [10, 22, 44, 56, 18, 77, 78,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 85, 23, 59, 42, 80,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[83, 72, 49, 51, 43, 99, 48, 32, 73, 48, 47,  0,  0,  0,  0,  0],\n",
       "        [33, 38, 62, 10,  5, 16, 12, 60,  8, 69, 49, 17, 45, 84,  1, 36],\n",
       "        [26, 19, 25, 71, 87, 76, 82,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [55, 10, 85, 89, 28,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [72, 64, 34,  6, 91, 51, 79,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[20, 88, 40, 74, 57, 91, 70, 94, 60,  5, 91, 41, 94, 37, 32, 94],\n",
       "        [35, 47, 38, 99, 12, 62,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [17, 22, 96, 89, 43,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [10, 34,  5, 38, 83, 71,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [22, 76, 42, 30, 60, 57, 66, 40, 77, 38, 53, 99, 77, 66, 55,  0]]),\n",
       " array([[14, 36, 71, 12, 30, 81, 64,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [59, 18, 55, 70, 89, 81,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [98, 89, 18, 88,  2,  3, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [41, 29, 38, 55, 69, 44,  3, 43, 31, 85, 42, 72,  4, 32, 89,  0],\n",
       "        [48, 82, 18, 48, 39,  0,  4, 57, 29, 27, 79, 97, 84, 40, 62, 80]])]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "\n",
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "result = a.test2(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4], inputs_v[5],\n",
    "                 inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4], inputs_m[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  4 55 67 81 81  6 29  0  0  0  0  0  0  0  0]\n",
      " [21 36 34 19 78 49  2 19  0 77 75 74 17  9 19  3]\n",
      " [ 5 29 11 94 21 70 78 10  2  6 98 42 66 28  8  0]\n",
      " [ 3 67 35 72 27 50 47 96 91 89 98  0  0  0  0  0]\n",
      " [44 30 99 88 56 79 69 91 34 33 72 41 28 81 74 33]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[  6.12901829e-04   1.28206219e-02   1.85810721e-02   1.77323277e-03\n",
      "  -1.10088005e-02  -5.78050119e-04   9.91322895e-04   1.83338379e-02\n",
      "  -7.76145479e-03   9.97180350e-03   2.69632479e-03  -1.11936929e-02\n",
      "  -6.97481570e-03   6.67866176e-03  -6.61085645e-04   8.17177092e-03\n",
      "  -8.19279369e-03   1.05830154e-02  -1.43372396e-02  -2.16162561e-03\n",
      "   3.08066795e-03   5.19928999e-03   5.88627218e-04  -7.88304211e-03\n",
      "  -1.46142518e-02   1.33390188e-02  -9.66771911e-03  -1.12186504e-02\n",
      "   3.66041710e-03   9.62523792e-03   1.28240819e-03  -5.20637273e-03\n",
      "  -8.51101042e-03   1.73788929e-03   1.94455368e-02  -1.24445732e-02\n",
      "  -7.50992763e-03  -1.18625974e-02   1.06565481e-02  -8.50607810e-03\n",
      "   9.51179236e-03  -1.27784173e-02   5.83417507e-03   1.72071440e-03\n",
      "  -9.64891977e-03   3.19398294e-03   1.17664811e-03  -9.18265630e-03\n",
      "  -8.65501609e-03  -1.03077354e-02   6.24028133e-03   4.43544259e-03\n",
      "  -2.45638349e-03  -4.25684644e-03   3.18747801e-02  -4.83649828e-05\n",
      "  -2.67939775e-02   9.74076707e-03   1.85942881e-02   1.24826275e-02\n",
      "  -2.17771374e-03  -4.68531558e-03   1.65318610e-02  -7.70148862e-03\n",
      "  -4.53093356e-04   3.14170183e-03   5.68420569e-03   2.06413522e-03\n",
      "   6.46826867e-03   1.39458706e-02   7.86960621e-04   1.44683683e-02\n",
      "  -2.27745902e-03  -1.96257737e-03  -4.98108148e-03   1.09601473e-03\n",
      "   1.15702706e-02  -4.88663669e-04   5.55022096e-03  -2.14605097e-02\n",
      "   1.15699134e-02  -1.11456152e-02   1.79392008e-03  -9.65212770e-04\n",
      "  -4.01781367e-03  -2.66765009e-03   2.26317785e-02   2.62675659e-05\n",
      "  -1.10773527e-02   2.56231139e-02   3.64012285e-03   1.18579518e-03\n",
      "   6.27733309e-03   9.23497631e-03   1.62080369e-02   2.52564406e-02\n",
      "   7.51477522e-03  -2.06253158e-03   7.10767999e-03   1.40570235e-03\n",
      "   6.14302837e-03   1.19155039e-02   7.78394065e-03  -5.90404405e-03\n",
      "   1.82832533e-03   3.23915510e-03   9.65873192e-05  -4.56338311e-03\n",
      "  -7.07014263e-03   1.40139544e-02  -9.51349706e-03  -1.34675806e-02\n",
      "   4.32400248e-03   4.32495517e-03   3.97841646e-03   7.17472132e-03\n",
      "  -1.39945855e-02  -1.68467974e-02  -9.66305075e-03   1.60504493e-02\n",
      "   1.23255507e-03   6.79191690e-03  -2.96179842e-03  -2.38546597e-02\n",
      "  -7.90462629e-03  -1.30571703e-02  -9.85711479e-04   1.10375176e-02\n",
      "   2.34140539e-03   1.69988652e-02   1.65805489e-02  -4.31683382e-03\n",
      "   6.53745632e-03   1.43275687e-02  -1.28447464e-02   1.53071060e-02\n",
      "  -1.51665692e-02  -1.03113224e-02  -3.59152320e-03  -7.34195665e-04\n",
      "   6.31960286e-03   1.13752726e-03  -2.51985425e-03   6.72883109e-03\n",
      "   1.05660976e-02   4.02486207e-03   4.20284436e-03  -6.79560347e-03\n",
      "  -6.66788572e-03  -5.18571887e-03  -5.30564288e-03   7.62538054e-03\n",
      "  -6.82219998e-04  -2.58756882e-02   1.60720733e-02   3.64325227e-03\n",
      "  -1.36926145e-02   8.85965549e-03  -6.08703759e-03  -2.43360334e-03\n",
      "   2.86727818e-02  -1.08768390e-02  -1.10670555e-02   7.06415504e-03\n",
      "   6.29545874e-03   1.67114386e-02   2.66423131e-03   8.70040078e-04\n",
      "  -1.26650183e-02  -1.16223439e-03  -4.61444065e-03   1.12443631e-02\n",
      "  -6.52807044e-03   2.42937622e-04  -1.19337379e-02  -1.99760387e-02\n",
      "   2.54425996e-03  -2.08506154e-03  -2.02432775e-03  -6.02969191e-03\n",
      "   7.65383764e-03  -4.72874181e-03   1.77809952e-02  -1.45806668e-02\n",
      "   1.92331560e-03  -1.64423652e-03   1.51963304e-02   1.02336222e-02\n",
      "   5.04524088e-03   2.43555917e-04  -3.03444673e-03  -4.60696976e-03\n",
      "  -1.04928335e-02  -5.72604887e-03   5.84920778e-03   4.77405925e-03\n",
      "   1.19406516e-02   4.07472596e-03  -1.93495969e-03   1.42278470e-02\n",
      "  -6.40953767e-03  -7.15519049e-03   9.44585834e-03  -3.15805734e-03\n",
      "   1.99132209e-02   1.36058179e-02   3.28401758e-03   9.36933386e-04\n",
      "  -2.77298232e-02   1.75149988e-02  -1.12172287e-02   8.29564100e-03\n",
      "  -1.13648752e-02   1.20745985e-02   1.16299438e-02  -7.76033557e-03\n",
      "   9.58660938e-03  -9.81128668e-03  -7.01891847e-03   1.89040723e-02\n",
      "   6.08100699e-04  -1.55949339e-02   1.47368876e-03   5.40284637e-03\n",
      "   1.08121872e-03  -3.98831696e-03   2.64104700e-03   1.66084846e-02\n",
      "   8.20015834e-03  -1.80545218e-03  -1.52018644e-02   1.25828250e-02\n",
      "   1.04639226e-03   2.18510069e-03  -4.46118589e-03   2.65594848e-03\n",
      "  -1.41341777e-03  -1.02972093e-02   1.12638984e-02  -9.95874766e-04\n",
      "   7.03455949e-03   4.65672125e-03  -1.00189111e-03   1.38683847e-02\n",
      "  -5.79315488e-03  -7.92557103e-03  -6.39303663e-03   1.43947534e-02\n",
      "   7.89221383e-03  -9.02580717e-03   1.41391766e-02   1.13795110e-02\n",
      "   9.97864095e-04   1.92361880e-03   4.65610356e-03   9.56517716e-03\n",
      "  -1.20648781e-02   2.21202066e-03  -7.56610858e-03  -1.59140463e-02\n",
      "   1.47016665e-02  -3.72651362e-03  -1.05129558e-02  -1.15903027e-02\n",
      "   5.47858685e-03  -7.38039301e-03  -1.25416205e-02   5.04812993e-03\n",
      "  -2.50375041e-03  -9.64182127e-03   1.06434698e-02  -9.69211901e-03\n",
      "   9.88548112e-03  -5.84101852e-03  -6.41420916e-03  -2.72472152e-04\n",
      "  -1.03198516e-02  -1.88283584e-05   1.17215420e-02   1.04900717e-02\n",
      "  -1.11961182e-02  -7.96973804e-03  -8.23949385e-03   8.53354294e-03\n",
      "  -1.37106648e-04  -8.38620352e-03  -4.77263147e-03   2.54838106e-04\n",
      "  -3.07033373e-03   6.87926961e-03   1.37273834e-02  -1.32135102e-02\n",
      "   3.76477724e-03  -2.70994728e-03  -1.02458705e-02   6.57407824e-03\n",
      "  -2.17595903e-02  -7.30573375e-03  -1.35557353e-02  -9.36033449e-03]\n"
     ]
    }
   ],
   "source": [
    "print inputs_v[0]\n",
    "print inputs_m[0]\n",
    "print result[0][3][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "IN_ = T.matrix(dtype = 'int64')\n",
    "MASK = T.matrix(dtype = theano.config.floatX)\n",
    "\n",
    "IN = IN_.reshape((IN_.shape[0], IN_.shape[1], 1))\n",
    "\n",
    "wemb = theano.shared(np.random.rand(100, 300))\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, 1))\n",
    "\n",
    "# Masks input shape ==> (n_batch, n_time_steps)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None))\n",
    "\n",
    "#setting gates and cell parameters with specific nonlinearity functions\n",
    "gate_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                b=lasagne.init.Constant(0.))\n",
    "\n",
    "cell_parameters = lasagne.layers.recurrent.Gate(W_in=lasagne.init.Orthogonal(), \n",
    "                                                W_hid=lasagne.init.Orthogonal(),\n",
    "                                                # Setting W_cell to None denotes that no cell connection will be used. \n",
    "                                                W_cell=None, \n",
    "                                                b=lasagne.init.Constant(0.),\n",
    "                                                # By convention, the cell nonlinearity is tanh in an LSTM. \n",
    "                                                nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "# The embedding layers with retieve subtensor from word embedding matrix\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, input_size=wemb.get_value().shape[0], output_size=wemb.get_value().shape[1], W=wemb)\n",
    "\n",
    "l_drop = lasagne.layers.DropoutLayer(l_emb, p = 0.0)\n",
    "# The LSTM layer should have the same mask input in order to avoid padding entries\n",
    "l_lstm = lasagne.layers.recurrent.LSTMLayer(l_drop, \n",
    "                                            num_units=300,\n",
    "                                            # We need to specify a separate input for masks\n",
    "                                            mask_input=l_mask,\n",
    "                                            # Here, we supply the gate parameters for each gate \n",
    "                                            ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                            cell=cell_parameters, outgate=gate_parameters,\n",
    "                                            # We'll learn the initialization and use gradient clipping \n",
    "                                            learn_init=True\n",
    "                                            )\n",
    "\n",
    "\n",
    "# The back directional LSTM layers\n",
    "l_lstm_back = lasagne.layers.recurrent.LSTMLayer(l_drop,\n",
    "                                                 num_units=300,\n",
    "                                                 mask_input = l_mask,\n",
    "                                                 ingate=gate_parameters, forgetgate=gate_parameters, \n",
    "                                                 cell=cell_parameters, outgate=gate_parameters,\n",
    "                                                 # We'll learn the initialization and use gradient clipping \n",
    "                                                 learn_init=True,\n",
    "                                                 backwards=True\n",
    "                                                )\n",
    "\n",
    "\n",
    "# Do sum up of bidirectional LSTM results\n",
    "l_sum = lasagne.layers.ElemwiseSumLayer([l_lstm, l_lstm_back])\n",
    "out = lasagne.layers.get_output(l_sum, {l_in:IN, l_mask:MASK}, deterministic = True)\n",
    "\n",
    "test = theano.function([IN_, MASK], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.41805189e-01   4.65947280e-02  -8.36854174e-02   1.07350674e-01\n",
      "  -2.37396935e-01  -1.79823246e-01   6.51879467e-02   4.60637026e-03\n",
      "  -2.09297061e-01  -1.59060352e-01   2.93781539e-01   2.85348498e-01\n",
      "   8.93948845e-02   5.16647735e-02  -6.63083297e-01  -3.32605698e-01\n",
      "  -2.13643046e-01  -2.52780222e-02   3.30183841e-01  -1.86089749e-01\n",
      "   2.64025800e-01   1.07492811e-01   5.57596003e-02  -4.45173354e-01\n",
      "  -1.89919893e-01   1.83129174e-01   1.55992846e-01   6.95604518e-02\n",
      "   2.86514647e-01  -4.01425141e-01  -3.06143785e-02  -2.88565510e-01\n",
      "  -6.13725809e-01  -1.95180382e-01  -2.38842957e-01  -2.73882412e-01\n",
      "  -1.94990750e-02   1.82266075e-01  -2.67372722e-02   1.89460599e-01\n",
      "  -3.17284749e-01   1.24459833e-01   1.97643377e-02  -4.07787518e-02\n",
      "   1.33853864e-01  -1.82464355e-01   8.99734217e-02   3.00601495e-01\n",
      "   1.07841359e-01   1.00602480e-01  -1.10121118e-01  -1.49100513e-01\n",
      "   4.55662451e-02   3.19698477e-01  -2.52166452e-01  -5.48263467e-02\n",
      "  -1.66052223e-01   2.32730964e-01   2.44532437e-01   2.88979955e-02\n",
      "  -1.54972644e-01   3.11617652e-02  -2.86030581e-01  -1.80347307e-01\n",
      "  -5.80585754e-03  -3.50427965e-01  -2.00044557e-01  -2.23736678e-01\n",
      "   3.44473783e-01  -1.16633545e-01   1.20076037e-01   1.64516287e-01\n",
      "  -3.76728337e-02   1.43556057e-01  -2.14316441e-01   3.13081906e-02\n",
      "  -1.81261681e-01   2.59679044e-01   6.83491469e-02   3.15903151e-01\n",
      "   1.42963854e-01  -4.82822922e-02   3.07992117e-02   8.36729715e-02\n",
      "  -2.20836098e-01   1.08064683e-01  -3.52158981e-01   6.33299526e-02\n",
      "   5.38521374e-02   1.26293333e-01  -1.51400991e-01  -1.73199360e-01\n",
      "   4.93580934e-02   9.74224017e-02  -1.90682080e-01  -1.18575519e-01\n",
      "  -6.88681518e-02   2.02876577e-01   6.42778192e-02  -3.59663086e-01\n",
      "  -1.61170709e-01   2.73048496e-01   3.04291984e-01  -5.47830130e-02\n",
      "   3.80496389e-02   1.29263373e-01  -1.41486884e-01   4.22245969e-01\n",
      "   3.45574460e-01  -1.32493562e-01  -4.02829865e-01  -1.19528884e-01\n",
      "  -1.18042623e-01   1.17232048e-01  -1.19601572e-01  -1.17724887e-01\n",
      "  -2.09025329e-02  -1.03244352e-02  -2.28599887e-04  -2.17391905e-01\n",
      "   1.20204521e-01   6.17174912e-02   2.30203500e-01  -1.38244054e-01\n",
      "   4.94981929e-02   2.18195071e-01  -2.12267096e-01  -1.88235632e-01\n",
      "   4.21086305e-02  -2.39597071e-01   1.73129334e-02   1.25530104e-01\n",
      "   9.64885552e-02   1.03689624e-01   1.17677763e-01  -1.42404896e-01\n",
      "   3.03548037e-01   3.59071841e-01  -1.43170138e-01  -1.45115828e-01\n",
      "   1.31757523e-01  -1.50814769e-02  -3.40939391e-01  -1.83105860e-02\n",
      "  -4.58525958e-01  -7.63787368e-03   2.66319285e-01  -1.84122525e-01\n",
      "   9.95186823e-02  -1.29188925e-01   2.43182762e-01   3.90279821e-02\n",
      "   1.40789155e-01   2.02716717e-01  -4.32419332e-04  -2.22346982e-01\n",
      "  -8.41890580e-02   1.87262149e-01  -5.17058521e-02   1.75941274e-01\n",
      "  -6.09538677e-03   1.42833704e-01  -1.31358050e-01  -1.12612377e-01\n",
      "   8.57445285e-02   1.66430535e-01   2.43428334e-01  -1.03569232e-01\n",
      "   1.99629578e-01   4.40311666e-01   5.33493546e-02  -7.20940593e-03\n",
      "   1.90127928e-01   2.48668682e-01  -6.49166649e-02   4.41358638e-02\n",
      "   8.76208976e-02   3.78786052e-01   2.18508988e-01  -3.75633042e-02\n",
      "   2.85975905e-02   2.19808020e-01   2.47440780e-01  -2.58754165e-01\n",
      "   2.94155414e-01  -8.21444917e-02  -1.16559695e-01   1.00147221e-01\n",
      "  -1.00013320e-01  -3.05407031e-01  -3.54175547e-02  -1.88286286e-01\n",
      "   1.31801810e-01  -2.50033897e-01  -3.64544650e-01  -1.92514940e-01\n",
      "  -2.20179670e-01   6.71782634e-02  -1.91986005e-01   8.99862525e-02\n",
      "   4.58506849e-02  -3.21618118e-01   1.27360550e-01  -5.78044083e-02\n",
      "  -2.46030986e-01   2.14993254e-01   4.92059966e-01  -2.24785879e-01\n",
      "   1.54586488e-02  -1.07244769e-01   1.34986476e-01   1.35231754e-01\n",
      "   2.63036715e-01  -1.32974960e-01  -2.19755114e-01  -2.90404075e-01\n",
      "   1.88962878e-01   2.57108608e-01   1.59051415e-01   6.40235904e-01\n",
      "  -8.81937500e-02   2.83615642e-01   2.79403292e-01  -1.40605716e-01\n",
      "  -1.35850237e-01   1.16606192e-01  -1.90442652e-01  -8.30214388e-02\n",
      "  -1.62195090e-01  -3.84474590e-03   3.35333647e-01   1.17424547e-01\n",
      "  -1.20708468e-01   2.80735464e-02   9.40222540e-02   7.45179891e-02\n",
      "  -1.92942886e-01   6.96951262e-03   2.33246674e-01   3.22433086e-01\n",
      "  -2.32097845e-01   1.67652782e-01  -7.95807504e-01  -2.43798434e-01\n",
      "   3.55652130e-01   4.94266208e-02  -2.10341914e-01   5.86849788e-02\n",
      "  -3.29640513e-02   2.18896708e-01  -3.64652703e-01  -9.67156222e-02\n",
      "   9.51957111e-02   3.68453550e-01   1.62654674e-01   2.12130387e-01\n",
      "  -4.76252094e-03   2.39174365e-01  -4.83751075e-02   1.95502159e-01\n",
      "   2.20471606e-01  -2.59043233e-01   1.10918691e-01   1.01299499e-01\n",
      "   1.67898083e-02   9.50671082e-02   7.92833124e-02   9.29138265e-02\n",
      "  -9.03090968e-02  -1.59619268e-02   3.25049892e-01  -8.55021027e-02\n",
      "  -1.25485420e-01  -2.75248046e-01  -1.31954432e-01  -6.11103789e-02\n",
      "  -1.85230646e-01   2.45496488e-01  -2.40795010e-01  -4.03117173e-01\n",
      "   5.85117944e-02  -2.81123249e-01  -2.09622975e-01  -1.48278290e-01\n",
      "   7.75883161e-02   6.81594361e-02  -8.07407569e-02  -6.23219426e-02\n",
      "   6.91475017e-02   2.72539457e-02  -1.36219491e-01  -1.29714907e-01\n",
      "   1.23861649e-01  -8.22218655e-02  -1.64528626e-01   1.89155404e-01\n",
      "  -1.06625821e-01   6.45507821e-02   2.63013033e-01  -2.77682583e-02]\n"
     ]
    }
   ],
   "source": [
    "result = test(inputs_v[5], inputs_m[5])\n",
    "print result[4][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "\n",
    "b = T.sum(a, axis = 1).reshape([-1,1])\n",
    "\n",
    "c = T.matrix()\n",
    "d = c / b\n",
    "test = theano.function([a,c], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1.5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(np.array([[1,1]]), np.array([[3,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "\n",
    "b = theano.shared\n",
    "a_ = a.reshape((-1, a.shape[2]))\n",
    "b_ = b.reshape((1,b.shape[0],b.shape[1]))\n",
    "b_f = b_ + T.zeros((a_.shape[0], b.shape[0], b.shape[1]))\n",
    "result = T.batched_dot(a_, b_f).reshape((a.shape[0], a.shape[1], -1))\n",
    "loss = result.sum()\n",
    "\n",
    "test = theano.function([a,b], result)\n",
    "train  = theano.function([a,b], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-54a9fa44f2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jon/Library/Python/2.7/lib/python/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: batch sizes unequal. x.shape is (12, 1, 5), y.shape is (1, 5, 5).\nApply node that caused the error: BatchedDot(Reshape{2}.0, Reshape{3}.0)\nToposort index: 10\nInputs types: [TensorType(float64, matrix), TensorType(float64, (True, False, False))]\nInputs shapes: [(12, 5), (1, 5, 5)]\nInputs strides: [(40, 8), (200, 40, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-224-e5ff831dbdc9>\", line 6, in <module>\n    result = T.batched_dot(a_, b_).reshape((a.shape[0], a.shape[1], -1))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "a_test = np.arange(3*4*5).reshape((3,4,5))\n",
    "\n",
    "b_test = np.arange(5*5).reshape((5,5))\n",
    "\n",
    "testing = test(a_test, b_test)\n",
    "print testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "c = np.ones((5,5))\n",
    "c[0] = 0.0\n",
    "a = theano.shared(c)\n",
    "b = T.matrix()\n",
    "d = b*a\n",
    "test = theano.function([b], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "b = T.roll(a, shift = -4, axis = 0)\n",
    "test = theano.function([a],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   2.,   3.,   4.],\n",
       "       [  5.,   6.,   7.,   8.,   9.],\n",
       "       [ 10.,  11.,  12.,  13.,  14.],\n",
       "       [ 15.,  16.,  17.,  18.,  19.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t = np.arange(20).reshape(4,5)\n",
    "test(a_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,2,3,3])\n",
    "c = np.all(a-b==0)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   1.   2.   3.   4.]\n",
      "  [  5.   6.   7.   8.   9.]\n",
      "  [ 10.  11.  12.  13.  14.]\n",
      "  [ 15.  16.  17.  18.  19.]]\n",
      "\n",
      " [[ 20.  21.  22.  23.  24.]\n",
      "  [ 25.  26.  27.  28.  29.]\n",
      "  [ 30.  31.  32.  33.  34.]\n",
      "  [ 35.  36.  37.  38.  39.]]\n",
      "\n",
      " [[ 40.  41.  42.  43.  44.]\n",
      "  [ 45.  46.  47.  48.  49.]\n",
      "  [ 50.  51.  52.  53.  54.]\n",
      "  [ 55.  56.  57.  58.  59.]]]\n",
      "[[  0.   1.   2.   3.   4.]\n",
      " [  5.   6.   7.   8.   9.]\n",
      " [ 10.  11.  12.  13.  14.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   30.,    80.,   130.,   180.],\n",
       "       [  780.,   955.,  1130.,  1305.],\n",
       "       [ 2530.,  2830.,  3130.,  3430.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(3 * 4 * 5).reshape(3, 4, 5).astype('float32')\n",
    "b = np.arange(3 * 5).reshape(3, 5).astype('float32')\n",
    "\n",
    "A = T.ftensor3()\n",
    "B = T.fmatrix()\n",
    "\n",
    "# out1 = T.tensordot(A,B)\n",
    "out = (A * B.dimshuffle(0, 'x', 1)).sum(2)\n",
    "print a\n",
    "print b\n",
    "out.eval({A: a, B: b})\n",
    "# out1.eval({A:a, B:b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "a_ = T.nnet.softmax(a)\n",
    "b = T.imatrix()\n",
    "\n",
    "c = lasagne.objectives.categorical_crossentropy(a_, b)\n",
    "test = theano.function([a, b], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "dictionary = pickle.load(open('../../data/pickles/index_wemb_matrix.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.matrix()\n",
    "\n",
    "e_x = x.max(axis=1, keepdims=True)\n",
    "\n",
    "test = theano.function([x], e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import numpy as np\n",
    "wemb = theano.shared(np.arange(100*5).reshape(100,5))\n",
    "a = T.matrix()\n",
    "\n",
    "b = T.iscalar()\n",
    "\n",
    "c = T.arange(b)\n",
    "\n",
    "d = T.set_subtensor(a[c], wemb[c])\n",
    "\n",
    "test = theano.function([a,b], [a,d])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.]]), array([[  0.,   1.,   2.,   3.,   4.],\n",
       "        [  5.,   6.,   7.,   8.,   9.],\n",
       "        [ 10.,  11.,  12.,  13.,  14.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.,   1.]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test = np.ones((7,5))\n",
    "b = 3\n",
    "test(a_test, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "aa = T.iscalar()\n",
    "substi_word_index = (2 * srng.uniform((aa, ))).astype('int64')\n",
    "test = theano.function([aa], substi_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BLSTM_sequence\n",
    "import BLSTM_last\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "class Hierachi_RNN(object):\n",
    "    def __init__(self, rnn_setting, batchsize, wemb_size = None):\n",
    "        # Initialize Theano Symbolic variable attributes\n",
    "        self.story_input_variable = None\n",
    "        self.story_mask = None\n",
    "        self.story_nsent = 4\n",
    "\n",
    "        self.cost = None\n",
    "\n",
    "        self.train_func = None\n",
    "\n",
    "        # Initialize data loading attributes\n",
    "        self.wemb = theano.shared(np.random.rand(300, 300))\n",
    "        self.val_set_path = '../../data/pickles/val_index_corpus.pkl'\n",
    "        self.test_set_path = '../../data/pickles/test_index_corpus.pkl' \n",
    "        self.train_set_path = '../../data/pickles/train_index_corpus.pkl'\n",
    "        self.wemb_matrix_path = '../../data/pickles/index_wemb_matrix.pkl'\n",
    "\n",
    "        self.rnn_units = int(rnn_setting)\n",
    "        # self.mlp_units = [int(elem) for elem in mlp_setting.split('x')]\n",
    "        self.bilinear_matrix = theano.shared(0.002*np.random.rand(self.rnn_units, self.rnn_units)-0.001)\n",
    "        # self.dropout_rate = float(dropout_rate)\n",
    "        self.batchsize = int(batchsize)\n",
    "\n",
    "        # self.val_split_ratio = float(val_split_ratio)\n",
    "        self.words_num = 100\n",
    "\n",
    "        self.wemb_size = 300\n",
    "        if wemb_size == None:\n",
    "            self.random_init_wemb = False\n",
    "        else:\n",
    "            self.random_init_wemb = True\n",
    "            self.wemb_size = int(wemb_size)\n",
    "\n",
    "        self.train_story = None\n",
    "        self.train_ending = None\n",
    "\n",
    "        self.val_story = None\n",
    "        self.val_ending1 = None \n",
    "        self.val_ending2 = None\n",
    "        self.val_answer = None\n",
    "        self.n_val = None\n",
    "\n",
    "        self.test_story = None \n",
    "        self.test_ending1 = None\n",
    "        self.test_ending2 = None\n",
    "        self.test_answer = None\n",
    "        self.n_test = None\n",
    "\n",
    "        self.train_encodinglayer_vecs = []\n",
    "        self.test_encodinglayer_vecs = []\n",
    "        self.reasoninglayer_vec1 = []\n",
    "        self.reasoninglayer_vec2 = []\n",
    "        self.reasoninglayer_vec1_test = []\n",
    "        self.reasoninglayer_vec2_test = []\n",
    "        self.reasoning_pool_results = []\n",
    "        self.reasoning_pool_results_test = []\n",
    "        self.reasoners = []\n",
    "        self.attentioned_sent_rep1 = []\n",
    "        self.attentioned_sent_rep2 = []\n",
    "        self.bilinear_attention_matrix = theano.shared(0.02*np.random.rand(self.rnn_units, self.rnn_units) - 0.01)\n",
    "\n",
    "    def encoding_layer(self):\n",
    "\n",
    "\n",
    "        assert len(self.reshaped_inputs_variables)==len(self.inputs_masks)\n",
    "        for i in range(self.story_nsent + 1):\n",
    "            self.train_encodinglayer_vecs.append(lasagne.layers.get_output(self.encoder.output,\n",
    "                                                        {self.encoder.l_in:self.reshaped_inputs_variables[i], \n",
    "                                                         self.encoder.l_mask:self.inputs_masks[i]},\n",
    "                                                         deterministic = True))\n",
    "\n",
    "\n",
    "        end_representation = (self.train_encodinglayer_vecs[-1] * self.inputs_masks[4].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[4].sum(axis = 1, keepdims = True)\n",
    "\n",
    "        #The last one (index-5) is the average of the non-attentioned ending sequence\n",
    "        self.train_encodinglayer_vecs.append(end_representation)\n",
    "        \n",
    "    def attention1_layer(self):        \n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "            #second attention\n",
    "\n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention1_score_tensor = T.batched_dot(bili_part1, self.train_encodinglayer_vecs[5])\n",
    "\n",
    "            numerator1 = self.inputs_masks[i] * T.exp(attention1_score_tensor - attention1_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention1_weight_matrix = numerator1 / numerator1.sum(axis = 1, keepdims = True)\n",
    "\n",
    "            attentioned_sent_seq1 = self.train_encodinglayer_vecs[i]*(attention1_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "            attentioned_sent_rep1 = T.sum(attentioned_sent_seq1, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep1.append(attentioned_sent_rep1)\n",
    "\n",
    "    def attention2_layer(self):\n",
    "        for i in range(self.story_nsent):\n",
    "            n_batch, n_seq, _ = self.train_encodinglayer_vecs[i].shape\n",
    "\n",
    "            #second attention\n",
    "\n",
    "            bili_part1 = T.dot(self.train_encodinglayer_vecs[i], self.bilinear_attention_matrix)\n",
    "\n",
    "            attention2_score_tensor = T.batched_dot(bili_part1, self.vt_2nd_end_repr)\n",
    "\n",
    "            numerator2 = self.inputs_masks[i] * T.exp(attention2_score_tensor - attention2_score_tensor.max(axis = 1, keepdims = True))\n",
    "        \n",
    "            attention2_weight_matrix = numerator2 / numerator2.sum(axis = 1, keepdims = True)\n",
    "\n",
    "            attentioned_sent_seq2 = self.train_encodinglayer_vecs[i]*(attention2_weight_matrix.reshape([n_batch, n_seq, 1]))\n",
    "\n",
    "            attentioned_sent_rep2 = T.sum(attentioned_sent_seq2, axis = 1) / T.sum(self.inputs_masks[i], axis = 1).reshape([-1, 1])\n",
    "\n",
    "            self.attentioned_sent_rep2.append(attentioned_sent_rep2)\n",
    "           \n",
    "    def model_constructor(self, wemb_size = None):\n",
    "        self.inputs_variables = []\n",
    "        self.inputs_masks = []\n",
    "        self.reshaped_inputs_variables = []\n",
    "        self.vt_2nd_end = T.matrix('second_end', dtype='int64')\n",
    "        self.vt_2nd_end_mask = T.matrix('second_end_mask', dtype=theano.config.floatX)\n",
    "\n",
    "        for i in range(self.story_nsent+1):\n",
    "            self.inputs_variables.append(T.matrix('story'+str(i)+'_input', dtype='int64'))\n",
    "            self.inputs_masks.append(T.matrix('story'+str(i)+'_mask', dtype=theano.config.floatX))\n",
    "            batch_size, seqlen = self.inputs_variables[i].shape\n",
    "            self.reshaped_inputs_variables.append(self.inputs_variables[i].reshape([batch_size, seqlen, 1]))\n",
    "\n",
    "        #initialize neural network units\n",
    "        self.encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.encoder.build_model(self.wemb)\n",
    "\n",
    "        #build encoding layer\n",
    "        self.encoding_layer()\n",
    "\n",
    "        '''============================================================================'''\n",
    "        #encode possible second ending\n",
    "        self.encode_2nd_end_seq = lasagne.layers.get_output(self.encoder.output,\n",
    "                                                    {self.encoder.l_in:self.vt_2nd_end, \n",
    "                                                     self.encoder.l_mask:self.vt_2nd_end_mask},\n",
    "                                                     deterministic = True)\n",
    "\n",
    "        self.vt_2nd_end_repr = (self.encode_2nd_end_seq * self.vt_2nd_end_mask.dimshuffle(0,1,'x')).sum(axis = 1) / self.vt_2nd_end_mask.sum(axis = 1, keepdims = True)\n",
    "        '''============================================================================'''\n",
    "\n",
    "        #build attention layer\n",
    "        self.attention1_layer()\n",
    "        self.attention2_layer()\n",
    "        #build reasoning layers\n",
    "        \n",
    "        self.test1 = theano.function(self.inputs_variables + self.inputs_masks, self.train_encodinglayer_vecs[5], on_unused_input='ignore')\n",
    "        # merge tensors to fit in BLSTM models as input tensor\n",
    "        # merge_ls1.shape = (n_batch, m_seq, self.rnn_units)\n",
    "        self.merge_ls1 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep1]\n",
    "        self.merge_ls2 = [T.reshape(tensor, (tensor.shape[0], 1, tensor.shape[1])) for tensor in self.attentioned_sent_rep2]\n",
    "        encode_merge1 = T.concatenate(self.merge_ls1, axis = 1)\n",
    "        encode_merge2 = T.concatenate(self.merge_ls2, axis = 1)\n",
    "        self.test2 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [encode_merge1, encode_merge2])\n",
    "        # create sentence level encoder\n",
    "        # using only last encoding result of both direction of the LSTM\n",
    "        self.sent_encoder = BLSTM_last.BlstmEncoder(INPUT_SIZE = self.rnn_units, LSTMLAYER_1_UNITS = self.rnn_units)\n",
    "        self.sent_encoder.build_model()\n",
    "\n",
    "        # reasoner_result1.shape = (n_batch, self.rnn_units)\n",
    "        reasoner_result1 = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge1}, \n",
    "                                                    deterministic = True)\n",
    "\n",
    "        reasoner_result2 = lasagne.layers.get_output(self.sent_encoder.output, {self.sent_encoder.l_in: encode_merge2}, \n",
    "                                                    deterministic = True)\n",
    "        self.test3 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [reasoner_result1, reasoner_result2])\n",
    "        # self.train_encodinglayer_vecs[4].shape == (n_batch, m_seq, 300)\n",
    "        end_attention_part1 = T.dot(self.train_encodinglayer_vecs[4], self.bilinear_attention_matrix)\n",
    "        end_attention = T.batched_dot(end_attention_part1, reasoner_result1)\n",
    "\n",
    "\n",
    "        end_att_numerator1 = self.inputs_masks[4] * T.exp(end_attention - end_attention.max(axis = 1, keepdims = True))\n",
    "    \n",
    "        end_attention_weight_matrix = end_att_numerator1 / end_att_numerator1.sum(axis = 1, keepdims = True)\n",
    "        self.test3_1 = theano.function(self.inputs_variables + self.inputs_masks, end_attention_weight_matrix)\n",
    "        # end_attention_weight_matrix.shape = (n_batch, m_seq)\n",
    "        # neg_ending_rep.shape == (n_batc, m_seq)\n",
    "        # neg_ending_subs_index is the one to be substituted in the original sentence\n",
    "        neg_ending_subs_index = T.argmax(end_attention_weight_matrix, axis = 1)\n",
    "        n_batch = self.train_encodinglayer_vecs[0].shape[0]\n",
    "\n",
    "        # substi_word_index is the random index generate to surrogate the original ones\n",
    "        srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "        substi_word_index = (self.words_num * srng.uniform((n_batch, ))).astype('int64')\n",
    "        self.test3_2 = theano.function(self.inputs_variables + self.inputs_masks, substi_word_index, on_unused_input = 'ignore')\n",
    "        batch_dim = T.arange(n_batch)\n",
    "        self.test3_3 = theano.function(self.inputs_variables + self.inputs_masks, batch_dim, on_unused_input = 'ignore')\n",
    "        # set_subtensor won't change the original tensor\n",
    "        # new_end_seq_tensor.shape = (self.batchsize, m_seq, 300)\n",
    "        new_end_seq_tensor = T.set_subtensor(self.train_encodinglayer_vecs[4][batch_dim, neg_ending_subs_index], self.wemb[substi_word_index])\n",
    "        # neg_end_rep.shape = (self.batchsize, self.rnn_units)\n",
    "        self.test3_4 = theano.function(self.inputs_variables + self.inputs_masks, new_end_seq_tensor)\n",
    "        neg_end_rep = (new_end_seq_tensor * self.inputs_masks[4].dimshuffle(0,1,'x')).sum(axis = 1) / self.inputs_masks[4].sum(axis = 1, keepdims = True)\n",
    "        self.test4 = theano.function(self.inputs_variables + self.inputs_masks, neg_end_rep)\n",
    "        \n",
    "        l_story_in = lasagne.layers.InputLayer(shape=(None, self.rnn_units))\n",
    "        l_end_in = lasagne.layers.InputLayer(shape = (None, self.rnn_units))\n",
    "        l_concate = lasagne.layers.ConcatLayer([l_story_in, l_end_in], axis = 1)\n",
    "        \n",
    "        l_hid = lasagne.layers.DenseLayer(l_concate, num_units=2,\n",
    "                                          nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        final_class_param = lasagne.layers.get_all_params(l_hid)\n",
    "        answer = (2 * srng.uniform((n_batch,))).astype('int64')\n",
    "\n",
    "        ending_pair_tensor1 = self.train_encodinglayer_vecs[-1] * (1-answer).dimshuffle(0,'x') + neg_end_rep * answer.dimshuffle(0,'x')\n",
    "        ending_pair_tensor2 = self.train_encodinglayer_vecs[-1] * (answer).dimshuffle(0,'x') + neg_end_rep * (1-answer).dimshuffle(0,'x')\n",
    "        self.test5 = theano.function(self.inputs_variables + self.inputs_masks, [ending_pair_tensor1, ending_pair_tensor2])\n",
    "\n",
    "        score1 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: ending_pair_tensor1})\n",
    "        score2 = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result1, \n",
    "                                                   l_end_in: ending_pair_tensor2})\n",
    "\n",
    "        vt_2nd_score = lasagne.layers.get_output(l_hid, {l_story_in: reasoner_result2, \n",
    "                                                   l_end_in: self.vt_2nd_end_repr})\n",
    "        self.test6 = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [score1, score2, vt_2nd_score])\n",
    "\n",
    "\n",
    "        prob1 = lasagne.nonlinearities.softmax(score1)\n",
    "        prob2 = lasagne.nonlinearities.softmax(score2)\n",
    "\n",
    "\n",
    "        # Construct symbolic cost function\n",
    "        \n",
    "        cost1 = lasagne.objectives.categorical_crossentropy(prob1, answer)\n",
    "        cost2 = lasagne.objectives.categorical_crossentropy(prob2, 1-answer)\n",
    "\n",
    "        self.cost = lasagne.objectives.aggregate(cost1+cost2, mode='sum')\n",
    "\n",
    "        # Retrieve all parameters from the network\n",
    "        all_params = self.encoder.all_params + self.sent_encoder.all_params + final_class_param + [self.bilinear_attention_matrix]\n",
    "\n",
    "        all_updates = lasagne.updates.adam(self.cost, all_params, learning_rate=0.001)\n",
    "        # all_updates = lasagne.updates.momentum(self.cost, all_params, learning_rate = 0.05, momentum=0.9)\n",
    "\n",
    "        self.train_func = theano.function(self.inputs_variables + self.inputs_masks, \n",
    "                                        [self.cost, prob1, prob2, answer], updates = all_updates)\n",
    "\n",
    "        # Compute adam updates for training\n",
    "\n",
    "        self.prediction = theano.function(self.inputs_variables + [self.vt_2nd_end] + self.inputs_masks + [self.vt_2nd_end_mask], [score1, vt_2nd_score])\n",
    "        # pydotprint(self.train_func, './computational_graph.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Hierachi_RNN(rnn_setting = '300', batchsize = '20')\n",
    "\n",
    "a.model_constructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "\n",
    "v = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        v[i].append(np.random.randint(100, size=(leng_v[i+j], )))\n",
    "        \n",
    "inputs_v = [utils.padding(sentence) for sentence in v]\n",
    "\n",
    "inputs_m = [utils.mask_generator(sentence) for sentence in v]\n",
    "\n",
    "result = a.test3_4(inputs_v[0], inputs_v[1], inputs_v[2], inputs_v[3], inputs_v[4],\n",
    "                 inputs_m[0], inputs_m[1], inputs_m[2], inputs_m[3], inputs_m[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one line cases\n",
    "leng_v = np.random.randint(5, 17, size=(30))\n",
    "test_inputs = [np.random.randint(100, size=(1,leng_v[j])) for i in range(6) for j in range(6)]\n",
    "\n",
    "test_masks = [np.ones_like(sent) for sent in test_inputs]\n",
    "\n",
    "result = a.test3_4(test_inputs[0],test_inputs[1],test_inputs[2],test_inputs[3],test_inputs[4],\n",
    "                test_masks[0], test_masks[1], test_masks[2], test_masks[3],test_masks[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 300)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "n_batch = a.shape[0]\n",
    "neg_ending_subs_index = T.ivector()\n",
    "srng = T.shared_randomstreams.RandomStreams(seed=234)\n",
    "substi_word_index = (100 * srng.uniform((1, n_batch))).astype('int64')\n",
    "batch_dim = T.arange(n_batch)\n",
    "wemb = theano.shared(np.arange(100*5).reshape(100,5))\n",
    "\n",
    "new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n",
    "\n",
    "test1 = theano.function([a, neg_ending_subs_index], new_end_seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array is not broadcastable to correct shape\nApply node that caused the error: AdvancedIncSubtensor1{inplace,set}(AdvancedSubtensor1.0, Reshape{3}.0, <TensorType(int32, vector)>)\nToposort index: 12\nInputs types: [TensorType(float64, 3D), TensorType(int64, (True, False, False)), TensorType(int32, vector)]\nInputs shapes: [(7, 8, 5), (1, 7, 5), (7,)]\nInputs strides: [(320, 40, 8), (280, 40, 8), (4,)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-d77298e604ac>\", line 9, in <module>\n    new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a69ae3bd09b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtensorA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msub_index_ls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_index_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array is not broadcastable to correct shape\nApply node that caused the error: AdvancedIncSubtensor1{inplace,set}(AdvancedSubtensor1.0, Reshape{3}.0, <TensorType(int32, vector)>)\nToposort index: 12\nInputs types: [TensorType(float64, 3D), TensorType(int64, (True, False, False)), TensorType(int32, vector)]\nInputs shapes: [(7, 8, 5), (1, 7, 5), (7,)]\nInputs strides: [(320, 40, 8), (280, 40, 8), (4,)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [['output']]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home-nfs/jontsai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-d77298e604ac>\", line 9, in <module>\n    new_end_seq_tensor = T.set_subtensor(a[batch_dim][neg_ending_subs_index], wemb[substi_word_index])\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "tensorA = np.random.rand(7, 8, 5)\n",
    "sub_index_ls = np.asarray([2,6,4,3,2,2,0]).astype('int32')\n",
    "result = test1(tensorA, sub_index_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.],\n",
       "       [ 235.,  236.,  237.,  238.,  239.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.tensor3()\n",
    "b = T.ivector()\n",
    "c = T.ivector()\n",
    "d = T.ivector()\n",
    "e = theano.shared(np.random.rand(100, 5))\n",
    "\n",
    "f = T.set_subtensor(a[b,c], e[d])\n",
    "test = theano.function([a,b,c,d], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_ = np.arange(6*15*5).reshape(6,15,5)\n",
    "b_ = np.arange(6).astype('int32')\n",
    "c_ = np.random.randint(15, size=(6,)).astype('int32')\n",
    "d_ = np.random.randint(100, size=(6,)).astype('int32')\n",
    "result = test(a_, b_, c_, d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  0  0 14 14  5]\n",
      "[62 69 37 24 60 33]\n"
     ]
    }
   ],
   "source": [
    "print c_\n",
    "print d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3669229 ,  0.0759273 ,  0.34172383,  0.78630821,  0.60700849])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "index2word_dic = pickle.load(open('../../data/pickles/ROC_train_index_dict.pkl'))\n",
    "\n",
    "wemb_matrix = pickle.load(open('../../data/pickles/index_wemb_matrix.pkl'))\n",
    "\n",
    "train_set = pickle.load(open('../../data/pickles/train_index_corpus.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Title + story plot \n",
    "import numpy as np\n",
    "\n",
    "story_set = np.asarray(train_set[0])\n",
    "\n",
    "story_n = len(end_set)\n",
    "story_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    story_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k][j]] for j in range(len(story_set[i][k]))) for k in range(5))/5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# story plot \n",
    "\n",
    "story_set = np.asarray(train_set[0])\n",
    "\n",
    "story_n = len(end_set)\n",
    "storyplot_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    storyplot_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k][j]] for j in range(len(story_set[i][k]))) for k in range(1, 5))/4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "end_set = np.asarray(train_set[1])\n",
    "\n",
    "story_n = len(end_set)\n",
    "end_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    end_rep_matrix[i] = np.sum(wemb_matrix[end_set[i]], axis = 0)/(len(end_set[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2]),\n",
       " array([3, 4, 5, 6, 1, 7]),\n",
       " array([ 3,  8,  1,  9, 10,  7]),\n",
       " array([11, 12, 13, 14,  5, 15,  8, 16,  7]),\n",
       " array([14,  5, 17, 18, 19, 20, 21, 22, 23,  7]),\n",
       " array([24, 25, 26, 18,  3, 27, 22, 28,  7])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# story plot + ending\n",
    "\n",
    "\n",
    "story_set = new_train_set\n",
    "\n",
    "story_n = len(end_set)\n",
    "storyplotNend_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    storyplotNend_rep_matrix[i] = np.sum(np.sum(wemb_matrix[story_set[i][k]],axis = 0) for k in range(1,6))/5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_simi(rep_matrix, story_n):    \n",
    "    normalized_matrix_vec = np.linalg.norm(rep_matrix, axis = 1)\n",
    "\n",
    "\n",
    "    most_similar_pair = np.zeros((story_n, 1))\n",
    "    for i in range(story_n):\n",
    "        dot_vec = np.dot(rep_matrix[i], rep_matrix.T)\n",
    "        norm_vec = np.asarray([normalized_matrix_vec[i] * normalized_matrix_vec[j] for j in range(story_n)])\n",
    "        cos_vec = dot_vec / norm_vec\n",
    "        most_similar_pair[i] = np.argsort(cos_vec)[-2]\n",
    "    return most_similar_pair\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,34]).reshape(-1,1)\n",
    "b = np.array([1,2,33]).reshape(-1,1)\n",
    "\n",
    "c = np.dot(a,b.T)\n",
    "d = np.argmax(c, axis = 0)\n",
    "print d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_simi_story_pair = cos_simi(story_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_simi_storyplot_pair = cos_simi(storyplot_rep_matrix, story_n)\n",
    "most_simi_end_pair = cos_simi(end_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_simi_storyplotNend_pair = cos_simi(storyplotNend_rep_matrix, story_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle.dump(most_simi_story_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_story_pair.pkl', 'w'))\n",
    "pickle.dump(most_simi_storyplot_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_storyplot_pair.pkl','w'))\n",
    "pickle.dump(most_simi_end_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_end_pair.pkl','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(most_simi_storyplotNend_pair.reshape(-1,).astype('int32'), open('../../data/pickles/most_simi_storyplotNend_pair.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert(nump_matrix):\n",
    "    return nump_matrix.reshape(-1,).astype('int32')\n",
    "\n",
    "most_simi_end_pair = convert(most_simi_end_pair)\n",
    "most_simi_story_pair = convert(most_simi_story_pair)\n",
    "most_simi_storyplot_pair = convert(most_simi_storyplot_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_simi_storyPNend_pair = convert(most_simi_storyplotNend_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3665,   899, 11902, 10411, 18049, 32872, 23746,  4604, 15949, 34794], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_storyPNend_pair[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance # 0\n",
      "dental adventures | one day , sally was eating nuts and heard a crack . | she had bitten into a shell and cracked her tooth ! | the tooth hurt very badly . | she called her dentist . | the dentist saw her later that day and fixed her tooth .\n",
      "==================most similar end pairs====================\n",
      "loose tooth | tricia had a loose tooth . | she was eating her cereal one morning . | her tooth was hanging on by just a little bit . | tricia bit into something hard . | she realized her tooth had come out in her cereal .\n",
      "\n",
      "instance # 1\n",
      "meeting an old friend | i recently met an old friend . | i accompanied him while he ran various errands . | we went to his job , his house , and a thrift shop . | i quite enjoyed playing around in the thrift shop . | the day wasn 't exciting , but i enjoyed my friend 's company .\n",
      "==================most similar end pairs====================\n",
      "keeping lips closed | i was walking to the local coffee shop . | as soon as i looked around , i can into my friend don . | he was kissing another female other than his wife . | he saw me in the shop and begged me not to tell anyone . | since we 're close friends , i kept his promise .\n",
      "\n",
      "instance # 2\n",
      "michelle 's first job | michelle wanted to work at a clothing store . | she applied to many clothing stores in her town . | michelle went to a couple of interviews . | her top choice called her a week later to hire her . | michelle was so excited to start working at her new job !\n",
      "==================most similar end pairs====================\n",
      "the interview | lexi just turned 16 . | she wanted to get a part time job to earn some money . | she went from store to store in the mall . | at her fifth stop they wanted to interview her immediately . | she was hired on the spot at a jewelry store .\n",
      "\n",
      "instance # 3\n",
      "tim and the bully . | tim got picked on at school by a bully . | every day the bully would pull his hair . | tim told the teacher , but that just made the bully more upset . | tim decided to stick with a large group of friends . | the bully never picked on him again .\n",
      "==================most similar end pairs====================\n",
      "tiny tim | tim was very tiny for his age and got bullied . | he was very fed up with his bully and decided to confront him . | the bully just laughed because tim was so small . | but tim used his arms to trip up the bully 's long legs . | the bully fell hard and never messed with tim again .\n",
      "\n",
      "instance # 4\n",
      "down the street | jackson and gloria were childhood friends . | they had grown up on the same street . | they had attended 12 consecutive years of school together . | then jackson 's family moved out of the state . | they never spoke again .\n",
      "==================most similar end pairs====================\n",
      "reconnecting | bonnie hadn 't seen her high school boyfriend in years . | at their ten year reunion they talked all night . | they were both still single . | they got together and started dating again . | they were married the following year .\n",
      "\n",
      "instance # 5\n",
      "broken phone | the other day i was talking on my cell phone to my friend . | while walking through the house , the phone slipped out of my hand . | the phone dropped and shattered . | i was upset because i loved the phone . | luckily it had a protector on it so it was okay .\n",
      "==================most similar end pairs====================\n",
      "pool jump | i was in my friend 's backyard by a pool . | i put on a silly voice and jumped into the pool . | after jumping in , i remembered that i left my phone in my pocket . | i climbed out of the water to check on my phone , but it was broken . | i had to leave my friend 's house to get a new phone .\n",
      "\n",
      "instance # 6\n",
      "guns | joe was afraid of guns . | one day his uncle took him to a shooting range . | he taught him how to shoot the gun . | but the gun had a huge recoil and flew out of his hand ! | joe is now even more afraid of guns .\n",
      "==================most similar end pairs====================\n",
      "gun jam | hank drove to the shooting range with his guns one day . | he walked up the targets with his guns . | just as he prepared to shoot , his gun became jammed . | hank spent over an hour trying to fix the gun . | he eventually gave up and used a different gun , then went home .\n",
      "\n",
      "instance # 7\n",
      "the hard way | two women decided to race to the top of a mountain . | the first woman meticulously planned her climb . | she charted out her route with great care . | when she arrived at the summit , she found that she had been beaten . | the other woman had taken the ski lift .\n",
      "==================most similar end pairs====================\n",
      "losing the competition . | alison had entered her painting into a contest . | she had made it all the way to nationals . | there , her painting was in the top ten . | she was waiting to see if she would win . | unfortunately , she only got third place .\n",
      "\n",
      "instance # 8\n",
      "ring ring | i called the insurance company . | i needed to find a new doctor . | the woman on the phone said i wasn 't a member . | i was at a loss for words . | it took her five minutes to realize she had entered my number wrong .\n",
      "==================most similar end pairs====================\n",
      "first car accident | i had just gotten a new job as a swim coach the day before . | on the second day of practice , i decided to take a new way to work . | while stopping , i noticed a man behind me who was not stopping . | the man ran into the back of my car like i wasn 't even there . | no one was hurt but my bank account .\n",
      "\n",
      "instance # 9\n",
      "recess mishap | joey fell off the jungle gym during recess . | the nurse called his mom to pick joey up . | joey 's mom brought him to the doctor . | the doctor had to put a cast on joey 's broken wrist . | the next day , joey let his classmates sign his cast .\n",
      "==================most similar end pairs====================\n",
      "baseball injury | jake was playing catch with his dad . | jake threw a baseball for his dad to catch . | his dad missed , and the baseball hit him right in the face . | jake got his father some ice to put on his face after . | his dad had to miss work the very next day .\n",
      "\n",
      "instance # 10\n",
      "inti | i do volunteer work for a non profit group called inti . | the group runs a soccer and art school for poor kids . | today my director sent me a grant proposal to proofread . | i made a few edits and returned the proposal . | i hope we get the $35,000 grant .\n",
      "==================most similar end pairs====================\n",
      "community service | my teacher assigned our class a community service project . | i wasn 't sure how to approach the task . | my dad suggested asking a nearby food bank if they need volunteers . | i called the food bank and made an appointment for orientation . | i went to help sort donations and got an a on the project .\n",
      "\n",
      "instance # 11\n",
      "can you smell that smell ? | cora walked into the kitchen and noticed a bad odor . | she looked in the trash can to see if the smell was coming from there . | the trash didn 't smell , so cora checked the cabinets . | nothing was smelly in the cabinets , so cora checked the sink . | she realized that a nasty smell was wafting from the garbage disposal !\n",
      "==================most similar end pairs====================\n",
      "the skunk which scared me | there once was a horrid smell in the house . | it smelled so bad , that i had to find the source . | it led me to my wardrobe,which was opened a bit . | i almost gagged in horror when i smelled the odor from the wardrobe | and then a skunk popped out , causing me to shriek loudly ! \n",
      "\n",
      "instance # 12\n",
      "delivery | tina 's water broke one night . | she hurried to the hospital . | they set her up on medicine and encouraged her . | she struggled through the birth of her baby . | and after sixteen hours , tina became a mommy !\n",
      "==================most similar end pairs====================\n",
      "too fast | karen was 9 months pregnant . | she was very ready to have her baby . | one night she was woken up by her water breaking . | her and her husband began their 30 minute drive to the hospital . | the baby couldn 't wait and was born in the car .\n",
      "\n",
      "instance # 13\n",
      "the old roller coaster | when i was a child i used to go to a local amusement park . | the park had one of the oldest roller coasters in the usa . | i went on it once and it felt shaky and unsafe . | i decided i would never go on it again since i valued my safety . | i recently heard that the park had finally tore it down .\n",
      "==================most similar end pairs====================\n",
      "space mountain ride | my cousin and i were about to go on the space mountain ride at disney . | i had never been on a coaster before and was freaked out . | as i got in the car and put the bar close to me , i shut my eyes . | the ride took off and i was freaking out . | thankfully it was over before i knew it .\n",
      "\n",
      "instance # 14\n",
      "painting | for valentine 's day andrew wanted to paint a portrait of her . | he got one of her pictures that he had . | he spent a week painting the portrait . | valentines day finally arrived . | his girlfriend loved the picture .\n",
      "==================most similar end pairs====================\n",
      "locket | rod bought his mom a locket for her birthday . | he wondered what pictures to put in it . | then he had a great idea . | he printed tiny copies of images of him and his sister . | he gave them to his mom in her new locket .\n",
      "\n",
      "instance # 15\n",
      "caught cheating . | harley was walking up his apartment stairs . | he walked inside and noticed a man 's pair of shoes . | that 's when he heard noises in the bedroom . | he caught his wife sleeping with someone else . | he didn 't know what to do so he just threw both of them out .\n",
      "==================most similar end pairs====================\n",
      "the scared kid . | max was asleep in his bed . | suddenly he woke up . | he thought that he saw something scary outside of his window . | he ran to his mom 's room and woke her up . | she checked for him but there was nothing there .\n",
      "\n",
      "instance # 16\n",
      "the end of friendship | brian and josh were friends . | one day , brian got mad at josh . | josh didn 't understand why brian was mad . | brian would not talk to josh . | brian and josh are no longer friends .\n",
      "==================most similar end pairs====================\n",
      "fight | brian found out matt was talking about him online . | matt was insulting brian . | matt decides to stop by brian 's house . | brian 's brother comes out . | brian 's brother beats matt up .\n",
      "\n",
      "instance # 17\n",
      "jimmy had to sell his shop | jimmy and his long time partner owned a hot dog shop together | they started getting into disputes over running the business | they decided to sell the place | it went up for auction and they each ended up bidding for it | jimmy 's partner won the auction from jimmy for 300k\n",
      "==================most similar end pairs====================\n",
      "mike 's unemployed | mike quit his job one day and then needed to find a source of income . | mike lived on savings for a while before deciding to start a business . | he came up with the idea for a t shirt company and bought the tools . | after designing some t shirts and a website , mike began to get work . | mike 's t shirt business began to kick off and he was a success .\n",
      "\n",
      "instance # 18\n",
      "can 't get away | maurice moved to florida to get away from his ex . | after moving into his new house , he looked around his yard . | he turned to his right at the house next door . | standing in the yard was his ex . | she had moved in next door .\n",
      "==================most similar end pairs====================\n",
      "crushed finger | william went to his school to pick up his class schedule . | he walked into the front office . | he picked up his schedule from a lady at the front desk . | while leaving the office , william closed his finger between the doors . | he yelped in pain , then left the school and treated his injury .\n",
      "\n",
      "instance # 19\n",
      "the promotion | john had worked for his company for many years . | he worked hard and often did more than his job required . | one day , john 's boss called him into an empty office . | he told john that the company appreciated all his work over the years . | finally , he told john that john was getting a promotion and a raise !\n",
      "==================most similar end pairs====================\n",
      "modern family | john was a hard worker at his job . | he spent at least 50 hours a week on his new business he started . | however , his wife and children has begun to feel neglected . | john saw how much they wanted to be with him . | so john quit his old job to take care of his family more\n",
      "\n",
      "instance # 20\n",
      "painting | maria wanted to learn to paint . | she signed up for a class . | she attended the class diligently . | by the end of the class , she wasn 't as good as she wanted to be . | she vowed to practice even more , every single day .\n",
      "==================most similar end pairs====================\n",
      "art teacher | bianca likes to teach art to children . | she set up an art studio to give classes to them . | the first day she had all of her seats filled for the class . | she taught them new techniques and terms they would be using . | at the end of the day she felt that it had been a success .\n",
      "\n",
      "instance # 21\n",
      "minecraft | jay 's son loved playing the game minecraft . | jay was curious and wanted to see what it was all about . | he logged on and tried to play the game himself . | but he was completely lost and confused . | jay could not figure out minecraft at all !\n",
      "==================most similar end pairs====================\n",
      "chess | i tried to play internet chess with my friend last night . | it was only 8 pm . | he refused to play , saying he was tired . | i played other people on the net instead . | it was fun , but not as fun as playing someone i knew .\n",
      "\n",
      "instance # 22\n",
      "anger at friends | i found out that my friend had been lying to me . | he had also stolen all of my money . | when i confronted him , he said i was crazy . | when he said this , i provided proof . | we are no longer friends .\n",
      "==================most similar end pairs====================\n",
      "blamed | when i was seven i was accused of stealing my father 's glasses . | i kept telling my parents that i didn 't . | they did not believe me . | eventually , the glasses were found on a table where my dad left them . | he never apologized for blaming me which makes me mad to this day .\n",
      "\n",
      "instance # 23\n",
      "the ball | zeke had a dog . | the dog loved to play catch . | one day , the dog 's favorite ball got lost . | the dog was sad . | zeke bought the dog a new ball and the dog was happy again .\n",
      "==================most similar end pairs====================\n",
      "loose dog | jim always walked to school . | but one day he heard a dog barking . | he looked behind him . | and it was a loose dog . | luckily , the owner caught the dog in time .\n",
      "\n",
      "instance # 24\n",
      "practice makes perfect | jane 's tennis serve was awful ! | her overall play was very good except for her serve . | jane realized she needed professional training . | she hired the best tennis trainer and she practiced every day . | jane won the next tennis match and , eventually , the championship !\n",
      "==================most similar end pairs====================\n",
      "illness | frankie loved tennis . | she was the star of her team . | she got sick and could not play for three weeks . | she worked hard to get her game back . | she eventually won the school tournament .\n",
      "\n",
      "instance # 25\n",
      "leg lifts | my goal is to leg lift over two hundred pounds at the gym . | right now i can only leg lift about one hundred pounds . | i got a trainer and worked hard for months . | the trainer helped me to push myself further and further . | months later i was able to reach my goal .\n",
      "==================most similar end pairs====================\n",
      "lifting | i 've always wanted to be able to lift four hundred pounds over my head . | right now i can lift about three hundred pounds that high . | i got myself a trainer and worked real head for a year . | i ate right and got plenty of sleep . | about a year later i became stronger and reached my goal !\n",
      "\n",
      "instance # 26\n",
      "stinky breath | for the past week or so , suzy has forgotten to brush her teeth ! | everyone around her had wondered where that awful smell was from . | luckily , her older sister had a brilliant idea . | suzy 's sister bought her some mint gum for a treat . | now at least suzy 's breath doesn 't stink !\n",
      "==================most similar end pairs====================\n",
      "smelly feet | my sister always wears sandals . | she was at my mom 's house one day . | no one could figure out the awful odor . | then as we got closer to her , we noticed the stench . | it was her smelly feet !\n",
      "\n",
      "instance # 27\n",
      "daniel affords a plane | daniel wanted to buy a toy plane , but he didn 't have any money . | he asked his neighbors if they would pay him to do jobs . | daniel raked leaves for one neighbor , and helped another one garden . | after 5 weeks of work he could finally afford his plane . | he bought his toy plane , and kept working so he could buy another !\n",
      "==================most similar end pairs====================\n",
      "broken phone | jamal wanted to get a new phone . | he did not want to buy one unnecessarily because he didn 't need it . | last night after work , he was walking to the car when his phone fell . | it fell face down and shattered and nothing would turn on . | he had no choice but to buy a new one to replace it .\n",
      "\n",
      "instance # 28\n",
      "clams | cj loved clams . | one day he went to the beach . | he dug for clams . | there were a lot of clams for him to collect . | cj had a great dinner that night with the clams .\n",
      "==================most similar end pairs====================\n",
      "clams | spence has always been grossed out by seafood . | he and his friends took a trip to the coast . | they went to one of the best seafood restaurants . | he decided to try clams . | he loved them !\n",
      "\n",
      "instance # 29\n",
      "bobo the clown | bobo was a clown who was very tall . | he had a small head however . | his odd proportions allowed him to be even funnier . | while he was younger other kids would laugh at him . | but now he makes a living with his odd physique .\n",
      "==================most similar end pairs====================\n",
      "a new pet in town | shawn was almost an adult now . | he had always wanted a pet dog for himself . | his parents would always say no because he was too young . | now that his eighteenth birthday was here he felt old enough . | before he could ask them again they surprised him with his very own dog .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_start = np.random.randint(story_n)\n",
    "for i in range(rand_start, rand_start + 30):\n",
    "    print \"instance #\",i - rand_start\n",
    "    print \" | \".join([\" \".join([index2word_dic[new_train_set[i][j][k]] for k in range(len(new_train_set[i][j]))]) for j in range(6)])\n",
    "    print \"==================most similar end pairs====================\"\n",
    "    print \" | \".join([\" \".join([index2word_dic[new_train_set[most_simi_storyPNend_pair[i]][j][k]] for k in range(len(new_train_set[most_simi_storyPNend_pair[i]][j]))]) for j in range(6)])\n",
    "    print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45502,)\n"
     ]
    }
   ],
   "source": [
    "most_simi_end = pickle.load(open('../../data/pickles/most_simi_end_pair.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(most_simi_end[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same_pair_dict = {}\n",
    "\n",
    "for i in range(len(compare_vec)):\n",
    "    if compare_vec[i] == 0:\n",
    "        same_pair_dict[i] = most_simi_story_pair[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "a = T.matrix()\n",
    "a_norm = T.sqrt(T.sum(T.sqr(a),axis = 1,keepdims = True))\n",
    "b = a/a_norm\n",
    "\n",
    "test = theano.function([a],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  0]\n",
      " [ 1  2]\n",
      " [ 3  4]]\n",
      "[[-1.          0.        ]\n",
      " [ 0.4472136   0.89442719]\n",
      " [ 0.6         0.8       ]]\n",
      "[[1 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "[[-1.          0.        ]\n",
      " [ 0.4472136   0.89442719]\n",
      " [ 0.6         0.8       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a_t = np.arange(-1,5).reshape(3,2)\n",
    "\n",
    "theano_version = test(a_t)\n",
    "numpy_version = a_t/np.sum(a_t, axis = 1).reshape(-1,1)\n",
    "np_lin_version = a_t/np.linalg.norm(a_t, axis = 1).reshape(-1,1)\n",
    "print a_t\n",
    "print theano_version\n",
    "print numpy_version\n",
    "print np_lin_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20210.,  11891.,  16703.,  27791.,  40423.,  25657.,  11257.,\n",
       "        40423.,  40023.,   6907.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_story_pair[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19170.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_simi_story_pair[42605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "whole_set = train_set[1]\n",
    "\n",
    "story_n = len(end_set)\n",
    "ending_rep_matrix = np.zeros((story_n, 300))\n",
    "for i in range(story_n):\n",
    "    ending_rep_matrix[i] = np.sum([wemb_matrix[end_set[i][j]] for j in range(len(end_set[i]))], axis = 0)/float(len(end_set[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pickle.load(open('../../data/pickles/train_index_corpus.pkl'))\n",
    "train_story = train_set[0]\n",
    "train_ending = train_set[1]\n",
    "n_train = len(train_ending)\n",
    "stories_indices = np.random.randint(n_train, size=(5,))\n",
    "adv_end_rep_batch = np.random.rand(5, 300)\n",
    "for i in range(len(train_ending)):\n",
    "    end_rep_matrix[i] = np.sum(wemb_matrix[train_ending[i]], axis = 0) / (len(train_ending[i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# '''part III print out story and the most similar end correspondingly'''\n",
    "# for i in range(5):\n",
    "#     index = stories_indices[i]\n",
    "#     story_string = \" | \".join([\" \".join(index2word_dict[train_story[index][j][k]] for k in range(len(train_story[index][j])))] for j in range(5))\n",
    "#     story_end = \" \".join(index2word_dict[train_ending[index][k]] for k in range(len(train_ending[index])))\n",
    "#     generated_end = \" \".join(index2word_dict[train_ending[index_list[i]][k]] for k in range(len(train_ending[index_list[i]])))\n",
    "\n",
    "#     print story_string + \"#END#\" + story_end\n",
    "#     print \"adv model generated:\" + generated_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_end_rep_matrix = np.linalg.norm(end_rep_matrix, axis = 1).reshape(-1,1)\n",
    "norm_adv_end_rep = np.linalg.norm(adv_end_rep_batch, axis = 1).reshape(-1,1)\n",
    "# norm_denominator_matrix.shape = (45503, 5)\n",
    "norm_denominator_matrix = np.dot(norm_end_rep_matrix, norm_adv_end_rep.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dot_prod.shape = (45503, 5)\n",
    "dot_prod = np.dot(end_rep_matrix, adv_end_rep_batch.T)\n",
    "\n",
    "# cos_simi_matrix.shape = (45503, 5)\n",
    "cos_simi_matrix = dot_prod / norm_denominator_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_list = np.argmax(cos_simi_matrix, axis = 0)\n",
    "index2word_dict = index2word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_LR_ls = [0.001, 0.01, 0.005, 0.002]\n",
    "\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(SGD_LR_ls)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('./AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.job','w')\n",
    "        \n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e AdvInvLogSepSGDAdamLR'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.8\"\\n')\n",
    "        f.write('SETTING3=\"150\"\\n')\n",
    "        f.write('SETTING4=\"100\"\\n')\n",
    "        f.write('SETTING5=\"512x512\"\\n')\n",
    "        f.write('SETTING6=\"'+str(SGD_LR_ls[i])+'\"\\n')\n",
    "        f.write('SETTING7=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING8=\"sgd\"\\n')\n",
    "        f.write('SETTING9=\"adam\"\\n')\n",
    "        f.write('SETTING10=\"default\"\\n')\n",
    "        f.write('SETTING11=\"0\"\\n')\n",
    "        f.write('SETTING12=\"0.005\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BLSTM_inverseAtt_onlyAdvOnVal.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7 $SETTING8 $SETTING9 $SETTING10 $SETTING11 $SETTING12\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_LR_ls = [0.001, 0.002, 0.003, 0.004]\n",
    "\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(SGD_LR_ls)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('./AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.job','w')\n",
    "\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e AdvInvLogSepAdamAdamLR'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.8\"\\n')\n",
    "        f.write('SETTING3=\"150\"\\n')\n",
    "        f.write('SETTING4=\"100\"\\n')\n",
    "        f.write('SETTING5=\"512x512\"\\n')\n",
    "        f.write('SETTING6=\"'+str(SGD_LR_ls[i])+'\"\\n')\n",
    "        f.write('SETTING7=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING8=\"adam\"\\n')\n",
    "        f.write('SETTING9=\"adam\"\\n')\n",
    "        f.write('SETTING10=\"None\"\\n')\n",
    "        f.write('SETTING11=\"0\"\\n')\n",
    "        f.write('SETTING12=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING13=\"euclidean_distance\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BLSTM_inverseAtt_onlyAdvOnVal.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7 $SETTING8 $SETTING9 $SETTING10 $SETTING11 $SETTING12 $SETTING13\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchsize_ls = [100, 150, 200, 250]\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0002]\n",
    "\n",
    "for i in range(len(batchsize_ls)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('../hierachical_rnn/HGRU_innermax' +str(i)+str(j)+'.job','w')\n",
    "\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N HGRU_innermax'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o HGRU_innermax'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e HGRU_innermax'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.0\"\\n')\n",
    "        f.write('SETTING3=\"'+str(batchsize_ls[i])+'\"\\n')\n",
    "        f.write('SETTING4=\"default\"\\n')\n",
    "        f.write('SETTING5=\"0\"\\n')\n",
    "        f.write('SETTING6=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING7=\"0.5\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BGRU2BGRU_hingeNearRight.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HierBLSTM job scripts \n",
    "\n",
    "batch_size = [200, 250, 300, 350]\n",
    "Adam_LR_ls = [0.001, 0.002, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('../hierachical_rnn/HierBLSTM_cos'+str(i)+str(j)+'.job','w')\n",
    "\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N HierBLSTM_cos'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o HierBLSTM_cos'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e HierBLSTM_cos'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"'+str(batch_size[i])+'\"\\n')\n",
    "        f.write('SETTING3=\"default\"\\n')\n",
    "        f.write('SETTING4=\"0\"\\n')\n",
    "        f.write('SETTING5=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING6=\"2.0\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BLSTM_hingeCosine.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HierBLSTM job scripts \n",
    "\n",
    "batch_size = [200, 250, 300, 350]\n",
    "Adam_LR_ls = [0.002, 0.001, 0.0005, 0.0001]\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('../hierachical_rnn/HierBGRU_cos'+str(i)+str(j)+'.job','w')\n",
    "\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N HierBGRU_cos'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o HierBGRU_cos'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e HierBGRU_cos'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.0\"\\n')\n",
    "        f.write('SETTING3=\"'+str(batch_size[i])+'\"\\n')\n",
    "        f.write('SETTING4=\"default\"\\n')\n",
    "        f.write('SETTING5=\"0\"\\n')\n",
    "        f.write('SETTING6=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING7=\"2.0\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python BGRU2BGRU_hingeCosine.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "best_val_acc_ls = np.zeros((4,4))\n",
    "\n",
    "best_test_acc_ls = np.zeros((4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        f = open('../hierachical_rnn/HierBGRU_cos'+str(i)+str(j)+'.out','r')\n",
    "        best_val_acc = 0.0\n",
    "        best_test_acc = 0.0\n",
    "        for line in f:\n",
    "            if line.startswith('accuracy is'):\n",
    "                val_acc = float(line.split(' ')[-2])\n",
    "                if val_acc >= best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "            if line.startswith('test set accuracy'):\n",
    "                test_acc = float(line.split(' ')[-2])\n",
    "                if test_acc >= best_test_acc:\n",
    "                    best_test_acc = test_acc\n",
    "        best_val_acc_ls[i][j] = best_val_acc\n",
    "        best_test_acc_ls[i][j] = best_test_acc\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55.47835382  56.38695885  55.2645644   56.49385355]\n",
      " [ 54.14216996  56.38695885  57.24211652  55.31801176]\n",
      " [ 57.88348477  56.28006414  56.4404062   56.33351149]\n",
      " [ 54.99732763  56.65419562  56.76109033  56.11972207]]\n",
      "[[ 54.94388028  55.1576697   53.23356494  54.83698557]\n",
      " [ 52.37840727  54.03527525  54.89043292  55.10422234]\n",
      " [ 55.1576697   54.62319615  54.78353821  54.5697488 ]\n",
      " [ 52.96632817  55.47835382  53.66114377  55.1576697 ]]\n"
     ]
    }
   ],
   "source": [
    "print best_val_acc_ls\n",
    "print best_test_acc_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "26\n",
      "32\n",
      "33\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        f = open('../hierachical_rnn/HierBLSTM_cos'+str(i)+str(j)+'.out','r')\n",
    "        epoch = 0\n",
    "        for line in f:\n",
    "            if line.startswith('epoch  '):\n",
    "                tokens = line.split()\n",
    "                epoch_num = int(tokens[-2])\n",
    "                if epoch_num > epoch:\n",
    "                    epoch = epoch_num\n",
    "        print epoch\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HierBGRU_hingeDNN large batch size experiments job scripts\n",
    "batch_size = [200, 250, 300, 350]\n",
    "Adam_LR_ls = [0.002, 0.001, 0.0005, 0.00025]\n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    for j in range(len(Adam_LR_ls)):\n",
    "        f = open('../hierachical_rnn/HierBGRU_hingeDNN'+str(i)+str(j)+'.job','w')\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write('#$ -S /bin/bash\\n')\n",
    "        f.write('#$ -M jontsai@uchicago.edu\\n')\n",
    "        f.write('#$ -N HierBGRU_DNN'+str(i)+str(j)+'\\n')\n",
    "        f.write('#$ -m beasn\\n')\n",
    "        f.write('#$ -o HierBGRU_DNN'+str(i)+str(j)+'.out\\n')\n",
    "        f.write('#$ -e HierBGRU_DNN'+str(i)+str(j)+'.err\\n')\n",
    "        f.write('#$ -r n\\n')\n",
    "        f.write('#$ -cwd\\n')\n",
    "        f.write('SETTING1=\"300\"\\n')\n",
    "        f.write('SETTING2=\"0.05\"\\n')\n",
    "        f.write('SETTING3=\"'+str(batch_size[i])+'\"\\n')\n",
    "        f.write('SETTING4=\"None\"\\n')\n",
    "        f.write('SETTING5=\"0\"\\n')\n",
    "        f.write('SETTING6=\"'+str(Adam_LR_ls[j])+'\"\\n')\n",
    "        f.write('SETTING7=\"1.0\"\\n')\n",
    "        f.write('SETTING8=\"last\"\\n')\n",
    "        f.write('export OMP_NUM_THREADS=2\\n')\n",
    "        f.write('export OPENBLAS_NUM_THREADS=2\\n')\n",
    "        f.write('echo \"Start - `date`\"\\n')\n",
    "        f.write('/home-nfs/jontsai/anaconda/bin/python HierBGRU_hingeDNN.py \\\\\\n')\n",
    "        f.write('$SETTING1 $SETTING2 $SETTING3 $SETTING4 $SETTING5 $SETTING6 $SETTING7 $SETTING8\\n')\n",
    "        f.write('echo \"End - `date`\"\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.vector()\n",
    "b = T.vector()\n",
    "c = a/b\n",
    "\n",
    "test = theano.function([a,b], c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[ nan   1.   1.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "b = np.arange(5)\n",
    "c = test(a,b)\n",
    "print c.shape\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Recurrent network example.  Trains a 2 layered LSTM network to learn\n",
    "text from a user-provided input file. The network can then be used to generate\n",
    "text using a short string as seed (refer to the variable generation_phrase).\n",
    "This example is partly based on Andrej Karpathy's blog\n",
    "(http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "and a similar example in the Keras package (keras.io).\n",
    "The inputs to the network are batches of sequences of characters and the corresponding\n",
    "targets are the characters in the text shifted to the right by one. \n",
    "Assuming a sequence length of 5, a training point for a text file\n",
    "\"The quick brown fox jumps over the lazy dog\" would be\n",
    "INPUT : 'T','h','e',' ','q'\n",
    "OUTPUT: 'u'\n",
    "The loss function compares (via categorical crossentropy) the prediction\n",
    "with the output/target.\n",
    "Also included is a function to generate text using the RNN given the first \n",
    "character.  \n",
    "About 20 or so epochs are necessary to generate text that \"makes sense\".\n",
    "Written by @keskarnitish\n",
    "Pre-processing of text uses snippets of Karpathy's code (BSD License)\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import urllib2 #For downloading the sample text file. You won't need this if you are providing your own file.\n",
    "try:\n",
    "    in_text = urllib2.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt').read()\n",
    "    #You can also use your own file\n",
    "    #The file must be a simple text file.\n",
    "    #Simply edit the file name below and uncomment the line.  \n",
    "    #in_text = open('your_file.txt', 'r').read()\n",
    "    in_text = in_text.decode(\"utf-8-sig\").encode(\"utf-8\")\n",
    "except Exception as e:\n",
    "    print(\"Please verify the location of the input file/URL.\")\n",
    "    print(\"A sample txt file can be downloaded from https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "    raise IOError('Unable to Read Text')\n",
    "\n",
    "generation_phrase = \"The quick brown fox jumps\" #This phrase will be used as seed to generate text.\n",
    "\n",
    "#This snippet loads the text file and creates dictionaries to \n",
    "#encode characters into a vector-space representation and vice-versa. \n",
    "chars = list(set(in_text))\n",
    "data_size, vocab_size = len(in_text), len(chars)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "#Lasagne Seed for Reproducibility\n",
    "lasagne.random.set_rng(np.random.RandomState(1))\n",
    "\n",
    "# Sequence Length\n",
    "SEQ_LENGTH = 20\n",
    "\n",
    "# Number of units in the two hidden (LSTM) layers\n",
    "N_HIDDEN = 512\n",
    "\n",
    "# Optimization learning rate\n",
    "LEARNING_RATE = .01\n",
    "\n",
    "# All gradients above this will be clipped\n",
    "GRAD_CLIP = 100\n",
    "\n",
    "# How often should we check the output?\n",
    "PRINT_FREQ = 1000\n",
    "\n",
    "# Number of epochs to train the net\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def gen_data(p, batch_size = BATCH_SIZE, data=in_text, return_target=True):\n",
    "    '''\n",
    "    This function produces a semi-redundant batch of training samples from the location 'p' in the provided string (data).\n",
    "    For instance, assuming SEQ_LENGTH = 5 and p=0, the function would create batches of \n",
    "    5 characters of the string (starting from the 0th character and stepping by 1 for each semi-redundant batch)\n",
    "    as the input and the next character as the target.\n",
    "    To make this clear, let us look at a concrete example. Assume that SEQ_LENGTH = 5, p = 0 and BATCH_SIZE = 2\n",
    "    If the input string was \"The quick brown fox jumps over the lazy dog.\",\n",
    "    For the first data point,\n",
    "    x (the inputs to the neural network) would correspond to the encoding of 'T','h','e',' ','q'\n",
    "    y (the targets of the neural network) would be the encoding of 'u'\n",
    "    For the second point,\n",
    "    x (the inputs to the neural network) would correspond to the encoding of 'h','e',' ','q', 'u'\n",
    "    y (the targets of the neural network) would be the encoding of 'i'\n",
    "    The data points are then stacked (into a three-dimensional tensor of size (batch_size,SEQ_LENGTH,vocab_size))\n",
    "    and returned. \n",
    "    Notice that there is overlap of characters between the batches (hence the name, semi-redundant batch).\n",
    "    '''\n",
    "    x = np.zeros((batch_size,SEQ_LENGTH,vocab_size))\n",
    "    y = np.zeros(batch_size)\n",
    "\n",
    "    for n in range(batch_size):\n",
    "        ptr = n\n",
    "        for i in range(SEQ_LENGTH):\n",
    "            x[n,i,char_to_ix[data[p+ptr+i]]] = 1.\n",
    "        if(return_target):\n",
    "            y[n] = char_to_ix[data[p+ptr+SEQ_LENGTH]]\n",
    "    return x, np.array(y,dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "def main(num_epochs=NUM_EPOCHS):\n",
    "    print(\"Building network ...\")\n",
    "   \n",
    "    # First, we build the network, starting with an input layer\n",
    "    # Recurrent layers expect input of shape\n",
    "    # (batch size, SEQ_LENGTH, num_features)\n",
    "\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, None, vocab_size))\n",
    "\n",
    "    # We now build the LSTM layer which takes l_in as the input layer\n",
    "    # We clip the gradients at GRAD_CLIP to prevent the problem of exploding gradients. \n",
    "\n",
    "    l_forward_1 = lasagne.layers.LSTMLayer(\n",
    "        l_in, N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "    l_forward_2 = lasagne.layers.LSTMLayer(\n",
    "        l_forward_1, N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        only_return_final=True)\n",
    "\n",
    "    # The output of l_forward_2 of shape (batch_size, N_HIDDEN) is then passed through the softmax nonlinearity to \n",
    "    # create probability distribution of the prediction\n",
    "    # The output of this stage is (batch_size, vocab_size)\n",
    "    l_out = lasagne.layers.DenseLayer(l_forward_2, num_units=vocab_size, W = lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    # Theano tensor for the targets\n",
    "    target_values = T.ivector('target_output')\n",
    "    \n",
    "    # lasagne.layers.get_output produces a variable for the output of the net\n",
    "    network_output = lasagne.layers.get_output(l_out)\n",
    "\n",
    "    # The loss function is calculated as the mean of the (categorical) cross-entropy between the prediction and target.\n",
    "    cost = T.nnet.categorical_crossentropy(network_output,target_values).mean()\n",
    "\n",
    "    # Retrieve all parameters from the network\n",
    "    all_params = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "\n",
    "    # Compute AdaGrad updates for training\n",
    "    print(\"Computing updates ...\")\n",
    "    updates = lasagne.updates.adagrad(cost, all_params, LEARNING_RATE)\n",
    "\n",
    "    # Theano functions for training and computing cost\n",
    "    print(\"Compiling functions ...\")\n",
    "    train = theano.function([l_in.input_var, target_values], cost, updates=updates, allow_input_downcast=True)\n",
    "    compute_cost = theano.function([l_in.input_var, target_values], cost, allow_input_downcast=True)\n",
    "\n",
    "    # In order to generate text from the network, we need the probability distribution of the next character given\n",
    "    # the state of the network and the input (a seed).\n",
    "    # In order to produce the probability distribution of the prediction, we compile a function called probs. \n",
    "    \n",
    "    probs = theano.function([l_in.input_var],network_output,allow_input_downcast=True)\n",
    "\n",
    "    # The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    # The phrase is set using the variable generation_phrase.\n",
    "    # The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "    def try_it_out(N=200):\n",
    "        '''\n",
    "        This function uses the user-provided string \"generation_phrase\" and current state of the RNN generate text.\n",
    "        The function works in three steps:\n",
    "        1. It converts the string set in \"generation_phrase\" (which must be over SEQ_LENGTH characters long) \n",
    "           to encoded format. We use the gen_data function for this. By providing the string and asking for a single batch,\n",
    "           we are converting the first SEQ_LENGTH characters into encoded form. \n",
    "        2. We then use the LSTM to predict the next character and store it in a (dynamic) list sample_ix. This is done by using the 'probs'\n",
    "           function which was compiled above. Simply put, given the output, we compute the probabilities of the target and pick the one \n",
    "           with the highest predicted probability. \n",
    "        3. Once this character has been predicted, we construct a new sequence using all but first characters of the \n",
    "           provided string and the predicted character. This sequence is then used to generate yet another character.\n",
    "           This process continues for \"N\" characters. \n",
    "        To make this clear, let us again look at a concrete example. \n",
    "        Assume that SEQ_LENGTH = 5 and generation_phrase = \"The quick brown fox jumps\". \n",
    "        We initially encode the first 5 characters ('T','h','e',' ','q'). The next character is then predicted (as explained in step 2). \n",
    "        Assume that this character was 'J'. We then construct a new sequence using the last 4 (=SEQ_LENGTH-1) characters of the previous\n",
    "        sequence ('h','e',' ','q') , and the predicted letter 'J'. This new sequence is then used to compute the next character and \n",
    "        the process continues.\n",
    "        '''\n",
    "\n",
    "        assert(len(generation_phrase)>=SEQ_LENGTH)\n",
    "        sample_ix = []\n",
    "        x,_ = gen_data(len(generation_phrase)-SEQ_LENGTH, 1, generation_phrase,0)\n",
    "\n",
    "        for i in range(N):\n",
    "            # Pick the character that got assigned the highest probability\n",
    "            ix = np.argmax(probs(x).ravel())\n",
    "            # Alternatively, to sample from the distribution instead:\n",
    "            # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "            sample_ix.append(ix)\n",
    "            x[:,0:SEQ_LENGTH-1,:] = x[:,1:,:]\n",
    "            x[:,SEQ_LENGTH-1,:] = 0\n",
    "            x[0,SEQ_LENGTH-1,sample_ix[-1]] = 1. \n",
    "\n",
    "        random_snippet = generation_phrase + ''.join(ix_to_char[ix] for ix in sample_ix)    \n",
    "        print(\"----\\n %s \\n----\" % random_snippet)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Training ...\")\n",
    "    print(\"Seed used for text generation is: \" + generation_phrase)\n",
    "    p = 0\n",
    "    try:\n",
    "        for it in xrange(data_size * num_epochs / BATCH_SIZE):\n",
    "            try_it_out() # Generate text using the p^th character as the start. \n",
    "            \n",
    "            avg_cost = 0;\n",
    "            for _ in range(PRINT_FREQ):\n",
    "                x,y = gen_data(p)\n",
    "                \n",
    "                #print(p)\n",
    "                p += SEQ_LENGTH + BATCH_SIZE - 1 \n",
    "                if(p+BATCH_SIZE+SEQ_LENGTH >= data_size):\n",
    "                    print('Carriage Return')\n",
    "                    p = 0;\n",
    "                \n",
    "\n",
    "                avg_cost += train(x, y)\n",
    "            print(\"Epoch {} average loss = {}\".format(it*1.0*PRINT_FREQ/data_size*BATCH_SIZE, avg_cost / PRINT_FREQ))\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2 #For downloading the sample text file. You won't need this if you are providing your own file.\n",
    "\n",
    "try:\n",
    "    in_text = urllib2.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt').read()\n",
    "    #You can also use your own file\n",
    "    #The file must be a simple text file.\n",
    "    #Simply edit the file name below and uncomment the line.  \n",
    "    #in_text = open('your_file.txt', 'r').read()\n",
    "    in_text = in_text.decode(\"utf-8-sig\").encode(\"utf-8\")\n",
    "except Exception as e:\n",
    "    print(\"Please verify the location of the input file/URL.\")\n",
    "    print(\"A sample txt file can be downloaded from https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "    raise IOError('Unable to Read Text')\n",
    "\n",
    "generation_phrase = \"The quick brown fox jumps\" #This phrase will be used as seed to generate text.\n",
    "\n",
    "#This snippet loads the text file and creates dictionaries to \n",
    "#encode characters into a vector-space representation and vice-versa. \n",
    "chars = list(set(in_text))\n",
    "data_size, vocab_size = len(in_text), len(chars)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600901\n",
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all ph\n"
     ]
    }
   ],
   "source": [
    "print len(in_text)\n",
    "print in_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import BLSTM_sequence\n",
    "import numpy as np\n",
    "import lasagne\n",
    "a = T.matrix(dtype='int64')\n",
    "a_reshape = a.dimshuffle(0,1,'x')\n",
    "b = T.matrix(dtype=theano.config.floatX)\n",
    "\n",
    "wemb = theano.shared(np.random.rand(20,2))\n",
    "encoder = BLSTM_sequence.BlstmEncoder(LSTMLAYER_1_UNITS = 2, wemb_trainable = False)\n",
    "encoder.build_model(wemb)\n",
    "\n",
    "seq = lasagne.layers.get_output(encoder.output, {encoder.l_in: a_reshape,\n",
    "                                                 encoder.l_mask: b})\n",
    "\n",
    "test = theano.function([a,b], seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_ls = np.random.randint(6, size = (5,))\n",
    "batch_ls = []\n",
    "for i in range(5):\n",
    "    batch_ls.append(list(np.random.randint(20, size=(len_ls[i],))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  7 17 16  3]\n",
      " [ 7  0  0  0  0]\n",
      " [ 7 15  0  0  0]\n",
      " [14 19  0  0  0]\n",
      " [ 4 15 17  8  0]]\n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "batch_matrix = utils.padding(batch_ls)\n",
    "batch_mask = utils.mask_generator(batch_ls)\n",
    "print batch_matrix\n",
    "print batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.13653159,  0.70147757],\n",
       "        [ 0.00950921,  0.58593329],\n",
       "        [ 0.0442238 ,  0.72475287],\n",
       "        [-0.03927389,  0.78916293],\n",
       "        [-0.18472336,  0.84670197]],\n",
       "\n",
       "       [[-0.0461301 ,  0.20130033],\n",
       "        [-0.03104189,  0.09977244],\n",
       "        [-0.03104189,  0.09977244],\n",
       "        [-0.03104189,  0.09977244],\n",
       "        [-0.03104189,  0.09977244]],\n",
       "\n",
       "       [[ 0.02154436,  0.31594813],\n",
       "        [ 0.03461041,  0.60768658],\n",
       "        [-0.02225799,  0.37655755],\n",
       "        [-0.02225799,  0.37655755],\n",
       "        [-0.02225799,  0.37655755]],\n",
       "\n",
       "       [[ 0.13216289,  0.62139024],\n",
       "        [-0.0686795 ,  0.83251609],\n",
       "        [-0.05181519,  0.54631201],\n",
       "        [-0.05181519,  0.54631201],\n",
       "        [-0.05181519,  0.54631201]],\n",
       "\n",
       "       [[-0.01564802,  0.31434353],\n",
       "        [ 0.0630465 ,  0.68519586],\n",
       "        [-0.02255314,  0.57926313],\n",
       "        [-0.1359491 ,  0.3418934 ],\n",
       "        [-0.1499376 ,  0.31680127]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(batch_matrix, batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.matrix()\n",
    "\n",
    "\n",
    "a_b = a.dimshuffle(0,'x',1)*T.ones((a.shape[0],2,a.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test = theano.function([a], a_b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.],\n",
       "        [ 0.,  1.]],\n",
       "\n",
       "       [[ 2.,  3.],\n",
       "        [ 2.,  3.]],\n",
       "\n",
       "       [[ 4.,  5.],\n",
       "        [ 4.,  5.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t = np.arange(6).reshape(3,2)\n",
    "\n",
    "test(a_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_pair_in = lasagne.layers.InputLayer(shape = (None, 10))\n",
    "\n",
    "# we cache the encoded result to pick the max score negative sample from them later\n",
    "l_hid1 = lasagne.layers.DenseLayer(l_pair_in, num_units = 1024, nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "l_hid = lasagne.layers.DenseLayer(l_hid1, num_units=1, nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "matrix_input = T.tensor3()\n",
    "\n",
    "reshaped_input = matrix_input.reshape((matrix_input.shape[0]*matrix_input.shape[1], -1))\n",
    "score = lasagne.layers.get_output(l_hid, {l_pair_in:reshaped_input})\n",
    "\n",
    "test = theano.function([matrix_input], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor.nlinalg as TL\n",
    "a = T.vector()\n",
    "dim = a.shape[0]\n",
    "b = T.eye(dim)\n",
    "c = a*b\n",
    "\n",
    "\n",
    "test = theano.function([a], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = T.tensor3()\n",
    "b = T.tensor3()\n",
    "\n",
    "\n",
    "c = T.batched_dot(a,b)\n",
    "\n",
    "test = theano.function([a,b], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "a_t = np.arange(3*4).reshape(3,4,1)\n",
    "b_t = np.arange(3*4).reshape(3,1,4)\n",
    "\n",
    "c_t = test(a_t, b_t)\n",
    "\n",
    "print c_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
